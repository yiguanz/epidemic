{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sklearn\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "# from viz import viz\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file, save\n",
    "from functions import merge_data\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import load_data\n",
    "import exponential_modeling\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import fit_and_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data.load_county_level(data_dir = '../data/')\n",
    "#df = df.sort_values('#Deaths_4/3/20', ascending=False)\n",
    "# outcome_cases = load_data.outcome_cases # most recent day\n",
    "# outcome_deaths = load_data.outcome_deaths\n",
    "important_vars = load_data.important_keys(df)\n",
    "very_important_vars = ['PopulationDensityperSqMile2010',\n",
    "#                        'MedicareEnrollment,AgedTot2017',\n",
    "                       'PopulationEstimate2018',\n",
    "                       '#ICU_beds',\n",
    "                       'MedianAge2010',\n",
    "                       'Smokers_Percentage',\n",
    "                       'DiabetesPercentage',\n",
    "                       'HeartDiseaseMortality',\n",
    "                        '#Hospitals'\n",
    "#                        'PopMale60-642010',\n",
    "#                         'PopFmle60-642010',\n",
    "#                          'PopMale65-742010',\n",
    "#                          'PopFmle65-742010',\n",
    "#                          'PopMale75-842010',\n",
    "#                          'PopFmle75-842010',\n",
    "#                          'PopMale>842010',\n",
    "#                          'PopFmle>842010'\n",
    "                      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cases = [max(v) for v in df['cases']]\n",
    "df['max_cases'] = max_cases\n",
    "df =  df[df['max_cases'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential = {'model_type':'exponential'}\n",
    "shared_exponential = {'model_type':'shared_exponential'}\n",
    "demographics = {'model_type':'shared_exponential', 'demographic_vars':very_important_vars}\n",
    "linear = {'model_type':'linear'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predictions we save: four separate models, simple ensemble model with exponential and shared_exponential , ensemble with all possible combinations of 3 models, full ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_methods = [exponential, \n",
    "               shared_exponential,\n",
    "               demographics,\n",
    "               linear]\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 22)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=all_methods,\n",
    "                                              output_key=f'predicted_deaths_ensemble_all'\n",
    "                                              )\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 22)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=all_methods[:2],\n",
    "                                              output_key=f'predicted_deaths_simple_ensemble_all'\n",
    "                                              )\n",
    "for (i, model) in enumerate(all_methods):\n",
    "        \n",
    "    if 'demographic_vars' in model:\n",
    "        demographic_vars = model['demographic_vars']\n",
    "    else:\n",
    "        demographic_vars = []\n",
    "    \n",
    "    method = model['model_type']\n",
    "    #print(method)\n",
    "    method_name = model['model_type']\n",
    "    if 'demographic_vars' in model:\n",
    "        method_name = 'demographics'\n",
    "    df = fit_and_predict.fit_and_predict(df, \n",
    "                                         outcome='deaths', \n",
    "                                         method=method, \n",
    "                                         mode='predict_future', \n",
    "                                         target_day=np.array(range(1, 22)),\n",
    "                                         output_key=f'predicted_deaths_{method_name}_all',\n",
    "                                         demographic_vars=demographic_vars)\n",
    "    print(all_methods[0:i]+all_methods[(i+1):])\n",
    "    df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 22)),\n",
    "                                              mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=all_methods[0:i]+all_methods[(i+1):],\n",
    "                                              output_key=f'predicted_deaths_ensemble_no_{method_name}_all'\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_keys = [c for c in df if 'predicted' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in method_keys:\n",
    "    for d in range(1, 8):\n",
    "        newkey = key[:-3] + str(d)\n",
    "        df[newkey] = np.array([p[d-1] for p in df[key].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_deaths_demographics_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in df if 'predicted' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df:\n",
    "    if 'predicted' in c and 'all' not in c:\n",
    "        print((c, df[c].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_keys = [c for c in df if 'predicted' in c]\n",
    "geo = ['countyFIPS', 'CountyNamew/StateAbbrev']\n",
    "preds_df = df[method_keys + geo]\n",
    "preds_df.to_csv(\"../predictions/predictions_04_03.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deaths'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-level predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_by_state = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_lists(list_of_lists):\n",
    "    arr = np.array(list(list_of_lists))\n",
    "    sum_arr = np.sum(arr,0)\n",
    "    return list(sum_arr)\n",
    "\n",
    "def get_90_quantile(feature):\n",
    "    return np.quantile(np.array(feature), .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as oj\n",
    "def load_state_data(usafacts_data_cases='usafacts/confirmed_cases.csv',\n",
    "                    usafacts_data_deaths='usafacts/deaths.csv',\n",
    "                    dir_mod = \"\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    load state-level data.\n",
    "    \n",
    "    For cases/deaths data, this is almost the same as load_usafacts, with unallocated deaths added to each state\n",
    "    For demographic variables, data are aggregated from county level\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    usafacts_data_cases = oj(dir_mod, usafacts_data_cases)\n",
    "    usafacts_data_deaths = oj(dir_mod, usafacts_data_deaths)\n",
    "    \n",
    "    cases = pd.read_csv(usafacts_data_cases, encoding=\"iso-8859-1\", index_col=0).T\n",
    "    deaths = pd.read_csv(usafacts_data_deaths, encoding=\"iso-8859-1\", index_col=0).T\n",
    "    if not 'countyFIPS' in deaths.keys():\n",
    "        deaths = pd.read_csv(usafacts_data_deaths, encoding=\"utf-8\", index_col=0).T\n",
    "    # change to int type\n",
    "    for col in cases.columns:\n",
    "        if not 'county' in col.lower() and not 'state' in col.lower():\n",
    "            cases[col] = cases[col].astype(float).astype(int)\n",
    "            deaths[col] = deaths[col].astype(float).astype(int)\n",
    "  \n",
    " \n",
    "    cases = cases.rename(columns={k: '#Cases_' + k for k in cases.keys()\n",
    "                                  if not 'county' in k.lower()\n",
    "                                  and not 'state' in k.lower()})\n",
    "\n",
    "\n",
    "    deaths = deaths.rename(columns={k: '#Deaths_' + k for k in deaths.keys()\n",
    "                                    if not 'county' in k.lower()\n",
    "                                    and not 'state' in k.lower()})\n",
    "\n",
    "    deaths.countyFIPS = deaths.countyFIPS.astype(int)\n",
    "    cases.countyFIPS = cases.countyFIPS.astype(int)\n",
    "   \n",
    "    #cases = cases[cases.countyFIPS != 0]   # these are not removed because of 'unallocated' deaths\n",
    "    cases = cases.groupby(['State']).sum().reset_index()  # sum over counties\n",
    "    #deaths = deaths[deaths.countyFIPS != 0]\n",
    "    deaths = deaths.groupby(['State']).sum().reset_index()\n",
    "    \n",
    "    cases_and_deaths = pd.merge(cases, deaths, how='left', on='State')\n",
    "    cases_and_deaths = cases_and_deaths.fillna(0)\n",
    "    deaths_keys = [k for k in cases_and_deaths.keys() if '#Deaths' in k and not 'Unnamed' in k]\n",
    "    cases_keys = [k for k in cases_and_deaths.keys() if '#Cases' in k and not 'Unnamed' in k]\n",
    "    deaths = cases_and_deaths[deaths_keys].values\n",
    "    cases = cases_and_deaths[cases_keys].values\n",
    "    cases_and_deaths['deaths'] = [deaths[i] for i in range(deaths.shape[0])]\n",
    "    cases_and_deaths['cases'] = [cases[i] for i in range(cases.shape[0])]\n",
    "    cases_and_deaths['tot_deaths'] = deaths[:, -1]\n",
    "    cases_and_deaths['tot_cases'] = cases[:, -1]    \n",
    "    \n",
    "    df = load_data.load_county_level(data_dir = '../data/')\n",
    "    df['DiabetesPercentage'] = df['DiabetesPercentage'].astype(float)\n",
    "    pop_density = df.groupby('StateNameAbbreviation').PopulationDensityperSqMile2010.agg(get_90_quantile).to_frame()\n",
    "    pop = df.groupby('StateNameAbbreviation').PopulationEstimate2018.agg(sum).to_frame()\n",
    "    median_age = df.groupby('StateNameAbbreviation').MedianAge2010.agg(get_90_quantile).to_frame()\n",
    "    smoker_pct = df.groupby('StateNameAbbreviation').Smokers_Percentage.agg(get_90_quantile).to_frame()\n",
    "    diabetes_pct = df.groupby('StateNameAbbreviation').DiabetesPercentage.agg(get_90_quantile).to_frame()\n",
    "    hdm = df.groupby('StateNameAbbreviation').HeartDiseaseMortality.agg(get_90_quantile).to_frame()\n",
    "    hospitals = df.groupby('StateNameAbbreviation')['#Hospitals'].agg(sum).to_frame()\n",
    "    ICU_beds = df.groupby('StateNameAbbreviation')['#ICU_beds'].agg(sum).to_frame()\n",
    "    df =  pd.concat([\n",
    "                     pop_density,pop,median_age,\n",
    "                     smoker_pct,diabetes_pct,hdm,\n",
    "                     hospitals,ICU_beds],axis =1 )\n",
    "    df['State'] = df.index\n",
    "    \n",
    "    state_df = pd.merge(cases_and_deaths, df, how='left', on='State')\n",
    "\n",
    "\n",
    "    return state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df = load_state_data(dir_mod = \"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9552"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p[-1] for p in state_df['deaths'].values) ## for 4/6, this should be close to 9552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_important_vars = ['PopulationDensityperSqMile2010',\n",
    "#                        'MedicareEnrollment,AgedTot2017',\n",
    "                       #'PopulationEstimate2018',\n",
    "                       #'#ICU_beds',\n",
    "                       'MedianAge2010',\n",
    "                       'Smokers_Percentage']\n",
    "exponential = {'model_type':'exponential'}\n",
    "shared_exponential = {'model_type':'shared_exponential'}\n",
    "demographics = {'model_type':'shared_exponential', 'demographic_vars':very_important_vars}\n",
    "linear = {'model_type':'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = copy.deepcopy(state_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running state-level prediction eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature weights\n",
      "log(deaths) : 1.1822510205293864\n",
      "bias : 1.3723001140188678\n",
      "Feature weights\n",
      "log(deaths) : 1.0759441459151247\n",
      "bias : 1.3138423004688369\n",
      "Feature weights\n",
      "log(deaths) : 1.0437926797933805\n",
      "bias : 1.278200967516959\n",
      "Feature weights\n",
      "log(deaths) : 1.0140128828289556\n",
      "bias : 1.2512151709547663\n",
      "Feature weights\n",
      "log(deaths) : 0.9844898004115722\n",
      "bias : 1.2360732782493025\n",
      "Feature weights\n",
      "log(deaths) : 0.97437289087402\n",
      "bias : 1.2138380524713366\n",
      "Feature weights\n",
      "log(deaths) : 0.954398259323746\n",
      "bias : 1.2326864386596612\n",
      "Feature weights\n",
      "log(deaths) : 0.9426483127024406\n",
      "bias : 1.2942167202218218\n",
      "--- Model Contributions ---\n",
      "{'model_type': 'shared_exponential'}: 0.5023676392953276\n",
      "{'model_type': 'linear'}: 0.4976323607046724\n",
      "Feature weights\n",
      "log(deaths) : 1.1822510205293864\n",
      "bias : 1.3723001140188678\n",
      "Feature weights\n",
      "log(deaths) : 1.0759441459151247\n",
      "bias : 1.3138423004688369\n",
      "Feature weights\n",
      "log(deaths) : 1.0437926797933805\n",
      "bias : 1.278200967516959\n",
      "Feature weights\n",
      "log(deaths) : 1.0140128828289556\n",
      "bias : 1.2512151709547663\n",
      "Feature weights\n",
      "log(deaths) : 0.9844898004115722\n",
      "bias : 1.2360732782493025\n",
      "Feature weights\n",
      "log(deaths) : 0.97437289087402\n",
      "bias : 1.2138380524713366\n",
      "Feature weights\n",
      "log(deaths) : 0.954398259323746\n",
      "bias : 1.2326864386596612\n",
      "Feature weights\n",
      "log(deaths) : 0.9426483127024406\n",
      "bias : 1.2942167202218218\n",
      "--- Model Contributions ---\n",
      "{'model_type': 'shared_exponential'}: 1.0\n"
     ]
    }
   ],
   "source": [
    "all_methods = [exponential, \n",
    "               shared_exponential,\n",
    "               #demographics,\n",
    "               linear]\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 8)),\n",
    "                                              mode='eval_mode',\n",
    "                                              #mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=all_methods[1:],\n",
    "                                              output_key=f'predicted_deaths_ensemble_all'\n",
    "                                              )\n",
    "df = fit_and_predict.fit_and_predict_ensemble(df, \n",
    "                                              target_day=np.array(range(1, 8)),\n",
    "                                              mode='eval_mode',\n",
    "                                              #mode='predict_future',\n",
    "                                              outcome='deaths',\n",
    "                                              methods=[all_methods[1]],\n",
    "                                              output_key=f'predicted_deaths_simple_ensemble_all'\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_keys = [c for c in df if 'predicted' in c]\n",
    "for key in method_keys:  # convert '_all' predictions to daily predictions\n",
    "    if 'all' in key:\n",
    "        for d in range(1, 8):\n",
    "            newkey = key[:-3] + str(d)\n",
    "            df[newkey] = np.array([p[d-1] for p in df[key].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state'] = df.State\n",
    "method_keys = [c for c in df if 'predicted' in c]\n",
    "preds_df = df[method_keys + ['state']]\n",
    "preds_df.to_csv(\"../predictions/predictions_state_level_03_30.csv\") # only run this if you wish to save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1853.4456776374047"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(df['predicted_deaths_ensemble_7'].values - np.array([p[-1] for p in df['deaths'].values])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_deaths_simple_ensemble_7'][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
