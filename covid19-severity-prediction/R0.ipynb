{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading county-level data...\n",
      "loaded and merged COVID-19 cases/deaths data successfully\n"
     ]
    }
   ],
   "source": [
    "import load_data\n",
    "df = load_data.load_county_level(data_dir='data')\n",
    "keys = df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "attr_cols = []\n",
    "\n",
    "# Set the variable to True if we want to specify features ourselves.\n",
    "use_specified_fields = False\n",
    "\n",
    "if use_specified_fields:\n",
    "    f = open(\"fields.txt\", \"r\")\n",
    "    fields = f.readlines()\n",
    "    for field in fields:\n",
    "        field = field.rstrip()\n",
    "        arr = np.array(df[field])\n",
    "        if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
    "            attr_cols.append(np.array(arr, dtype=np.float32))\n",
    "else:\n",
    "    for i in range(6, 86):\n",
    "        arr = np.array(df[keys[i]])\n",
    "        if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
    "            attr_cols.append(np.array(arr, dtype=np.float32))\n",
    "\n",
    "attrs = th.tensor(np.stack(attr_cols, 1), dtype=th.float32)\n",
    "cases = []\n",
    "# for i in range(87, 216):\n",
    "for i in range(132, 216):\n",
    "    cases.append(np.array(df[keys[i]]))\n",
    "cases = np.stack(cases, 1)\n",
    "deaths = []\n",
    "# for i in range(218, 347):\n",
    "for i in range(263, 347):\n",
    "    deaths.append(np.array(df[keys[i]]))\n",
    "deaths = np.stack(deaths, 1)\n",
    "\n",
    "pop = attrs[:,5]\n",
    "pop = pop.view(3142, 1)\n",
    "pop[1834] = 96471 #fixed the population value for Erie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_params(cases, recovered, deaths, population):\n",
    "    X = cases\n",
    "    R = recovered + deaths\n",
    "\n",
    "    n = np.array([population] * len(X), dtype=np.float64)\n",
    "\n",
    "    S = n - X - R\n",
    "\n",
    "    X_diff = np.array([X[:-1], X[1:]], dtype=np.float64).T\n",
    "    R_diff = np.array([R[:-1], R[1:]], dtype=np.float64).T\n",
    "\n",
    "    gamma = (R[1:] - R[:-1]) / (X[:-1] + 1)\n",
    "    beta = n[:-1] * (X[1:] - X[:-1] + R[1:] - R[:-1]) / (X[:-1] * (n[:-1] - X[:-1] - R[:-1]) + 1)\n",
    "    return gamma, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_lst = []\n",
    "beta_lst = []\n",
    "recovered = np.zeros(len(cases[0]))\n",
    "for i in range(len(cases)):\n",
    "    gamma, beta = true_params(cases[i], recovered, deaths[i], pop[i])\n",
    "    gamma_lst.append(gamma)\n",
    "    beta_lst.append(beta)\n",
    "gamma_lst = np.stack(gamma_lst,0)\n",
    "beta_lst = np.stack(beta_lst,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#keys = df.keys()\n",
    "#for i, val in enumerate(df.iloc[4]):\n",
    "#    print(i, '\\t', keys[i], '\\t', val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "out_size = 1\n",
    "num_days = cases.shape[1]\n",
    "num_valid_days = 15\n",
    "num_test_days = 15\n",
    "train_valid_split = num_days - num_valid_days - num_test_days\n",
    "valid_test_split = num_days - num_test_days\n",
    "in_len = 20\n",
    "out_len = 1\n",
    "\n",
    "train_past_cases_1d = []\n",
    "train_past_deaths_1d = []\n",
    "train_past_gamma_1d = []\n",
    "train_past_beta_1d = []\n",
    "train_labels_cases_1d = []\n",
    "train_labels_deaths_1d = []\n",
    "train_labels_gamma_1d = []\n",
    "train_labels_beta_1d = []\n",
    "\n",
    "# for start in range(14):\n",
    "#     end = start + in_len + out_len - 1\n",
    "#     end_begin = end - out_len\n",
    "#     train_past_cases_1d.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "#     train_past_deaths_1d.append(th.mul(th.tensor(deaths[:,start:end_begin], dtype=th.float32),1))\n",
    "#     train_labels_cases_1d.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "#     train_labels_deaths_1d.append(th.mul(th.tensor(deaths[:,end_begin:end], dtype=th.float32),1))\n",
    "\n",
    "# for start in range(14, train_valid_split - in_len - out_len + 1):\n",
    "#     end = start + in_len + out_len - 1\n",
    "#     end_begin = end - out_len\n",
    "#     train_past_cases_1d.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "#     train_past_deaths_1d.append(th.mul(th.tensor(cases[:,start-14:end_begin-14], dtype=th.float32),1))\n",
    "#     train_labels_cases_1d.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "#     train_labels_deaths_1d.append(th.mul(th.tensor(cases[:,end_begin-14:end-14], dtype=th.float32),1))\n",
    "\n",
    "for start in range(train_valid_split - in_len - out_len + 1):\n",
    "    end = start + in_len + out_len - 1\n",
    "    end_begin = end - out_len\n",
    "    train_past_cases_1d.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "    train_past_deaths_1d.append(th.tensor(deaths[:,start:end_begin], dtype=th.float32))\n",
    "    train_past_gamma_1d.append(th.tensor(gamma_lst[:,start:end_begin], dtype=th.float32))\n",
    "    train_past_beta_1d.append(th.tensor(beta_lst[:,start:end_begin], dtype=th.float32))\n",
    "    train_labels_cases_1d.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "    train_labels_deaths_1d.append(th.tensor(deaths[:,end_begin:end], dtype=th.float32))\n",
    "    train_labels_gamma_1d.append(th.tensor(gamma_lst[:,end_begin:end], dtype=th.float32))\n",
    "    train_labels_beta_1d.append(th.tensor(beta_lst[:,end_begin:end], dtype=th.float32))\n",
    "\n",
    "\n",
    "valid_past_cases_1d = []\n",
    "valid_past_deaths_1d = []\n",
    "valid_past_gamma_1d = []\n",
    "valid_past_beta_1d = []\n",
    "valid_labels_cases_1d = []\n",
    "valid_labels_deaths_1d = []\n",
    "valid_labels_gamma_1d = []\n",
    "valid_labels_beta_1d = []\n",
    "for start in range(train_valid_split - in_len - out_len + 1, valid_test_split - in_len - out_len):\n",
    "    end = start + in_len + out_len - 1\n",
    "    end_begin = end - out_len\n",
    "    valid_past_cases_1d.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "    valid_past_deaths_1d.append(th.mul(th.tensor(deaths[:,start:end_begin], dtype=th.float32),1))\n",
    "    valid_past_gamma_1d.append(th.tensor(gamma_lst[:,start:end_begin], dtype=th.float32))\n",
    "    valid_past_beta_1d.append(th.tensor(beta_lst[:,start:end_begin], dtype=th.float32))\n",
    "    valid_labels_cases_1d.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "    valid_labels_deaths_1d.append(th.mul(th.tensor(deaths[:,end_begin:end], dtype=th.float32),1))\n",
    "    valid_labels_gamma_1d.append(th.tensor(gamma_lst[:,end_begin:end], dtype=th.float32))\n",
    "    valid_labels_beta_1d.append(th.tensor(beta_lst[:,end_begin:end], dtype=th.float32))\n",
    "    \n",
    "test_past_cases_1d = []\n",
    "test_past_deaths_1d = []\n",
    "test_past_gamma_1d = []\n",
    "test_past_beta_1d = []\n",
    "test_labels_cases_1d = []\n",
    "test_labels_deaths_1d = []\n",
    "test_labels_gamma_1d = []\n",
    "test_labels_beta_1d = []\n",
    "for start in range(valid_test_split - in_len - out_len + 1, num_days - in_len - out_len):\n",
    "    end = start + in_len + out_len - 1\n",
    "    end_begin = end - out_len\n",
    "    test_past_cases_1d.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "    test_past_deaths_1d.append(th.mul(th.tensor(deaths[:,start:end_begin], dtype=th.float32),1))\n",
    "    test_past_gamma_1d.append(th.tensor(gamma_lst[:,start:end_begin], dtype=th.float32))\n",
    "    test_past_beta_1d.append(th.tensor(beta_lst[:,start:end_begin], dtype=th.float32))\n",
    "    test_labels_cases_1d.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "    test_labels_deaths_1d.append(th.mul(th.tensor(deaths[:,end_begin:end], dtype=th.float32),1))\n",
    "    test_labels_gamma_1d.append(th.tensor(gamma_lst[:,end_begin:end], dtype=th.float32))\n",
    "    test_labels_beta_1d.append(th.tensor(beta_lst[:,end_begin:end], dtype=th.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_Sacramento = []\n",
    "for i in range(34):\n",
    "    train_labels_Sacramento.append(train_labels_cases_1d[i][202].cpu().numpy())\n",
    "\n",
    "train_labels_NYC = []\n",
    "for i in range(34):\n",
    "    train_labels_NYC.append(train_labels_cases_1d[i][4].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net_SIR(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size):\n",
    "        super(Net_SIR, self).__init__()\n",
    "        self.nn_model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            #nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.nn_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_msle(output, target):\n",
    "    loss = th.mean(((output.add(1)).log() - (target.add(1)).log())**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_msle_ID(I, D, I_label, D_label):\n",
    "    I_loss = ((I.add(1)).log() - (I_label.add(1)).log())**2\n",
    "    D_loss = ((D.add(1)).log() - (D_label.add(1)).log())**2\n",
    "    loss = th.mean(th.add(I_loss, D_loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_1d_output(params, I, D):\n",
    "    gamma = params[:,0]\n",
    "    beta = params[:,1]\n",
    "    I[I != I] = 0.0\n",
    "    D[D != D] = 0.0\n",
    "    err = th.tensor([0],dtype=th.float)\n",
    "    err = err.to(device)\n",
    "    S = pop - I - D\n",
    "\n",
    "    I_new = th.add(th.add(I, th.mul(beta.view(3142,1), th.div(th.mul(S,I), pop))), - th.mul(gamma.view(3142,1), I))\n",
    "    D_new = th.add(D, th.mul(gamma.view(3142,1), I))\n",
    "\n",
    "    return I_new, D_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT - SIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contiguous Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "county_names = df['CountyName']\n",
    "county_code = np.array([int(code) for code in df['countyFIPS']])\n",
    "county_code_dict = {code:idx for idx, code in enumerate(county_code)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_contiguous = pd.read_csv('/home/ubuntu/covid19-severity-prediction/data/neighborcounties.csv')\n",
    "df_contiguous = pd.DataFrame(data_contiguous, columns= ['orgfips','adjfips','instate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "\n",
    "g = dgl.DGLGraph()\n",
    "g.add_nodes(len(county_code_dict))\n",
    "for ind in df_contiguous.index: \n",
    "    src = int(df_contiguous['orgfips'][ind])\n",
    "    dst = int(df_contiguous['adjfips'][ind])\n",
    "    if src in county_code_dict and dst in county_code_dict:\n",
    "        g.add_edge(county_code_dict[src],county_code_dict[dst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import pytorch as dglnn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GAT_SIR(nn.Module):\n",
    "    def __init__(self, g, input_size, hidden_size, output_size, gcn_nlayers, num_heads=5):\n",
    "        super(GAT_SIR, self).__init__()\n",
    "        self.g = g\n",
    "        self.gcn_layers = nn.ModuleList()\n",
    "        self.gcn_layers.append(dglnn.conv.GATConv(input_size, hidden_size, num_heads=num_heads,\n",
    "                                                  residual=True, activation=F.relu))\n",
    "        for i in range(gcn_nlayers):\n",
    "            self.gcn_layers.append(dglnn.conv.GATConv(num_heads * hidden_size, hidden_size, num_heads=num_heads,\n",
    "                                                      residual=True, activation=F.relu))\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(num_heads * hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        for layer in self.gcn_layers:\n",
    "            h = layer(self.g, h).flatten(1)\n",
    "        return self.linear_layers(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - SIR (loss = cases label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 97\n",
      "epoch=0, loss=3.233, validation loss = 5.258, test loss=5.969, test mse = 8303646.500, test mae = 409.080\n",
      "epoch=1, loss=3.080, validation loss = 4.463, test loss=4.794, test mse = 3053318.250, test mae = 230.526\n",
      "epoch=2, loss=2.836, validation loss = 3.818, test loss=4.255, test mse = 54523.105, test mae = 64.724\n",
      "epoch=3, loss=2.638, validation loss = 3.586, test loss=3.978, test mse = 11442.084, test mae = 34.584\n",
      "epoch=4, loss=2.527, validation loss = 3.426, test loss=3.779, test mse = 5112.528, test mae = 23.660\n",
      "epoch=5, loss=2.457, validation loss = 3.302, test loss=3.622, test mse = 3129.805, test mae = 17.672\n",
      "epoch=6, loss=2.400, validation loss = 3.198, test loss=3.491, test mse = 2398.186, test mae = 13.812\n",
      "epoch=7, loss=2.351, validation loss = 3.107, test loss=3.377, test mse = 2068.741, test mae = 11.099\n",
      "epoch=8, loss=2.307, validation loss = 3.025, test loss=3.277, test mse = 1910.262, test mae = 9.153\n",
      "epoch=9, loss=2.266, validation loss = 2.951, test loss=3.185, test mse = 1837.615, test mae = 8.012\n",
      "epoch=10, loss=2.229, validation loss = 2.883, test loss=3.102, test mse = 1811.320, test mae = 7.769\n",
      "epoch=11, loss=2.194, validation loss = 2.820, test loss=3.025, test mse = 1809.932, test mae = 8.042\n",
      "epoch=12, loss=2.161, validation loss = 2.761, test loss=2.954, test mse = 1821.279, test mae = 8.549\n",
      "epoch=13, loss=2.130, validation loss = 2.706, test loss=2.887, test mse = 1838.864, test mae = 9.130\n",
      "epoch=14, loss=2.100, validation loss = 2.654, test loss=2.824, test mse = 1859.210, test mae = 9.704\n",
      "epoch=15, loss=2.072, validation loss = 2.606, test loss=2.764, test mse = 1880.439, test mae = 10.251\n",
      "epoch=16, loss=2.045, validation loss = 2.559, test loss=2.708, test mse = 1901.439, test mae = 10.760\n",
      "epoch=17, loss=2.019, validation loss = 2.515, test loss=2.654, test mse = 1921.632, test mae = 11.229\n",
      "epoch=18, loss=1.995, validation loss = 2.472, test loss=2.603, test mse = 1940.644, test mae = 11.659\n",
      "epoch=19, loss=1.971, validation loss = 2.432, test loss=2.554, test mse = 1958.195, test mae = 12.050\n",
      "epoch=20, loss=1.948, validation loss = 2.393, test loss=2.508, test mse = 1974.284, test mae = 12.406\n",
      "epoch=21, loss=1.925, validation loss = 2.356, test loss=2.463, test mse = 1988.832, test mae = 12.731\n",
      "epoch=22, loss=1.904, validation loss = 2.320, test loss=2.420, test mse = 2001.892, test mae = 13.028\n",
      "epoch=23, loss=1.883, validation loss = 2.285, test loss=2.379, test mse = 2013.668, test mae = 13.298\n",
      "epoch=24, loss=1.863, validation loss = 2.252, test loss=2.339, test mse = 2024.276, test mae = 13.545\n",
      "epoch=25, loss=1.843, validation loss = 2.219, test loss=2.300, test mse = 2033.716, test mae = 13.770\n",
      "epoch=26, loss=1.824, validation loss = 2.188, test loss=2.263, test mse = 2042.051, test mae = 13.975\n",
      "epoch=27, loss=1.806, validation loss = 2.158, test loss=2.228, test mse = 2049.324, test mae = 14.163\n",
      "epoch=28, loss=1.788, validation loss = 2.128, test loss=2.193, test mse = 2055.611, test mae = 14.334\n",
      "epoch=29, loss=1.770, validation loss = 2.100, test loss=2.160, test mse = 2060.926, test mae = 14.490\n",
      "epoch=30, loss=1.753, validation loss = 2.072, test loss=2.127, test mse = 2065.341, test mae = 14.632\n",
      "epoch=31, loss=1.736, validation loss = 2.045, test loss=2.096, test mse = 2068.989, test mae = 14.761\n",
      "epoch=32, loss=1.720, validation loss = 2.019, test loss=2.065, test mse = 2071.855, test mae = 14.878\n",
      "epoch=33, loss=1.704, validation loss = 1.993, test loss=2.036, test mse = 2074.024, test mae = 14.984\n",
      "epoch=34, loss=1.688, validation loss = 1.968, test loss=2.007, test mse = 2075.564, test mae = 15.080\n",
      "epoch=35, loss=1.673, validation loss = 1.944, test loss=1.979, test mse = 2076.464, test mae = 15.165\n",
      "epoch=36, loss=1.658, validation loss = 1.920, test loss=1.952, test mse = 2076.932, test mae = 15.242\n",
      "epoch=37, loss=1.644, validation loss = 1.897, test loss=1.925, test mse = 2076.883, test mae = 15.310\n",
      "epoch=38, loss=1.629, validation loss = 1.874, test loss=1.900, test mse = 2076.503, test mae = 15.370\n",
      "epoch=39, loss=1.615, validation loss = 1.852, test loss=1.874, test mse = 2075.637, test mae = 15.422\n",
      "epoch=40, loss=1.602, validation loss = 1.831, test loss=1.850, test mse = 2074.293, test mae = 15.467\n",
      "epoch=41, loss=1.588, validation loss = 1.809, test loss=1.826, test mse = 2072.416, test mae = 15.505\n",
      "epoch=42, loss=1.575, validation loss = 1.789, test loss=1.802, test mse = 2070.037, test mae = 15.536\n",
      "epoch=43, loss=1.562, validation loss = 1.769, test loss=1.779, test mse = 2067.281, test mae = 15.561\n",
      "epoch=44, loss=1.550, validation loss = 1.749, test loss=1.757, test mse = 2064.195, test mae = 15.580\n",
      "epoch=45, loss=1.537, validation loss = 1.729, test loss=1.735, test mse = 2060.775, test mae = 15.594\n",
      "epoch=46, loss=1.525, validation loss = 1.710, test loss=1.714, test mse = 2057.050, test mae = 15.601\n",
      "epoch=47, loss=1.513, validation loss = 1.692, test loss=1.693, test mse = 2053.062, test mae = 15.604\n",
      "epoch=48, loss=1.501, validation loss = 1.673, test loss=1.672, test mse = 2048.888, test mae = 15.601\n",
      "epoch=49, loss=1.489, validation loss = 1.655, test loss=1.652, test mse = 2044.488, test mae = 15.594\n",
      "epoch=50, loss=1.478, validation loss = 1.638, test loss=1.632, test mse = 2039.851, test mae = 15.581\n",
      "epoch=51, loss=1.467, validation loss = 1.620, test loss=1.613, test mse = 2035.075, test mae = 15.564\n",
      "epoch=52, loss=1.456, validation loss = 1.603, test loss=1.594, test mse = 2030.043, test mae = 15.543\n",
      "epoch=53, loss=1.445, validation loss = 1.587, test loss=1.575, test mse = 2024.752, test mae = 15.517\n",
      "epoch=54, loss=1.434, validation loss = 1.570, test loss=1.557, test mse = 2019.279, test mae = 15.488\n",
      "epoch=55, loss=1.424, validation loss = 1.554, test loss=1.539, test mse = 2013.617, test mae = 15.454\n",
      "epoch=56, loss=1.413, validation loss = 1.538, test loss=1.521, test mse = 2007.782, test mae = 15.417\n",
      "epoch=57, loss=1.403, validation loss = 1.523, test loss=1.504, test mse = 2001.843, test mae = 15.376\n",
      "epoch=58, loss=1.393, validation loss = 1.507, test loss=1.487, test mse = 1995.781, test mae = 15.332\n",
      "epoch=59, loss=1.383, validation loss = 1.492, test loss=1.470, test mse = 1989.537, test mae = 15.285\n",
      "epoch=60, loss=1.373, validation loss = 1.477, test loss=1.454, test mse = 1983.118, test mae = 15.235\n",
      "epoch=61, loss=1.363, validation loss = 1.463, test loss=1.438, test mse = 1976.630, test mae = 15.182\n",
      "epoch=62, loss=1.354, validation loss = 1.448, test loss=1.422, test mse = 1970.044, test mae = 15.126\n",
      "epoch=63, loss=1.344, validation loss = 1.434, test loss=1.406, test mse = 1963.363, test mae = 15.067\n",
      "epoch=64, loss=1.335, validation loss = 1.420, test loss=1.391, test mse = 1956.641, test mae = 15.006\n",
      "epoch=65, loss=1.326, validation loss = 1.406, test loss=1.376, test mse = 1949.856, test mae = 14.942\n",
      "epoch=66, loss=1.317, validation loss = 1.393, test loss=1.361, test mse = 1942.943, test mae = 14.876\n",
      "epoch=67, loss=1.308, validation loss = 1.380, test loss=1.346, test mse = 1935.933, test mae = 14.807\n",
      "epoch=68, loss=1.299, validation loss = 1.366, test loss=1.332, test mse = 1928.881, test mae = 14.736\n",
      "epoch=69, loss=1.290, validation loss = 1.353, test loss=1.318, test mse = 1921.791, test mae = 14.664\n",
      "epoch=70, loss=1.282, validation loss = 1.341, test loss=1.304, test mse = 1914.648, test mae = 14.590\n",
      "epoch=71, loss=1.273, validation loss = 1.328, test loss=1.290, test mse = 1907.546, test mae = 14.516\n",
      "epoch=72, loss=1.265, validation loss = 1.316, test loss=1.277, test mse = 1900.419, test mae = 14.441\n",
      "epoch=73, loss=1.256, validation loss = 1.303, test loss=1.264, test mse = 1893.320, test mae = 14.365\n",
      "epoch=74, loss=1.248, validation loss = 1.291, test loss=1.251, test mse = 1886.263, test mae = 14.289\n",
      "epoch=75, loss=1.240, validation loss = 1.279, test loss=1.238, test mse = 1879.223, test mae = 14.213\n",
      "epoch=76, loss=1.232, validation loss = 1.268, test loss=1.225, test mse = 1872.162, test mae = 14.136\n",
      "epoch=77, loss=1.224, validation loss = 1.256, test loss=1.213, test mse = 1865.316, test mae = 14.060\n",
      "epoch=78, loss=1.216, validation loss = 1.245, test loss=1.200, test mse = 1858.605, test mae = 13.985\n",
      "epoch=79, loss=1.208, validation loss = 1.233, test loss=1.188, test mse = 1851.987, test mae = 13.910\n",
      "epoch=80, loss=1.201, validation loss = 1.222, test loss=1.176, test mse = 1845.750, test mae = 13.835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=81, loss=1.193, validation loss = 1.211, test loss=1.165, test mse = 1839.713, test mae = 13.762\n",
      "epoch=82, loss=1.186, validation loss = 1.200, test loss=1.153, test mse = 1833.792, test mae = 13.688\n",
      "epoch=83, loss=1.178, validation loss = 1.190, test loss=1.142, test mse = 1827.991, test mae = 13.616\n",
      "epoch=84, loss=1.171, validation loss = 1.179, test loss=1.131, test mse = 1822.318, test mae = 13.544\n",
      "epoch=85, loss=1.164, validation loss = 1.169, test loss=1.119, test mse = 1816.878, test mae = 13.474\n",
      "epoch=86, loss=1.156, validation loss = 1.158, test loss=1.108, test mse = 1811.583, test mae = 13.405\n",
      "epoch=87, loss=1.149, validation loss = 1.148, test loss=1.098, test mse = 1806.421, test mae = 13.337\n",
      "epoch=88, loss=1.142, validation loss = 1.138, test loss=1.087, test mse = 1801.405, test mae = 13.271\n",
      "epoch=89, loss=1.135, validation loss = 1.128, test loss=1.076, test mse = 1796.526, test mae = 13.206\n",
      "epoch=90, loss=1.128, validation loss = 1.118, test loss=1.066, test mse = 1791.745, test mae = 13.142\n",
      "epoch=91, loss=1.121, validation loss = 1.109, test loss=1.056, test mse = 1787.105, test mae = 13.079\n",
      "epoch=92, loss=1.115, validation loss = 1.099, test loss=1.046, test mse = 1782.599, test mae = 13.018\n",
      "epoch=93, loss=1.108, validation loss = 1.089, test loss=1.036, test mse = 1778.224, test mae = 12.957\n",
      "epoch=94, loss=1.101, validation loss = 1.080, test loss=1.026, test mse = 1773.999, test mae = 12.898\n",
      "epoch=95, loss=1.095, validation loss = 1.071, test loss=1.016, test mse = 1769.877, test mae = 12.840\n",
      "epoch=96, loss=1.088, validation loss = 1.062, test loss=1.006, test mse = 1765.856, test mae = 12.782\n",
      "epoch=97, loss=1.082, validation loss = 1.052, test loss=0.997, test mse = 1761.952, test mae = 12.726\n",
      "epoch=98, loss=1.075, validation loss = 1.043, test loss=0.988, test mse = 1758.161, test mae = 12.670\n",
      "epoch=99, loss=1.069, validation loss = 1.035, test loss=0.978, test mse = 1754.597, test mae = 12.615\n",
      "epoch=100, loss=1.063, validation loss = 1.026, test loss=0.969, test mse = 1751.190, test mae = 12.562\n",
      "epoch=101, loss=1.056, validation loss = 1.017, test loss=0.960, test mse = 1747.927, test mae = 12.509\n",
      "epoch=102, loss=1.050, validation loss = 1.009, test loss=0.951, test mse = 1744.731, test mae = 12.457\n",
      "epoch=103, loss=1.044, validation loss = 1.000, test loss=0.943, test mse = 1741.634, test mae = 12.407\n",
      "epoch=104, loss=1.038, validation loss = 0.992, test loss=0.934, test mse = 1738.634, test mae = 12.357\n",
      "epoch=105, loss=1.032, validation loss = 0.984, test loss=0.925, test mse = 1735.736, test mae = 12.308\n",
      "epoch=106, loss=1.026, validation loss = 0.975, test loss=0.917, test mse = 1732.925, test mae = 12.261\n",
      "epoch=107, loss=1.020, validation loss = 0.967, test loss=0.909, test mse = 1730.119, test mae = 12.216\n",
      "epoch=108, loss=1.014, validation loss = 0.959, test loss=0.900, test mse = 1727.421, test mae = 12.172\n",
      "epoch=109, loss=1.008, validation loss = 0.951, test loss=0.892, test mse = 1724.824, test mae = 12.130\n",
      "epoch=110, loss=1.003, validation loss = 0.944, test loss=0.884, test mse = 1722.321, test mae = 12.090\n",
      "epoch=111, loss=0.997, validation loss = 0.936, test loss=0.876, test mse = 1719.922, test mae = 12.050\n",
      "epoch=112, loss=0.991, validation loss = 0.928, test loss=0.869, test mse = 1717.609, test mae = 12.012\n",
      "epoch=113, loss=0.986, validation loss = 0.921, test loss=0.861, test mse = 1715.377, test mae = 11.974\n",
      "epoch=114, loss=0.980, validation loss = 0.913, test loss=0.854, test mse = 1713.213, test mae = 11.938\n",
      "epoch=115, loss=0.975, validation loss = 0.906, test loss=0.846, test mse = 1711.145, test mae = 11.902\n",
      "epoch=116, loss=0.969, validation loss = 0.899, test loss=0.839, test mse = 1709.145, test mae = 11.868\n",
      "epoch=117, loss=0.964, validation loss = 0.892, test loss=0.831, test mse = 1707.203, test mae = 11.834\n",
      "epoch=118, loss=0.958, validation loss = 0.885, test loss=0.824, test mse = 1705.312, test mae = 11.802\n",
      "epoch=119, loss=0.953, validation loss = 0.878, test loss=0.817, test mse = 1703.472, test mae = 11.769\n",
      "epoch=120, loss=0.948, validation loss = 0.871, test loss=0.810, test mse = 1701.679, test mae = 11.738\n",
      "epoch=121, loss=0.943, validation loss = 0.864, test loss=0.803, test mse = 1699.929, test mae = 11.707\n",
      "epoch=122, loss=0.937, validation loss = 0.857, test loss=0.796, test mse = 1698.223, test mae = 11.676\n",
      "epoch=123, loss=0.932, validation loss = 0.850, test loss=0.789, test mse = 1696.557, test mae = 11.646\n",
      "epoch=124, loss=0.927, validation loss = 0.844, test loss=0.783, test mse = 1694.930, test mae = 11.616\n",
      "epoch=125, loss=0.922, validation loss = 0.837, test loss=0.776, test mse = 1693.341, test mae = 11.586\n",
      "epoch=126, loss=0.917, validation loss = 0.831, test loss=0.769, test mse = 1691.789, test mae = 11.557\n",
      "epoch=127, loss=0.912, validation loss = 0.824, test loss=0.763, test mse = 1690.278, test mae = 11.529\n",
      "epoch=128, loss=0.907, validation loss = 0.818, test loss=0.757, test mse = 1688.802, test mae = 11.501\n",
      "epoch=129, loss=0.902, validation loss = 0.811, test loss=0.750, test mse = 1687.363, test mae = 11.473\n",
      "epoch=130, loss=0.897, validation loss = 0.805, test loss=0.744, test mse = 1685.957, test mae = 11.446\n",
      "epoch=131, loss=0.892, validation loss = 0.799, test loss=0.738, test mse = 1684.586, test mae = 11.419\n",
      "epoch=132, loss=0.887, validation loss = 0.793, test loss=0.731, test mse = 1683.245, test mae = 11.393\n",
      "epoch=133, loss=0.883, validation loss = 0.787, test loss=0.725, test mse = 1681.883, test mae = 11.367\n",
      "epoch=134, loss=0.878, validation loss = 0.781, test loss=0.719, test mse = 1680.555, test mae = 11.342\n",
      "epoch=135, loss=0.873, validation loss = 0.775, test loss=0.713, test mse = 1679.266, test mae = 11.317\n",
      "epoch=136, loss=0.868, validation loss = 0.769, test loss=0.707, test mse = 1678.008, test mae = 11.292\n",
      "epoch=137, loss=0.864, validation loss = 0.763, test loss=0.702, test mse = 1676.784, test mae = 11.267\n",
      "epoch=138, loss=0.859, validation loss = 0.757, test loss=0.696, test mse = 1675.590, test mae = 11.244\n",
      "epoch=139, loss=0.855, validation loss = 0.751, test loss=0.690, test mse = 1674.419, test mae = 11.220\n",
      "epoch=140, loss=0.850, validation loss = 0.746, test loss=0.684, test mse = 1673.275, test mae = 11.197\n",
      "epoch=141, loss=0.845, validation loss = 0.740, test loss=0.679, test mse = 1672.138, test mae = 11.174\n",
      "epoch=142, loss=0.841, validation loss = 0.734, test loss=0.673, test mse = 1671.017, test mae = 11.151\n",
      "epoch=143, loss=0.836, validation loss = 0.729, test loss=0.668, test mse = 1669.929, test mae = 11.129\n",
      "epoch=144, loss=0.832, validation loss = 0.723, test loss=0.662, test mse = 1668.868, test mae = 11.107\n",
      "epoch=145, loss=0.828, validation loss = 0.718, test loss=0.657, test mse = 1667.830, test mae = 11.085\n",
      "epoch=146, loss=0.823, validation loss = 0.713, test loss=0.651, test mse = 1666.818, test mae = 11.064\n",
      "epoch=147, loss=0.819, validation loss = 0.707, test loss=0.646, test mse = 1665.826, test mae = 11.043\n",
      "epoch=148, loss=0.815, validation loss = 0.702, test loss=0.641, test mse = 1664.855, test mae = 11.021\n",
      "epoch=149, loss=0.810, validation loss = 0.697, test loss=0.635, test mse = 1663.905, test mae = 11.001\n",
      "epoch=150, loss=0.806, validation loss = 0.691, test loss=0.630, test mse = 1662.973, test mae = 10.980\n",
      "epoch=151, loss=0.802, validation loss = 0.686, test loss=0.625, test mse = 1662.052, test mae = 10.959\n",
      "epoch=152, loss=0.797, validation loss = 0.681, test loss=0.620, test mse = 1661.152, test mae = 10.939\n",
      "epoch=153, loss=0.793, validation loss = 0.676, test loss=0.615, test mse = 1660.276, test mae = 10.919\n",
      "epoch=154, loss=0.789, validation loss = 0.671, test loss=0.610, test mse = 1659.419, test mae = 10.899\n",
      "epoch=155, loss=0.785, validation loss = 0.666, test loss=0.605, test mse = 1658.578, test mae = 10.880\n",
      "epoch=156, loss=0.781, validation loss = 0.661, test loss=0.600, test mse = 1657.753, test mae = 10.861\n",
      "epoch=157, loss=0.777, validation loss = 0.656, test loss=0.595, test mse = 1656.943, test mae = 10.842\n",
      "epoch=158, loss=0.773, validation loss = 0.651, test loss=0.591, test mse = 1656.150, test mae = 10.823\n",
      "epoch=159, loss=0.769, validation loss = 0.646, test loss=0.586, test mse = 1655.373, test mae = 10.805\n",
      "epoch=160, loss=0.764, validation loss = 0.642, test loss=0.581, test mse = 1654.611, test mae = 10.787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=161, loss=0.760, validation loss = 0.637, test loss=0.576, test mse = 1653.863, test mae = 10.769\n",
      "epoch=162, loss=0.756, validation loss = 0.632, test loss=0.572, test mse = 1653.127, test mae = 10.752\n",
      "epoch=163, loss=0.753, validation loss = 0.627, test loss=0.567, test mse = 1652.403, test mae = 10.735\n",
      "epoch=164, loss=0.749, validation loss = 0.623, test loss=0.563, test mse = 1651.690, test mae = 10.718\n",
      "epoch=165, loss=0.745, validation loss = 0.618, test loss=0.558, test mse = 1650.989, test mae = 10.701\n",
      "epoch=166, loss=0.741, validation loss = 0.614, test loss=0.554, test mse = 1650.298, test mae = 10.685\n",
      "epoch=167, loss=0.737, validation loss = 0.609, test loss=0.549, test mse = 1649.618, test mae = 10.669\n",
      "epoch=168, loss=0.733, validation loss = 0.605, test loss=0.545, test mse = 1648.949, test mae = 10.653\n",
      "epoch=169, loss=0.729, validation loss = 0.600, test loss=0.540, test mse = 1648.290, test mae = 10.637\n",
      "epoch=170, loss=0.725, validation loss = 0.596, test loss=0.536, test mse = 1647.641, test mae = 10.621\n",
      "epoch=171, loss=0.722, validation loss = 0.591, test loss=0.532, test mse = 1647.003, test mae = 10.606\n",
      "epoch=172, loss=0.718, validation loss = 0.587, test loss=0.528, test mse = 1646.377, test mae = 10.591\n",
      "epoch=173, loss=0.714, validation loss = 0.583, test loss=0.523, test mse = 1645.762, test mae = 10.576\n",
      "epoch=174, loss=0.710, validation loss = 0.579, test loss=0.519, test mse = 1645.158, test mae = 10.562\n",
      "epoch=175, loss=0.707, validation loss = 0.574, test loss=0.515, test mse = 1644.564, test mae = 10.548\n",
      "epoch=176, loss=0.703, validation loss = 0.570, test loss=0.511, test mse = 1643.978, test mae = 10.534\n",
      "epoch=177, loss=0.699, validation loss = 0.566, test loss=0.507, test mse = 1643.401, test mae = 10.520\n",
      "epoch=178, loss=0.696, validation loss = 0.562, test loss=0.503, test mse = 1642.832, test mae = 10.507\n",
      "epoch=179, loss=0.692, validation loss = 0.558, test loss=0.499, test mse = 1642.269, test mae = 10.493\n",
      "epoch=180, loss=0.688, validation loss = 0.554, test loss=0.495, test mse = 1641.715, test mae = 10.480\n",
      "epoch=181, loss=0.685, validation loss = 0.550, test loss=0.491, test mse = 1641.170, test mae = 10.467\n",
      "epoch=182, loss=0.681, validation loss = 0.546, test loss=0.487, test mse = 1640.633, test mae = 10.454\n",
      "epoch=183, loss=0.678, validation loss = 0.542, test loss=0.483, test mse = 1640.101, test mae = 10.442\n",
      "epoch=184, loss=0.674, validation loss = 0.538, test loss=0.479, test mse = 1639.577, test mae = 10.430\n",
      "epoch=185, loss=0.671, validation loss = 0.534, test loss=0.476, test mse = 1639.060, test mae = 10.417\n",
      "epoch=186, loss=0.667, validation loss = 0.530, test loss=0.472, test mse = 1638.551, test mae = 10.405\n",
      "epoch=187, loss=0.664, validation loss = 0.526, test loss=0.468, test mse = 1638.049, test mae = 10.394\n",
      "epoch=188, loss=0.660, validation loss = 0.522, test loss=0.464, test mse = 1637.555, test mae = 10.382\n",
      "epoch=189, loss=0.657, validation loss = 0.518, test loss=0.461, test mse = 1637.068, test mae = 10.370\n",
      "epoch=190, loss=0.653, validation loss = 0.514, test loss=0.457, test mse = 1636.589, test mae = 10.359\n",
      "epoch=191, loss=0.650, validation loss = 0.511, test loss=0.453, test mse = 1636.116, test mae = 10.348\n",
      "epoch=192, loss=0.647, validation loss = 0.507, test loss=0.450, test mse = 1635.650, test mae = 10.336\n",
      "epoch=193, loss=0.643, validation loss = 0.503, test loss=0.446, test mse = 1635.188, test mae = 10.325\n",
      "epoch=194, loss=0.640, validation loss = 0.499, test loss=0.443, test mse = 1634.727, test mae = 10.314\n",
      "epoch=195, loss=0.636, validation loss = 0.496, test loss=0.439, test mse = 1634.268, test mae = 10.303\n",
      "epoch=196, loss=0.633, validation loss = 0.492, test loss=0.435, test mse = 1633.811, test mae = 10.291\n",
      "epoch=197, loss=0.630, validation loss = 0.488, test loss=0.432, test mse = 1633.354, test mae = 10.280\n",
      "epoch=198, loss=0.626, validation loss = 0.485, test loss=0.428, test mse = 1632.896, test mae = 10.268\n",
      "epoch=199, loss=0.623, validation loss = 0.481, test loss=0.425, test mse = 1632.436, test mae = 10.256\n",
      "epoch=200, loss=0.620, validation loss = 0.478, test loss=0.421, test mse = 1631.971, test mae = 10.244\n",
      "epoch=201, loss=0.617, validation loss = 0.474, test loss=0.418, test mse = 1631.503, test mae = 10.231\n",
      "epoch=202, loss=0.613, validation loss = 0.470, test loss=0.415, test mse = 1631.034, test mae = 10.218\n",
      "epoch=203, loss=0.610, validation loss = 0.467, test loss=0.411, test mse = 1630.564, test mae = 10.204\n",
      "epoch=204, loss=0.607, validation loss = 0.463, test loss=0.408, test mse = 1630.093, test mae = 10.191\n",
      "epoch=205, loss=0.604, validation loss = 0.460, test loss=0.404, test mse = 1629.620, test mae = 10.177\n",
      "epoch=206, loss=0.600, validation loss = 0.456, test loss=0.401, test mse = 1629.147, test mae = 10.163\n",
      "epoch=207, loss=0.597, validation loss = 0.453, test loss=0.398, test mse = 1628.672, test mae = 10.148\n",
      "epoch=208, loss=0.594, validation loss = 0.450, test loss=0.394, test mse = 1628.194, test mae = 10.134\n",
      "epoch=209, loss=0.591, validation loss = 0.446, test loss=0.391, test mse = 1627.715, test mae = 10.119\n",
      "epoch=210, loss=0.588, validation loss = 0.443, test loss=0.388, test mse = 1627.234, test mae = 10.104\n",
      "epoch=211, loss=0.585, validation loss = 0.439, test loss=0.385, test mse = 1626.753, test mae = 10.089\n",
      "epoch=212, loss=0.581, validation loss = 0.436, test loss=0.382, test mse = 1626.272, test mae = 10.073\n",
      "epoch=213, loss=0.578, validation loss = 0.433, test loss=0.378, test mse = 1625.791, test mae = 10.058\n",
      "epoch=214, loss=0.575, validation loss = 0.430, test loss=0.375, test mse = 1625.310, test mae = 10.043\n",
      "epoch=215, loss=0.572, validation loss = 0.426, test loss=0.372, test mse = 1624.832, test mae = 10.027\n",
      "epoch=216, loss=0.569, validation loss = 0.423, test loss=0.369, test mse = 1624.358, test mae = 10.012\n",
      "epoch=217, loss=0.566, validation loss = 0.420, test loss=0.366, test mse = 1623.889, test mae = 9.996\n",
      "epoch=218, loss=0.563, validation loss = 0.417, test loss=0.363, test mse = 1623.424, test mae = 9.981\n",
      "epoch=219, loss=0.560, validation loss = 0.413, test loss=0.360, test mse = 1622.964, test mae = 9.965\n",
      "epoch=220, loss=0.557, validation loss = 0.410, test loss=0.357, test mse = 1622.507, test mae = 9.950\n",
      "epoch=221, loss=0.554, validation loss = 0.407, test loss=0.354, test mse = 1622.054, test mae = 9.934\n",
      "epoch=222, loss=0.551, validation loss = 0.404, test loss=0.351, test mse = 1621.608, test mae = 9.919\n",
      "epoch=223, loss=0.548, validation loss = 0.401, test loss=0.348, test mse = 1621.169, test mae = 9.904\n",
      "epoch=224, loss=0.545, validation loss = 0.398, test loss=0.345, test mse = 1620.737, test mae = 9.889\n",
      "epoch=225, loss=0.542, validation loss = 0.395, test loss=0.342, test mse = 1620.310, test mae = 9.874\n",
      "epoch=226, loss=0.539, validation loss = 0.392, test loss=0.340, test mse = 1619.887, test mae = 9.859\n",
      "epoch=227, loss=0.536, validation loss = 0.389, test loss=0.337, test mse = 1619.472, test mae = 9.844\n",
      "epoch=228, loss=0.533, validation loss = 0.386, test loss=0.334, test mse = 1619.063, test mae = 9.829\n",
      "epoch=229, loss=0.530, validation loss = 0.383, test loss=0.331, test mse = 1618.661, test mae = 9.815\n",
      "epoch=230, loss=0.527, validation loss = 0.380, test loss=0.328, test mse = 1618.266, test mae = 9.801\n",
      "epoch=231, loss=0.524, validation loss = 0.377, test loss=0.326, test mse = 1617.878, test mae = 9.787\n",
      "epoch=232, loss=0.522, validation loss = 0.375, test loss=0.323, test mse = 1617.496, test mae = 9.773\n",
      "epoch=233, loss=0.519, validation loss = 0.372, test loss=0.320, test mse = 1617.120, test mae = 9.759\n",
      "epoch=234, loss=0.516, validation loss = 0.369, test loss=0.318, test mse = 1616.751, test mae = 9.745\n",
      "epoch=235, loss=0.513, validation loss = 0.366, test loss=0.315, test mse = 1616.387, test mae = 9.732\n",
      "epoch=236, loss=0.510, validation loss = 0.363, test loss=0.312, test mse = 1616.029, test mae = 9.718\n",
      "epoch=237, loss=0.507, validation loss = 0.361, test loss=0.310, test mse = 1615.677, test mae = 9.705\n",
      "epoch=238, loss=0.505, validation loss = 0.358, test loss=0.307, test mse = 1615.326, test mae = 9.692\n",
      "epoch=239, loss=0.502, validation loss = 0.355, test loss=0.305, test mse = 1614.981, test mae = 9.679\n",
      "epoch=240, loss=0.499, validation loss = 0.352, test loss=0.302, test mse = 1614.640, test mae = 9.666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=241, loss=0.496, validation loss = 0.350, test loss=0.300, test mse = 1614.306, test mae = 9.653\n",
      "epoch=242, loss=0.494, validation loss = 0.347, test loss=0.297, test mse = 1613.977, test mae = 9.640\n",
      "epoch=243, loss=0.491, validation loss = 0.344, test loss=0.295, test mse = 1613.654, test mae = 9.628\n",
      "epoch=244, loss=0.488, validation loss = 0.342, test loss=0.292, test mse = 1613.335, test mae = 9.615\n",
      "epoch=245, loss=0.486, validation loss = 0.339, test loss=0.290, test mse = 1613.020, test mae = 9.603\n",
      "epoch=246, loss=0.483, validation loss = 0.336, test loss=0.287, test mse = 1612.712, test mae = 9.591\n",
      "epoch=247, loss=0.480, validation loss = 0.334, test loss=0.285, test mse = 1612.409, test mae = 9.578\n",
      "epoch=248, loss=0.478, validation loss = 0.331, test loss=0.282, test mse = 1612.114, test mae = 9.566\n",
      "epoch=249, loss=0.475, validation loss = 0.329, test loss=0.280, test mse = 1611.823, test mae = 9.554\n",
      "epoch=250, loss=0.472, validation loss = 0.326, test loss=0.278, test mse = 1611.538, test mae = 9.542\n",
      "epoch=251, loss=0.470, validation loss = 0.324, test loss=0.275, test mse = 1611.258, test mae = 9.531\n",
      "epoch=252, loss=0.467, validation loss = 0.321, test loss=0.273, test mse = 1610.983, test mae = 9.519\n",
      "epoch=253, loss=0.465, validation loss = 0.319, test loss=0.271, test mse = 1610.713, test mae = 9.508\n",
      "epoch=254, loss=0.462, validation loss = 0.316, test loss=0.268, test mse = 1610.448, test mae = 9.496\n",
      "epoch=255, loss=0.459, validation loss = 0.314, test loss=0.266, test mse = 1610.188, test mae = 9.485\n",
      "epoch=256, loss=0.457, validation loss = 0.312, test loss=0.264, test mse = 1609.933, test mae = 9.474\n",
      "epoch=257, loss=0.454, validation loss = 0.309, test loss=0.262, test mse = 1609.684, test mae = 9.463\n",
      "epoch=258, loss=0.452, validation loss = 0.307, test loss=0.260, test mse = 1609.440, test mae = 9.452\n",
      "epoch=259, loss=0.449, validation loss = 0.304, test loss=0.257, test mse = 1609.203, test mae = 9.441\n",
      "epoch=260, loss=0.447, validation loss = 0.302, test loss=0.255, test mse = 1608.971, test mae = 9.431\n",
      "epoch=261, loss=0.444, validation loss = 0.300, test loss=0.253, test mse = 1608.746, test mae = 9.420\n",
      "epoch=262, loss=0.442, validation loss = 0.297, test loss=0.251, test mse = 1608.527, test mae = 9.410\n",
      "epoch=263, loss=0.439, validation loss = 0.295, test loss=0.249, test mse = 1608.312, test mae = 9.400\n",
      "epoch=264, loss=0.437, validation loss = 0.293, test loss=0.247, test mse = 1608.102, test mae = 9.390\n",
      "epoch=265, loss=0.434, validation loss = 0.291, test loss=0.245, test mse = 1607.895, test mae = 9.380\n",
      "epoch=266, loss=0.432, validation loss = 0.288, test loss=0.243, test mse = 1607.692, test mae = 9.370\n",
      "epoch=267, loss=0.430, validation loss = 0.286, test loss=0.241, test mse = 1607.493, test mae = 9.361\n",
      "epoch=268, loss=0.427, validation loss = 0.284, test loss=0.239, test mse = 1607.297, test mae = 9.351\n",
      "epoch=269, loss=0.425, validation loss = 0.282, test loss=0.237, test mse = 1607.103, test mae = 9.342\n",
      "epoch=270, loss=0.422, validation loss = 0.279, test loss=0.235, test mse = 1606.912, test mae = 9.333\n",
      "epoch=271, loss=0.420, validation loss = 0.277, test loss=0.233, test mse = 1606.722, test mae = 9.323\n",
      "epoch=272, loss=0.418, validation loss = 0.275, test loss=0.231, test mse = 1606.535, test mae = 9.314\n",
      "epoch=273, loss=0.415, validation loss = 0.273, test loss=0.229, test mse = 1606.349, test mae = 9.304\n",
      "epoch=274, loss=0.413, validation loss = 0.271, test loss=0.227, test mse = 1606.166, test mae = 9.295\n",
      "epoch=275, loss=0.410, validation loss = 0.269, test loss=0.225, test mse = 1605.985, test mae = 9.286\n",
      "epoch=276, loss=0.408, validation loss = 0.267, test loss=0.223, test mse = 1605.805, test mae = 9.276\n",
      "epoch=277, loss=0.406, validation loss = 0.265, test loss=0.221, test mse = 1605.628, test mae = 9.267\n",
      "epoch=278, loss=0.403, validation loss = 0.262, test loss=0.219, test mse = 1605.452, test mae = 9.258\n",
      "epoch=279, loss=0.401, validation loss = 0.260, test loss=0.217, test mse = 1605.276, test mae = 9.248\n",
      "epoch=280, loss=0.399, validation loss = 0.258, test loss=0.215, test mse = 1605.103, test mae = 9.239\n",
      "epoch=281, loss=0.397, validation loss = 0.256, test loss=0.214, test mse = 1604.931, test mae = 9.230\n",
      "epoch=282, loss=0.394, validation loss = 0.254, test loss=0.212, test mse = 1604.761, test mae = 9.220\n",
      "epoch=283, loss=0.392, validation loss = 0.252, test loss=0.210, test mse = 1604.594, test mae = 9.211\n",
      "epoch=284, loss=0.390, validation loss = 0.250, test loss=0.208, test mse = 1604.428, test mae = 9.202\n",
      "epoch=285, loss=0.387, validation loss = 0.248, test loss=0.206, test mse = 1604.264, test mae = 9.193\n",
      "epoch=286, loss=0.385, validation loss = 0.246, test loss=0.205, test mse = 1604.102, test mae = 9.184\n",
      "epoch=287, loss=0.383, validation loss = 0.244, test loss=0.203, test mse = 1603.942, test mae = 9.174\n",
      "epoch=288, loss=0.381, validation loss = 0.243, test loss=0.201, test mse = 1603.784, test mae = 9.165\n",
      "epoch=289, loss=0.379, validation loss = 0.241, test loss=0.200, test mse = 1603.627, test mae = 9.156\n",
      "epoch=290, loss=0.376, validation loss = 0.239, test loss=0.198, test mse = 1603.471, test mae = 9.147\n",
      "epoch=291, loss=0.374, validation loss = 0.237, test loss=0.196, test mse = 1603.317, test mae = 9.138\n",
      "epoch=292, loss=0.372, validation loss = 0.235, test loss=0.195, test mse = 1603.165, test mae = 9.129\n",
      "epoch=293, loss=0.370, validation loss = 0.233, test loss=0.193, test mse = 1603.015, test mae = 9.120\n",
      "epoch=294, loss=0.368, validation loss = 0.231, test loss=0.191, test mse = 1602.865, test mae = 9.111\n",
      "epoch=295, loss=0.365, validation loss = 0.229, test loss=0.190, test mse = 1602.718, test mae = 9.102\n",
      "epoch=296, loss=0.363, validation loss = 0.228, test loss=0.188, test mse = 1602.572, test mae = 9.093\n",
      "epoch=297, loss=0.361, validation loss = 0.226, test loss=0.186, test mse = 1602.427, test mae = 9.084\n",
      "epoch=298, loss=0.359, validation loss = 0.224, test loss=0.185, test mse = 1602.284, test mae = 9.076\n",
      "epoch=299, loss=0.357, validation loss = 0.222, test loss=0.183, test mse = 1602.143, test mae = 9.067\n",
      "epoch=300, loss=0.355, validation loss = 0.220, test loss=0.182, test mse = 1602.004, test mae = 9.058\n",
      "epoch=301, loss=0.353, validation loss = 0.219, test loss=0.180, test mse = 1601.865, test mae = 9.049\n",
      "epoch=302, loss=0.351, validation loss = 0.217, test loss=0.179, test mse = 1601.729, test mae = 9.040\n",
      "epoch=303, loss=0.349, validation loss = 0.215, test loss=0.177, test mse = 1601.593, test mae = 9.032\n",
      "epoch=304, loss=0.347, validation loss = 0.214, test loss=0.176, test mse = 1601.460, test mae = 9.023\n",
      "epoch=305, loss=0.344, validation loss = 0.212, test loss=0.174, test mse = 1601.327, test mae = 9.014\n",
      "epoch=306, loss=0.342, validation loss = 0.210, test loss=0.173, test mse = 1601.196, test mae = 9.005\n",
      "epoch=307, loss=0.340, validation loss = 0.208, test loss=0.171, test mse = 1601.067, test mae = 8.997\n",
      "epoch=308, loss=0.338, validation loss = 0.207, test loss=0.170, test mse = 1600.939, test mae = 8.988\n",
      "epoch=309, loss=0.336, validation loss = 0.205, test loss=0.168, test mse = 1600.813, test mae = 8.980\n",
      "epoch=310, loss=0.334, validation loss = 0.203, test loss=0.167, test mse = 1600.688, test mae = 8.971\n",
      "epoch=311, loss=0.332, validation loss = 0.202, test loss=0.165, test mse = 1600.563, test mae = 8.962\n",
      "epoch=312, loss=0.330, validation loss = 0.200, test loss=0.164, test mse = 1600.440, test mae = 8.954\n",
      "epoch=313, loss=0.328, validation loss = 0.199, test loss=0.162, test mse = 1600.318, test mae = 8.945\n",
      "epoch=314, loss=0.326, validation loss = 0.197, test loss=0.161, test mse = 1600.198, test mae = 8.937\n",
      "epoch=315, loss=0.324, validation loss = 0.195, test loss=0.160, test mse = 1600.079, test mae = 8.928\n",
      "epoch=316, loss=0.322, validation loss = 0.194, test loss=0.158, test mse = 1599.961, test mae = 8.920\n",
      "epoch=317, loss=0.321, validation loss = 0.192, test loss=0.157, test mse = 1599.844, test mae = 8.911\n",
      "epoch=318, loss=0.319, validation loss = 0.191, test loss=0.156, test mse = 1599.727, test mae = 8.903\n",
      "epoch=319, loss=0.317, validation loss = 0.189, test loss=0.154, test mse = 1599.612, test mae = 8.895\n",
      "epoch=320, loss=0.315, validation loss = 0.188, test loss=0.153, test mse = 1599.498, test mae = 8.886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=321, loss=0.313, validation loss = 0.186, test loss=0.152, test mse = 1599.385, test mae = 8.878\n",
      "epoch=322, loss=0.311, validation loss = 0.185, test loss=0.150, test mse = 1599.272, test mae = 8.869\n",
      "epoch=323, loss=0.309, validation loss = 0.183, test loss=0.149, test mse = 1599.160, test mae = 8.861\n",
      "epoch=324, loss=0.307, validation loss = 0.182, test loss=0.148, test mse = 1599.049, test mae = 8.852\n",
      "epoch=325, loss=0.305, validation loss = 0.180, test loss=0.147, test mse = 1598.938, test mae = 8.844\n",
      "epoch=326, loss=0.304, validation loss = 0.179, test loss=0.145, test mse = 1598.829, test mae = 8.835\n",
      "epoch=327, loss=0.302, validation loss = 0.177, test loss=0.144, test mse = 1598.720, test mae = 8.827\n",
      "epoch=328, loss=0.300, validation loss = 0.176, test loss=0.143, test mse = 1598.612, test mae = 8.819\n",
      "epoch=329, loss=0.298, validation loss = 0.175, test loss=0.142, test mse = 1598.506, test mae = 8.810\n",
      "epoch=330, loss=0.296, validation loss = 0.173, test loss=0.140, test mse = 1598.400, test mae = 8.802\n",
      "epoch=331, loss=0.294, validation loss = 0.172, test loss=0.139, test mse = 1598.295, test mae = 8.793\n",
      "epoch=332, loss=0.293, validation loss = 0.170, test loss=0.138, test mse = 1598.191, test mae = 8.785\n",
      "epoch=333, loss=0.291, validation loss = 0.169, test loss=0.137, test mse = 1598.088, test mae = 8.777\n",
      "epoch=334, loss=0.289, validation loss = 0.168, test loss=0.136, test mse = 1597.986, test mae = 8.768\n",
      "epoch=335, loss=0.287, validation loss = 0.166, test loss=0.135, test mse = 1597.885, test mae = 8.760\n",
      "epoch=336, loss=0.285, validation loss = 0.165, test loss=0.133, test mse = 1597.785, test mae = 8.752\n",
      "epoch=337, loss=0.284, validation loss = 0.164, test loss=0.132, test mse = 1597.687, test mae = 8.744\n",
      "epoch=338, loss=0.282, validation loss = 0.162, test loss=0.131, test mse = 1597.589, test mae = 8.735\n",
      "epoch=339, loss=0.280, validation loss = 0.161, test loss=0.130, test mse = 1597.492, test mae = 8.727\n",
      "epoch=340, loss=0.279, validation loss = 0.160, test loss=0.129, test mse = 1597.397, test mae = 8.719\n",
      "epoch=341, loss=0.277, validation loss = 0.158, test loss=0.128, test mse = 1597.302, test mae = 8.711\n",
      "epoch=342, loss=0.275, validation loss = 0.157, test loss=0.127, test mse = 1597.209, test mae = 8.703\n",
      "epoch=343, loss=0.273, validation loss = 0.156, test loss=0.126, test mse = 1597.116, test mae = 8.695\n",
      "epoch=344, loss=0.272, validation loss = 0.155, test loss=0.125, test mse = 1597.025, test mae = 8.687\n",
      "epoch=345, loss=0.270, validation loss = 0.153, test loss=0.124, test mse = 1596.934, test mae = 8.679\n",
      "epoch=346, loss=0.268, validation loss = 0.152, test loss=0.122, test mse = 1596.845, test mae = 8.671\n",
      "epoch=347, loss=0.267, validation loss = 0.151, test loss=0.121, test mse = 1596.757, test mae = 8.663\n",
      "epoch=348, loss=0.265, validation loss = 0.150, test loss=0.120, test mse = 1596.670, test mae = 8.655\n",
      "epoch=349, loss=0.263, validation loss = 0.148, test loss=0.119, test mse = 1596.584, test mae = 8.648\n",
      "epoch=350, loss=0.262, validation loss = 0.147, test loss=0.118, test mse = 1596.500, test mae = 8.640\n",
      "epoch=351, loss=0.260, validation loss = 0.146, test loss=0.117, test mse = 1596.416, test mae = 8.632\n",
      "epoch=352, loss=0.259, validation loss = 0.145, test loss=0.116, test mse = 1596.334, test mae = 8.625\n",
      "epoch=353, loss=0.257, validation loss = 0.144, test loss=0.115, test mse = 1596.253, test mae = 8.617\n",
      "epoch=354, loss=0.255, validation loss = 0.143, test loss=0.114, test mse = 1596.174, test mae = 8.610\n",
      "epoch=355, loss=0.254, validation loss = 0.141, test loss=0.113, test mse = 1596.095, test mae = 8.602\n",
      "epoch=356, loss=0.252, validation loss = 0.140, test loss=0.113, test mse = 1596.017, test mae = 8.595\n",
      "epoch=357, loss=0.251, validation loss = 0.139, test loss=0.112, test mse = 1595.941, test mae = 8.588\n",
      "epoch=358, loss=0.249, validation loss = 0.138, test loss=0.111, test mse = 1595.866, test mae = 8.581\n",
      "epoch=359, loss=0.247, validation loss = 0.137, test loss=0.110, test mse = 1595.792, test mae = 8.574\n",
      "epoch=360, loss=0.246, validation loss = 0.136, test loss=0.109, test mse = 1595.719, test mae = 8.567\n",
      "epoch=361, loss=0.244, validation loss = 0.135, test loss=0.108, test mse = 1595.646, test mae = 8.560\n",
      "epoch=362, loss=0.243, validation loss = 0.134, test loss=0.107, test mse = 1595.575, test mae = 8.553\n",
      "epoch=363, loss=0.241, validation loss = 0.133, test loss=0.106, test mse = 1595.504, test mae = 8.546\n",
      "epoch=364, loss=0.240, validation loss = 0.131, test loss=0.105, test mse = 1595.434, test mae = 8.539\n",
      "epoch=365, loss=0.238, validation loss = 0.130, test loss=0.104, test mse = 1595.365, test mae = 8.532\n",
      "epoch=366, loss=0.237, validation loss = 0.129, test loss=0.103, test mse = 1595.297, test mae = 8.526\n",
      "epoch=367, loss=0.235, validation loss = 0.128, test loss=0.103, test mse = 1595.229, test mae = 8.519\n",
      "epoch=368, loss=0.234, validation loss = 0.127, test loss=0.102, test mse = 1595.162, test mae = 8.512\n",
      "epoch=369, loss=0.232, validation loss = 0.126, test loss=0.101, test mse = 1595.096, test mae = 8.506\n",
      "epoch=370, loss=0.231, validation loss = 0.125, test loss=0.100, test mse = 1595.031, test mae = 8.499\n",
      "epoch=371, loss=0.229, validation loss = 0.124, test loss=0.099, test mse = 1594.966, test mae = 8.492\n",
      "epoch=372, loss=0.228, validation loss = 0.123, test loss=0.098, test mse = 1594.902, test mae = 8.486\n",
      "epoch=373, loss=0.226, validation loss = 0.122, test loss=0.098, test mse = 1594.839, test mae = 8.479\n",
      "epoch=374, loss=0.225, validation loss = 0.121, test loss=0.097, test mse = 1594.776, test mae = 8.473\n",
      "epoch=375, loss=0.224, validation loss = 0.120, test loss=0.096, test mse = 1594.714, test mae = 8.466\n",
      "epoch=376, loss=0.222, validation loss = 0.119, test loss=0.095, test mse = 1594.653, test mae = 8.460\n",
      "epoch=377, loss=0.221, validation loss = 0.118, test loss=0.094, test mse = 1594.592, test mae = 8.454\n",
      "epoch=378, loss=0.219, validation loss = 0.118, test loss=0.094, test mse = 1594.532, test mae = 8.447\n",
      "epoch=379, loss=0.218, validation loss = 0.117, test loss=0.093, test mse = 1594.472, test mae = 8.441\n",
      "epoch=380, loss=0.217, validation loss = 0.116, test loss=0.092, test mse = 1594.413, test mae = 8.434\n",
      "epoch=381, loss=0.215, validation loss = 0.115, test loss=0.091, test mse = 1594.354, test mae = 8.428\n",
      "epoch=382, loss=0.214, validation loss = 0.114, test loss=0.091, test mse = 1594.296, test mae = 8.422\n",
      "epoch=383, loss=0.212, validation loss = 0.113, test loss=0.090, test mse = 1594.238, test mae = 8.415\n",
      "epoch=384, loss=0.211, validation loss = 0.112, test loss=0.089, test mse = 1594.180, test mae = 8.409\n",
      "epoch=385, loss=0.210, validation loss = 0.111, test loss=0.088, test mse = 1594.123, test mae = 8.403\n",
      "epoch=386, loss=0.208, validation loss = 0.110, test loss=0.088, test mse = 1594.066, test mae = 8.397\n",
      "epoch=387, loss=0.207, validation loss = 0.109, test loss=0.087, test mse = 1594.010, test mae = 8.390\n",
      "epoch=388, loss=0.206, validation loss = 0.108, test loss=0.086, test mse = 1593.954, test mae = 8.384\n",
      "epoch=389, loss=0.204, validation loss = 0.108, test loss=0.085, test mse = 1593.898, test mae = 8.378\n",
      "epoch=390, loss=0.203, validation loss = 0.107, test loss=0.085, test mse = 1593.843, test mae = 8.372\n",
      "epoch=391, loss=0.202, validation loss = 0.106, test loss=0.084, test mse = 1593.789, test mae = 8.366\n",
      "epoch=392, loss=0.200, validation loss = 0.105, test loss=0.083, test mse = 1593.734, test mae = 8.359\n",
      "epoch=393, loss=0.199, validation loss = 0.104, test loss=0.083, test mse = 1593.680, test mae = 8.353\n",
      "epoch=394, loss=0.198, validation loss = 0.103, test loss=0.082, test mse = 1593.627, test mae = 8.347\n",
      "epoch=395, loss=0.197, validation loss = 0.103, test loss=0.081, test mse = 1593.573, test mae = 8.341\n",
      "epoch=396, loss=0.195, validation loss = 0.102, test loss=0.081, test mse = 1593.521, test mae = 8.335\n",
      "epoch=397, loss=0.194, validation loss = 0.101, test loss=0.080, test mse = 1593.468, test mae = 8.329\n",
      "epoch=398, loss=0.193, validation loss = 0.100, test loss=0.079, test mse = 1593.416, test mae = 8.322\n",
      "epoch=399, loss=0.191, validation loss = 0.099, test loss=0.079, test mse = 1593.364, test mae = 8.316\n",
      "epoch=400, loss=0.190, validation loss = 0.099, test loss=0.078, test mse = 1593.312, test mae = 8.310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=401, loss=0.189, validation loss = 0.098, test loss=0.077, test mse = 1593.261, test mae = 8.304\n",
      "epoch=402, loss=0.188, validation loss = 0.097, test loss=0.077, test mse = 1593.210, test mae = 8.298\n",
      "epoch=403, loss=0.187, validation loss = 0.096, test loss=0.076, test mse = 1593.160, test mae = 8.292\n",
      "epoch=404, loss=0.185, validation loss = 0.095, test loss=0.076, test mse = 1593.109, test mae = 8.286\n",
      "epoch=405, loss=0.184, validation loss = 0.095, test loss=0.075, test mse = 1593.060, test mae = 8.280\n",
      "epoch=406, loss=0.183, validation loss = 0.094, test loss=0.074, test mse = 1593.010, test mae = 8.273\n",
      "epoch=407, loss=0.182, validation loss = 0.093, test loss=0.074, test mse = 1592.961, test mae = 8.267\n",
      "epoch=408, loss=0.180, validation loss = 0.092, test loss=0.073, test mse = 1592.912, test mae = 8.261\n",
      "epoch=409, loss=0.179, validation loss = 0.092, test loss=0.073, test mse = 1592.864, test mae = 8.255\n",
      "epoch=410, loss=0.178, validation loss = 0.091, test loss=0.072, test mse = 1592.816, test mae = 8.249\n",
      "epoch=411, loss=0.177, validation loss = 0.090, test loss=0.071, test mse = 1592.768, test mae = 8.243\n",
      "epoch=412, loss=0.176, validation loss = 0.090, test loss=0.071, test mse = 1592.720, test mae = 8.237\n",
      "epoch=413, loss=0.175, validation loss = 0.089, test loss=0.070, test mse = 1592.674, test mae = 8.231\n",
      "epoch=414, loss=0.173, validation loss = 0.088, test loss=0.070, test mse = 1592.627, test mae = 8.225\n",
      "epoch=415, loss=0.172, validation loss = 0.087, test loss=0.069, test mse = 1592.580, test mae = 8.219\n",
      "epoch=416, loss=0.171, validation loss = 0.087, test loss=0.069, test mse = 1592.534, test mae = 8.213\n",
      "epoch=417, loss=0.170, validation loss = 0.086, test loss=0.068, test mse = 1592.488, test mae = 8.207\n",
      "epoch=418, loss=0.169, validation loss = 0.085, test loss=0.067, test mse = 1592.443, test mae = 8.201\n",
      "epoch=419, loss=0.168, validation loss = 0.085, test loss=0.067, test mse = 1592.398, test mae = 8.195\n",
      "epoch=420, loss=0.167, validation loss = 0.084, test loss=0.066, test mse = 1592.353, test mae = 8.189\n",
      "epoch=421, loss=0.165, validation loss = 0.083, test loss=0.066, test mse = 1592.308, test mae = 8.183\n",
      "epoch=422, loss=0.164, validation loss = 0.083, test loss=0.065, test mse = 1592.264, test mae = 8.177\n",
      "epoch=423, loss=0.163, validation loss = 0.082, test loss=0.065, test mse = 1592.221, test mae = 8.171\n",
      "epoch=424, loss=0.162, validation loss = 0.081, test loss=0.064, test mse = 1592.177, test mae = 8.165\n",
      "epoch=425, loss=0.161, validation loss = 0.081, test loss=0.064, test mse = 1592.134, test mae = 8.159\n",
      "epoch=426, loss=0.160, validation loss = 0.080, test loss=0.063, test mse = 1592.091, test mae = 8.153\n",
      "epoch=427, loss=0.159, validation loss = 0.079, test loss=0.063, test mse = 1592.048, test mae = 8.147\n",
      "epoch=428, loss=0.158, validation loss = 0.079, test loss=0.062, test mse = 1592.006, test mae = 8.141\n",
      "epoch=429, loss=0.157, validation loss = 0.078, test loss=0.062, test mse = 1591.964, test mae = 8.135\n",
      "epoch=430, loss=0.156, validation loss = 0.078, test loss=0.061, test mse = 1591.923, test mae = 8.130\n",
      "epoch=431, loss=0.155, validation loss = 0.077, test loss=0.061, test mse = 1591.881, test mae = 8.124\n",
      "epoch=432, loss=0.154, validation loss = 0.076, test loss=0.060, test mse = 1591.840, test mae = 8.118\n",
      "epoch=433, loss=0.153, validation loss = 0.076, test loss=0.060, test mse = 1591.800, test mae = 8.112\n",
      "epoch=434, loss=0.152, validation loss = 0.075, test loss=0.059, test mse = 1591.759, test mae = 8.106\n",
      "epoch=435, loss=0.151, validation loss = 0.075, test loss=0.059, test mse = 1591.719, test mae = 8.100\n",
      "epoch=436, loss=0.150, validation loss = 0.074, test loss=0.058, test mse = 1591.680, test mae = 8.095\n",
      "epoch=437, loss=0.149, validation loss = 0.073, test loss=0.058, test mse = 1591.640, test mae = 8.089\n",
      "epoch=438, loss=0.148, validation loss = 0.073, test loss=0.057, test mse = 1591.601, test mae = 8.083\n",
      "epoch=439, loss=0.147, validation loss = 0.072, test loss=0.057, test mse = 1591.562, test mae = 8.077\n",
      "epoch=440, loss=0.146, validation loss = 0.072, test loss=0.056, test mse = 1591.523, test mae = 8.072\n",
      "epoch=441, loss=0.145, validation loss = 0.071, test loss=0.056, test mse = 1591.485, test mae = 8.066\n",
      "epoch=442, loss=0.144, validation loss = 0.071, test loss=0.055, test mse = 1591.447, test mae = 8.060\n",
      "epoch=443, loss=0.143, validation loss = 0.070, test loss=0.055, test mse = 1591.409, test mae = 8.054\n",
      "epoch=444, loss=0.142, validation loss = 0.069, test loss=0.055, test mse = 1591.372, test mae = 8.049\n",
      "epoch=445, loss=0.141, validation loss = 0.069, test loss=0.054, test mse = 1591.335, test mae = 8.043\n",
      "epoch=446, loss=0.140, validation loss = 0.068, test loss=0.054, test mse = 1591.298, test mae = 8.037\n",
      "epoch=447, loss=0.139, validation loss = 0.068, test loss=0.053, test mse = 1591.261, test mae = 8.032\n",
      "epoch=448, loss=0.138, validation loss = 0.067, test loss=0.053, test mse = 1591.225, test mae = 8.026\n",
      "epoch=449, loss=0.137, validation loss = 0.067, test loss=0.052, test mse = 1591.189, test mae = 8.020\n",
      "epoch=450, loss=0.136, validation loss = 0.066, test loss=0.052, test mse = 1591.153, test mae = 8.015\n",
      "epoch=451, loss=0.135, validation loss = 0.066, test loss=0.052, test mse = 1591.118, test mae = 8.009\n",
      "epoch=452, loss=0.134, validation loss = 0.065, test loss=0.051, test mse = 1591.083, test mae = 8.003\n",
      "epoch=453, loss=0.133, validation loss = 0.065, test loss=0.051, test mse = 1591.048, test mae = 7.998\n",
      "epoch=454, loss=0.132, validation loss = 0.064, test loss=0.050, test mse = 1591.014, test mae = 7.992\n",
      "epoch=455, loss=0.131, validation loss = 0.064, test loss=0.050, test mse = 1590.979, test mae = 7.986\n",
      "epoch=456, loss=0.130, validation loss = 0.063, test loss=0.050, test mse = 1590.945, test mae = 7.981\n",
      "epoch=457, loss=0.129, validation loss = 0.063, test loss=0.049, test mse = 1590.911, test mae = 7.975\n",
      "epoch=458, loss=0.129, validation loss = 0.062, test loss=0.049, test mse = 1590.878, test mae = 7.970\n",
      "epoch=459, loss=0.128, validation loss = 0.062, test loss=0.048, test mse = 1590.845, test mae = 7.964\n",
      "epoch=460, loss=0.127, validation loss = 0.061, test loss=0.048, test mse = 1590.812, test mae = 7.959\n",
      "epoch=461, loss=0.126, validation loss = 0.061, test loss=0.048, test mse = 1590.779, test mae = 7.953\n",
      "epoch=462, loss=0.125, validation loss = 0.060, test loss=0.047, test mse = 1590.747, test mae = 7.948\n",
      "epoch=463, loss=0.124, validation loss = 0.060, test loss=0.047, test mse = 1590.715, test mae = 7.942\n",
      "epoch=464, loss=0.123, validation loss = 0.059, test loss=0.047, test mse = 1590.683, test mae = 7.937\n",
      "epoch=465, loss=0.123, validation loss = 0.059, test loss=0.046, test mse = 1590.652, test mae = 7.931\n",
      "epoch=466, loss=0.122, validation loss = 0.058, test loss=0.046, test mse = 1590.620, test mae = 7.926\n",
      "epoch=467, loss=0.121, validation loss = 0.058, test loss=0.045, test mse = 1590.590, test mae = 7.920\n",
      "epoch=468, loss=0.120, validation loss = 0.057, test loss=0.045, test mse = 1590.559, test mae = 7.915\n",
      "epoch=469, loss=0.119, validation loss = 0.057, test loss=0.045, test mse = 1590.528, test mae = 7.909\n",
      "epoch=470, loss=0.118, validation loss = 0.057, test loss=0.044, test mse = 1590.498, test mae = 7.904\n",
      "epoch=471, loss=0.118, validation loss = 0.056, test loss=0.044, test mse = 1590.469, test mae = 7.898\n",
      "epoch=472, loss=0.117, validation loss = 0.056, test loss=0.044, test mse = 1590.439, test mae = 7.893\n",
      "epoch=473, loss=0.116, validation loss = 0.055, test loss=0.043, test mse = 1590.409, test mae = 7.888\n",
      "epoch=474, loss=0.115, validation loss = 0.055, test loss=0.043, test mse = 1590.380, test mae = 7.882\n",
      "epoch=475, loss=0.114, validation loss = 0.054, test loss=0.043, test mse = 1590.351, test mae = 7.877\n",
      "epoch=476, loss=0.114, validation loss = 0.054, test loss=0.042, test mse = 1590.323, test mae = 7.872\n",
      "epoch=477, loss=0.113, validation loss = 0.054, test loss=0.042, test mse = 1590.294, test mae = 7.867\n",
      "epoch=478, loss=0.112, validation loss = 0.053, test loss=0.042, test mse = 1590.266, test mae = 7.861\n",
      "epoch=479, loss=0.111, validation loss = 0.053, test loss=0.041, test mse = 1590.238, test mae = 7.856\n",
      "epoch=480, loss=0.111, validation loss = 0.052, test loss=0.041, test mse = 1590.211, test mae = 7.851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=481, loss=0.110, validation loss = 0.052, test loss=0.041, test mse = 1590.183, test mae = 7.845\n",
      "epoch=482, loss=0.109, validation loss = 0.052, test loss=0.040, test mse = 1590.156, test mae = 7.840\n",
      "epoch=483, loss=0.108, validation loss = 0.051, test loss=0.040, test mse = 1590.130, test mae = 7.835\n",
      "epoch=484, loss=0.108, validation loss = 0.051, test loss=0.040, test mse = 1590.103, test mae = 7.830\n",
      "epoch=485, loss=0.107, validation loss = 0.050, test loss=0.040, test mse = 1590.077, test mae = 7.825\n",
      "epoch=486, loss=0.106, validation loss = 0.050, test loss=0.039, test mse = 1590.051, test mae = 7.820\n",
      "epoch=487, loss=0.105, validation loss = 0.050, test loss=0.039, test mse = 1590.025, test mae = 7.814\n",
      "epoch=488, loss=0.105, validation loss = 0.049, test loss=0.039, test mse = 1589.999, test mae = 7.809\n",
      "epoch=489, loss=0.104, validation loss = 0.049, test loss=0.038, test mse = 1589.974, test mae = 7.804\n",
      "epoch=490, loss=0.103, validation loss = 0.048, test loss=0.038, test mse = 1589.949, test mae = 7.799\n",
      "epoch=491, loss=0.103, validation loss = 0.048, test loss=0.038, test mse = 1589.924, test mae = 7.794\n",
      "epoch=492, loss=0.102, validation loss = 0.048, test loss=0.037, test mse = 1589.900, test mae = 7.789\n",
      "epoch=493, loss=0.101, validation loss = 0.047, test loss=0.037, test mse = 1589.876, test mae = 7.784\n",
      "epoch=494, loss=0.100, validation loss = 0.047, test loss=0.037, test mse = 1589.852, test mae = 7.779\n",
      "epoch=495, loss=0.100, validation loss = 0.047, test loss=0.037, test mse = 1589.828, test mae = 7.774\n",
      "epoch=496, loss=0.099, validation loss = 0.046, test loss=0.036, test mse = 1589.804, test mae = 7.769\n",
      "epoch=497, loss=0.098, validation loss = 0.046, test loss=0.036, test mse = 1589.781, test mae = 7.764\n",
      "epoch=498, loss=0.098, validation loss = 0.046, test loss=0.036, test mse = 1589.758, test mae = 7.759\n",
      "epoch=499, loss=0.097, validation loss = 0.045, test loss=0.036, test mse = 1589.736, test mae = 7.754\n",
      "epoch=500, loss=0.096, validation loss = 0.045, test loss=0.035, test mse = 1589.713, test mae = 7.749\n",
      "epoch=501, loss=0.096, validation loss = 0.045, test loss=0.035, test mse = 1589.691, test mae = 7.745\n",
      "epoch=502, loss=0.095, validation loss = 0.044, test loss=0.035, test mse = 1589.669, test mae = 7.740\n",
      "epoch=503, loss=0.095, validation loss = 0.044, test loss=0.035, test mse = 1589.647, test mae = 7.735\n",
      "epoch=504, loss=0.094, validation loss = 0.044, test loss=0.034, test mse = 1589.625, test mae = 7.730\n",
      "epoch=505, loss=0.093, validation loss = 0.043, test loss=0.034, test mse = 1589.604, test mae = 7.725\n",
      "epoch=506, loss=0.093, validation loss = 0.043, test loss=0.034, test mse = 1589.583, test mae = 7.721\n",
      "epoch=507, loss=0.092, validation loss = 0.043, test loss=0.034, test mse = 1589.562, test mae = 7.716\n",
      "epoch=508, loss=0.091, validation loss = 0.042, test loss=0.033, test mse = 1589.542, test mae = 7.711\n",
      "epoch=509, loss=0.091, validation loss = 0.042, test loss=0.033, test mse = 1589.521, test mae = 7.706\n",
      "epoch=510, loss=0.090, validation loss = 0.042, test loss=0.033, test mse = 1589.501, test mae = 7.702\n",
      "epoch=511, loss=0.090, validation loss = 0.042, test loss=0.033, test mse = 1589.481, test mae = 7.697\n",
      "epoch=512, loss=0.089, validation loss = 0.041, test loss=0.032, test mse = 1589.461, test mae = 7.692\n",
      "epoch=513, loss=0.089, validation loss = 0.041, test loss=0.032, test mse = 1589.442, test mae = 7.688\n",
      "epoch=514, loss=0.088, validation loss = 0.041, test loss=0.032, test mse = 1589.423, test mae = 7.683\n",
      "epoch=515, loss=0.087, validation loss = 0.040, test loss=0.032, test mse = 1589.404, test mae = 7.679\n",
      "epoch=516, loss=0.087, validation loss = 0.040, test loss=0.032, test mse = 1589.385, test mae = 7.674\n",
      "epoch=517, loss=0.086, validation loss = 0.040, test loss=0.031, test mse = 1589.366, test mae = 7.669\n",
      "epoch=518, loss=0.086, validation loss = 0.040, test loss=0.031, test mse = 1589.348, test mae = 7.665\n",
      "epoch=519, loss=0.085, validation loss = 0.039, test loss=0.031, test mse = 1589.330, test mae = 7.660\n",
      "epoch=520, loss=0.085, validation loss = 0.039, test loss=0.031, test mse = 1589.312, test mae = 7.656\n",
      "epoch=521, loss=0.084, validation loss = 0.039, test loss=0.030, test mse = 1589.294, test mae = 7.652\n",
      "epoch=522, loss=0.084, validation loss = 0.039, test loss=0.030, test mse = 1589.276, test mae = 7.647\n",
      "epoch=523, loss=0.083, validation loss = 0.038, test loss=0.030, test mse = 1589.259, test mae = 7.643\n",
      "epoch=524, loss=0.082, validation loss = 0.038, test loss=0.030, test mse = 1589.242, test mae = 7.638\n",
      "epoch=525, loss=0.082, validation loss = 0.038, test loss=0.030, test mse = 1589.225, test mae = 7.634\n",
      "epoch=526, loss=0.081, validation loss = 0.037, test loss=0.029, test mse = 1589.208, test mae = 7.630\n",
      "epoch=527, loss=0.081, validation loss = 0.037, test loss=0.029, test mse = 1589.191, test mae = 7.625\n",
      "epoch=528, loss=0.080, validation loss = 0.037, test loss=0.029, test mse = 1589.175, test mae = 7.621\n",
      "epoch=529, loss=0.080, validation loss = 0.037, test loss=0.029, test mse = 1589.159, test mae = 7.617\n",
      "epoch=530, loss=0.079, validation loss = 0.036, test loss=0.029, test mse = 1589.143, test mae = 7.612\n",
      "epoch=531, loss=0.079, validation loss = 0.036, test loss=0.028, test mse = 1589.127, test mae = 7.608\n",
      "epoch=532, loss=0.078, validation loss = 0.036, test loss=0.028, test mse = 1589.112, test mae = 7.604\n",
      "epoch=533, loss=0.078, validation loss = 0.036, test loss=0.028, test mse = 1589.096, test mae = 7.600\n",
      "epoch=534, loss=0.077, validation loss = 0.036, test loss=0.028, test mse = 1589.081, test mae = 7.596\n",
      "epoch=535, loss=0.077, validation loss = 0.035, test loss=0.028, test mse = 1589.066, test mae = 7.591\n",
      "epoch=536, loss=0.077, validation loss = 0.035, test loss=0.028, test mse = 1589.051, test mae = 7.587\n",
      "epoch=537, loss=0.076, validation loss = 0.035, test loss=0.027, test mse = 1589.037, test mae = 7.583\n",
      "epoch=538, loss=0.076, validation loss = 0.035, test loss=0.027, test mse = 1589.022, test mae = 7.579\n",
      "epoch=539, loss=0.075, validation loss = 0.034, test loss=0.027, test mse = 1589.008, test mae = 7.575\n",
      "epoch=540, loss=0.075, validation loss = 0.034, test loss=0.027, test mse = 1588.994, test mae = 7.571\n",
      "epoch=541, loss=0.074, validation loss = 0.034, test loss=0.027, test mse = 1588.980, test mae = 7.567\n",
      "epoch=542, loss=0.074, validation loss = 0.034, test loss=0.027, test mse = 1588.966, test mae = 7.563\n",
      "epoch=543, loss=0.073, validation loss = 0.034, test loss=0.026, test mse = 1588.953, test mae = 7.559\n",
      "epoch=544, loss=0.073, validation loss = 0.033, test loss=0.026, test mse = 1588.939, test mae = 7.555\n",
      "epoch=545, loss=0.073, validation loss = 0.033, test loss=0.026, test mse = 1588.926, test mae = 7.551\n",
      "epoch=546, loss=0.072, validation loss = 0.033, test loss=0.026, test mse = 1588.913, test mae = 7.548\n",
      "epoch=547, loss=0.072, validation loss = 0.033, test loss=0.026, test mse = 1588.900, test mae = 7.544\n",
      "epoch=548, loss=0.071, validation loss = 0.033, test loss=0.026, test mse = 1588.887, test mae = 7.540\n",
      "epoch=549, loss=0.071, validation loss = 0.032, test loss=0.025, test mse = 1588.875, test mae = 7.536\n",
      "epoch=550, loss=0.070, validation loss = 0.032, test loss=0.025, test mse = 1588.862, test mae = 7.532\n",
      "epoch=551, loss=0.070, validation loss = 0.032, test loss=0.025, test mse = 1588.850, test mae = 7.528\n",
      "epoch=552, loss=0.070, validation loss = 0.032, test loss=0.025, test mse = 1588.838, test mae = 7.525\n",
      "epoch=553, loss=0.069, validation loss = 0.032, test loss=0.025, test mse = 1588.826, test mae = 7.521\n",
      "epoch=554, loss=0.069, validation loss = 0.031, test loss=0.025, test mse = 1588.814, test mae = 7.517\n",
      "epoch=555, loss=0.068, validation loss = 0.031, test loss=0.025, test mse = 1588.802, test mae = 7.514\n",
      "epoch=556, loss=0.068, validation loss = 0.031, test loss=0.024, test mse = 1588.791, test mae = 7.510\n",
      "epoch=557, loss=0.068, validation loss = 0.031, test loss=0.024, test mse = 1588.780, test mae = 7.506\n",
      "epoch=558, loss=0.067, validation loss = 0.031, test loss=0.024, test mse = 1588.768, test mae = 7.503\n",
      "epoch=559, loss=0.067, validation loss = 0.030, test loss=0.024, test mse = 1588.757, test mae = 7.499\n",
      "epoch=560, loss=0.067, validation loss = 0.030, test loss=0.024, test mse = 1588.746, test mae = 7.496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=561, loss=0.066, validation loss = 0.030, test loss=0.024, test mse = 1588.735, test mae = 7.492\n",
      "epoch=562, loss=0.066, validation loss = 0.030, test loss=0.024, test mse = 1588.725, test mae = 7.488\n",
      "epoch=563, loss=0.065, validation loss = 0.030, test loss=0.023, test mse = 1588.714, test mae = 7.485\n",
      "epoch=564, loss=0.065, validation loss = 0.030, test loss=0.023, test mse = 1588.704, test mae = 7.481\n",
      "epoch=565, loss=0.065, validation loss = 0.029, test loss=0.023, test mse = 1588.693, test mae = 7.478\n",
      "epoch=566, loss=0.064, validation loss = 0.029, test loss=0.023, test mse = 1588.683, test mae = 7.475\n",
      "epoch=567, loss=0.064, validation loss = 0.029, test loss=0.023, test mse = 1588.673, test mae = 7.471\n",
      "epoch=568, loss=0.064, validation loss = 0.029, test loss=0.023, test mse = 1588.663, test mae = 7.468\n",
      "epoch=569, loss=0.063, validation loss = 0.029, test loss=0.023, test mse = 1588.653, test mae = 7.464\n",
      "epoch=570, loss=0.063, validation loss = 0.029, test loss=0.023, test mse = 1588.644, test mae = 7.461\n",
      "epoch=571, loss=0.063, validation loss = 0.028, test loss=0.022, test mse = 1588.634, test mae = 7.457\n",
      "epoch=572, loss=0.062, validation loss = 0.028, test loss=0.022, test mse = 1588.624, test mae = 7.454\n",
      "epoch=573, loss=0.062, validation loss = 0.028, test loss=0.022, test mse = 1588.615, test mae = 7.451\n",
      "epoch=574, loss=0.062, validation loss = 0.028, test loss=0.022, test mse = 1588.606, test mae = 7.447\n",
      "epoch=575, loss=0.061, validation loss = 0.028, test loss=0.022, test mse = 1588.597, test mae = 7.444\n",
      "epoch=576, loss=0.061, validation loss = 0.028, test loss=0.022, test mse = 1588.588, test mae = 7.441\n",
      "epoch=577, loss=0.061, validation loss = 0.027, test loss=0.022, test mse = 1588.579, test mae = 7.438\n",
      "epoch=578, loss=0.061, validation loss = 0.027, test loss=0.022, test mse = 1588.570, test mae = 7.434\n",
      "epoch=579, loss=0.060, validation loss = 0.027, test loss=0.021, test mse = 1588.561, test mae = 7.431\n",
      "epoch=580, loss=0.060, validation loss = 0.027, test loss=0.021, test mse = 1588.553, test mae = 7.428\n",
      "epoch=581, loss=0.060, validation loss = 0.027, test loss=0.021, test mse = 1588.544, test mae = 7.425\n",
      "epoch=582, loss=0.059, validation loss = 0.027, test loss=0.021, test mse = 1588.536, test mae = 7.421\n",
      "epoch=583, loss=0.059, validation loss = 0.027, test loss=0.021, test mse = 1588.528, test mae = 7.418\n",
      "epoch=584, loss=0.059, validation loss = 0.026, test loss=0.021, test mse = 1588.519, test mae = 7.415\n",
      "epoch=585, loss=0.059, validation loss = 0.026, test loss=0.021, test mse = 1588.511, test mae = 7.412\n",
      "epoch=586, loss=0.058, validation loss = 0.026, test loss=0.021, test mse = 1588.503, test mae = 7.409\n",
      "epoch=587, loss=0.058, validation loss = 0.026, test loss=0.021, test mse = 1588.495, test mae = 7.406\n",
      "epoch=588, loss=0.058, validation loss = 0.026, test loss=0.020, test mse = 1588.488, test mae = 7.403\n",
      "epoch=589, loss=0.057, validation loss = 0.026, test loss=0.020, test mse = 1588.480, test mae = 7.400\n",
      "epoch=590, loss=0.057, validation loss = 0.026, test loss=0.020, test mse = 1588.473, test mae = 7.397\n",
      "epoch=591, loss=0.057, validation loss = 0.026, test loss=0.020, test mse = 1588.465, test mae = 7.394\n",
      "epoch=592, loss=0.057, validation loss = 0.025, test loss=0.020, test mse = 1588.458, test mae = 7.391\n",
      "epoch=593, loss=0.056, validation loss = 0.025, test loss=0.020, test mse = 1588.450, test mae = 7.388\n",
      "epoch=594, loss=0.056, validation loss = 0.025, test loss=0.020, test mse = 1588.443, test mae = 7.385\n",
      "epoch=595, loss=0.056, validation loss = 0.025, test loss=0.020, test mse = 1588.436, test mae = 7.382\n",
      "epoch=596, loss=0.056, validation loss = 0.025, test loss=0.020, test mse = 1588.429, test mae = 7.379\n",
      "epoch=597, loss=0.055, validation loss = 0.025, test loss=0.020, test mse = 1588.422, test mae = 7.376\n",
      "epoch=598, loss=0.055, validation loss = 0.025, test loss=0.019, test mse = 1588.415, test mae = 7.373\n",
      "epoch=599, loss=0.055, validation loss = 0.025, test loss=0.019, test mse = 1588.408, test mae = 7.370\n",
      "epoch=600, loss=0.055, validation loss = 0.024, test loss=0.019, test mse = 1588.402, test mae = 7.367\n",
      "epoch=601, loss=0.054, validation loss = 0.024, test loss=0.019, test mse = 1588.395, test mae = 7.364\n",
      "epoch=602, loss=0.054, validation loss = 0.024, test loss=0.019, test mse = 1588.388, test mae = 7.361\n",
      "epoch=603, loss=0.054, validation loss = 0.024, test loss=0.019, test mse = 1588.382, test mae = 7.359\n",
      "epoch=604, loss=0.054, validation loss = 0.024, test loss=0.019, test mse = 1588.376, test mae = 7.356\n",
      "epoch=605, loss=0.054, validation loss = 0.024, test loss=0.019, test mse = 1588.370, test mae = 7.353\n",
      "epoch=606, loss=0.053, validation loss = 0.024, test loss=0.019, test mse = 1588.363, test mae = 7.350\n",
      "epoch=607, loss=0.053, validation loss = 0.024, test loss=0.019, test mse = 1588.357, test mae = 7.347\n",
      "epoch=608, loss=0.053, validation loss = 0.024, test loss=0.019, test mse = 1588.351, test mae = 7.345\n",
      "epoch=609, loss=0.053, validation loss = 0.023, test loss=0.018, test mse = 1588.345, test mae = 7.342\n",
      "epoch=610, loss=0.052, validation loss = 0.023, test loss=0.018, test mse = 1588.339, test mae = 7.339\n",
      "epoch=611, loss=0.052, validation loss = 0.023, test loss=0.018, test mse = 1588.334, test mae = 7.337\n",
      "epoch=612, loss=0.052, validation loss = 0.023, test loss=0.018, test mse = 1588.328, test mae = 7.334\n",
      "epoch=613, loss=0.052, validation loss = 0.023, test loss=0.018, test mse = 1588.322, test mae = 7.331\n",
      "epoch=614, loss=0.052, validation loss = 0.023, test loss=0.018, test mse = 1588.316, test mae = 7.329\n",
      "epoch=615, loss=0.051, validation loss = 0.023, test loss=0.018, test mse = 1588.311, test mae = 7.326\n",
      "epoch=616, loss=0.051, validation loss = 0.023, test loss=0.018, test mse = 1588.306, test mae = 7.323\n",
      "epoch=617, loss=0.051, validation loss = 0.023, test loss=0.018, test mse = 1588.300, test mae = 7.321\n",
      "epoch=618, loss=0.051, validation loss = 0.023, test loss=0.018, test mse = 1588.295, test mae = 7.318\n",
      "epoch=619, loss=0.051, validation loss = 0.022, test loss=0.018, test mse = 1588.289, test mae = 7.315\n",
      "epoch=620, loss=0.050, validation loss = 0.022, test loss=0.018, test mse = 1588.284, test mae = 7.313\n",
      "epoch=621, loss=0.050, validation loss = 0.022, test loss=0.018, test mse = 1588.279, test mae = 7.310\n",
      "epoch=622, loss=0.050, validation loss = 0.022, test loss=0.017, test mse = 1588.274, test mae = 7.308\n",
      "epoch=623, loss=0.050, validation loss = 0.022, test loss=0.017, test mse = 1588.270, test mae = 7.305\n",
      "epoch=624, loss=0.050, validation loss = 0.022, test loss=0.017, test mse = 1588.265, test mae = 7.303\n",
      "epoch=625, loss=0.050, validation loss = 0.022, test loss=0.017, test mse = 1588.260, test mae = 7.300\n",
      "epoch=626, loss=0.049, validation loss = 0.022, test loss=0.017, test mse = 1588.255, test mae = 7.298\n",
      "epoch=627, loss=0.049, validation loss = 0.022, test loss=0.017, test mse = 1588.250, test mae = 7.295\n",
      "epoch=628, loss=0.049, validation loss = 0.022, test loss=0.017, test mse = 1588.245, test mae = 7.293\n",
      "epoch=629, loss=0.049, validation loss = 0.021, test loss=0.017, test mse = 1588.241, test mae = 7.290\n",
      "epoch=630, loss=0.049, validation loss = 0.021, test loss=0.017, test mse = 1588.236, test mae = 7.288\n",
      "epoch=631, loss=0.049, validation loss = 0.021, test loss=0.017, test mse = 1588.232, test mae = 7.285\n",
      "epoch=632, loss=0.048, validation loss = 0.021, test loss=0.017, test mse = 1588.228, test mae = 7.283\n",
      "epoch=633, loss=0.048, validation loss = 0.021, test loss=0.017, test mse = 1588.223, test mae = 7.280\n",
      "epoch=634, loss=0.048, validation loss = 0.021, test loss=0.017, test mse = 1588.219, test mae = 7.278\n",
      "epoch=635, loss=0.048, validation loss = 0.021, test loss=0.017, test mse = 1588.215, test mae = 7.276\n",
      "epoch=636, loss=0.048, validation loss = 0.021, test loss=0.016, test mse = 1588.211, test mae = 7.273\n",
      "epoch=637, loss=0.048, validation loss = 0.021, test loss=0.016, test mse = 1588.206, test mae = 7.271\n",
      "epoch=638, loss=0.047, validation loss = 0.021, test loss=0.016, test mse = 1588.202, test mae = 7.269\n",
      "epoch=639, loss=0.047, validation loss = 0.021, test loss=0.016, test mse = 1588.198, test mae = 7.266\n",
      "epoch=640, loss=0.047, validation loss = 0.021, test loss=0.016, test mse = 1588.194, test mae = 7.264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=641, loss=0.047, validation loss = 0.020, test loss=0.016, test mse = 1588.190, test mae = 7.262\n",
      "epoch=642, loss=0.047, validation loss = 0.020, test loss=0.016, test mse = 1588.187, test mae = 7.259\n",
      "epoch=643, loss=0.047, validation loss = 0.020, test loss=0.016, test mse = 1588.183, test mae = 7.257\n",
      "epoch=644, loss=0.047, validation loss = 0.020, test loss=0.016, test mse = 1588.179, test mae = 7.255\n",
      "epoch=645, loss=0.046, validation loss = 0.020, test loss=0.016, test mse = 1588.176, test mae = 7.253\n",
      "epoch=646, loss=0.046, validation loss = 0.020, test loss=0.016, test mse = 1588.172, test mae = 7.250\n",
      "epoch=647, loss=0.046, validation loss = 0.020, test loss=0.016, test mse = 1588.168, test mae = 7.248\n",
      "epoch=648, loss=0.046, validation loss = 0.020, test loss=0.016, test mse = 1588.164, test mae = 7.246\n",
      "epoch=649, loss=0.046, validation loss = 0.020, test loss=0.016, test mse = 1588.161, test mae = 7.244\n",
      "epoch=650, loss=0.046, validation loss = 0.020, test loss=0.016, test mse = 1588.158, test mae = 7.242\n",
      "epoch=651, loss=0.046, validation loss = 0.020, test loss=0.015, test mse = 1588.154, test mae = 7.240\n",
      "epoch=652, loss=0.045, validation loss = 0.020, test loss=0.015, test mse = 1588.151, test mae = 7.237\n",
      "epoch=653, loss=0.045, validation loss = 0.020, test loss=0.015, test mse = 1588.148, test mae = 7.235\n",
      "epoch=654, loss=0.045, validation loss = 0.020, test loss=0.015, test mse = 1588.144, test mae = 7.233\n",
      "epoch=655, loss=0.045, validation loss = 0.019, test loss=0.015, test mse = 1588.141, test mae = 7.231\n",
      "epoch=656, loss=0.045, validation loss = 0.019, test loss=0.015, test mse = 1588.138, test mae = 7.229\n",
      "epoch=657, loss=0.045, validation loss = 0.019, test loss=0.015, test mse = 1588.135, test mae = 7.227\n",
      "epoch=658, loss=0.045, validation loss = 0.019, test loss=0.015, test mse = 1588.132, test mae = 7.225\n",
      "epoch=659, loss=0.045, validation loss = 0.019, test loss=0.015, test mse = 1588.129, test mae = 7.223\n",
      "epoch=660, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.126, test mae = 7.221\n",
      "epoch=661, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.123, test mae = 7.219\n",
      "epoch=662, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.120, test mae = 7.217\n",
      "epoch=663, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.117, test mae = 7.215\n",
      "epoch=664, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.115, test mae = 7.213\n",
      "epoch=665, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.112, test mae = 7.211\n",
      "epoch=666, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.109, test mae = 7.209\n",
      "epoch=667, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.106, test mae = 7.207\n",
      "epoch=668, loss=0.044, validation loss = 0.019, test loss=0.015, test mse = 1588.104, test mae = 7.205\n",
      "epoch=669, loss=0.043, validation loss = 0.019, test loss=0.015, test mse = 1588.101, test mae = 7.203\n",
      "epoch=670, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.099, test mae = 7.201\n",
      "epoch=671, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.096, test mae = 7.199\n",
      "epoch=672, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.094, test mae = 7.197\n",
      "epoch=673, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.091, test mae = 7.195\n",
      "epoch=674, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.089, test mae = 7.194\n",
      "epoch=675, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.086, test mae = 7.192\n",
      "epoch=676, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.084, test mae = 7.190\n",
      "epoch=677, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.082, test mae = 7.188\n",
      "epoch=678, loss=0.043, validation loss = 0.018, test loss=0.014, test mse = 1588.079, test mae = 7.186\n",
      "epoch=679, loss=0.042, validation loss = 0.018, test loss=0.014, test mse = 1588.077, test mae = 7.184\n",
      "epoch=680, loss=0.042, validation loss = 0.018, test loss=0.014, test mse = 1588.074, test mae = 7.183\n",
      "epoch=681, loss=0.042, validation loss = 0.018, test loss=0.014, test mse = 1588.072, test mae = 7.181\n",
      "epoch=682, loss=0.042, validation loss = 0.018, test loss=0.014, test mse = 1588.070, test mae = 7.179\n",
      "epoch=683, loss=0.042, validation loss = 0.018, test loss=0.014, test mse = 1588.068, test mae = 7.177\n",
      "epoch=684, loss=0.042, validation loss = 0.018, test loss=0.014, test mse = 1588.066, test mae = 7.175\n",
      "epoch=685, loss=0.042, validation loss = 0.018, test loss=0.014, test mse = 1588.064, test mae = 7.174\n",
      "epoch=686, loss=0.042, validation loss = 0.018, test loss=0.014, test mse = 1588.062, test mae = 7.172\n",
      "epoch=687, loss=0.042, validation loss = 0.017, test loss=0.014, test mse = 1588.060, test mae = 7.170\n",
      "epoch=688, loss=0.042, validation loss = 0.017, test loss=0.014, test mse = 1588.058, test mae = 7.168\n",
      "epoch=689, loss=0.042, validation loss = 0.017, test loss=0.014, test mse = 1588.056, test mae = 7.167\n",
      "epoch=690, loss=0.041, validation loss = 0.017, test loss=0.014, test mse = 1588.054, test mae = 7.165\n",
      "epoch=691, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.052, test mae = 7.163\n",
      "epoch=692, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.050, test mae = 7.162\n",
      "epoch=693, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.048, test mae = 7.160\n",
      "epoch=694, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.046, test mae = 7.158\n",
      "epoch=695, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.045, test mae = 7.157\n",
      "epoch=696, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.043, test mae = 7.155\n",
      "epoch=697, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.041, test mae = 7.153\n",
      "epoch=698, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.039, test mae = 7.152\n",
      "epoch=699, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.038, test mae = 7.150\n",
      "epoch=700, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.036, test mae = 7.149\n",
      "epoch=701, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.035, test mae = 7.147\n",
      "epoch=702, loss=0.041, validation loss = 0.017, test loss=0.013, test mse = 1588.033, test mae = 7.145\n",
      "epoch=703, loss=0.040, validation loss = 0.017, test loss=0.013, test mse = 1588.031, test mae = 7.144\n",
      "epoch=704, loss=0.040, validation loss = 0.017, test loss=0.013, test mse = 1588.030, test mae = 7.142\n",
      "epoch=705, loss=0.040, validation loss = 0.017, test loss=0.013, test mse = 1588.028, test mae = 7.141\n",
      "epoch=706, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.027, test mae = 7.139\n",
      "epoch=707, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.025, test mae = 7.138\n",
      "epoch=708, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.024, test mae = 7.136\n",
      "epoch=709, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.023, test mae = 7.135\n",
      "epoch=710, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.021, test mae = 7.133\n",
      "epoch=711, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.020, test mae = 7.132\n",
      "epoch=712, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.018, test mae = 7.130\n",
      "epoch=713, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.017, test mae = 7.129\n",
      "epoch=714, loss=0.040, validation loss = 0.016, test loss=0.013, test mse = 1588.016, test mae = 7.127\n",
      "epoch=715, loss=0.040, validation loss = 0.016, test loss=0.012, test mse = 1588.015, test mae = 7.126\n",
      "epoch=716, loss=0.040, validation loss = 0.016, test loss=0.012, test mse = 1588.013, test mae = 7.124\n",
      "epoch=717, loss=0.040, validation loss = 0.016, test loss=0.012, test mse = 1588.012, test mae = 7.123\n",
      "epoch=718, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.011, test mae = 7.121\n",
      "epoch=719, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.010, test mae = 7.120\n",
      "epoch=720, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.009, test mae = 7.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=721, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.007, test mae = 7.117\n",
      "epoch=722, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.006, test mae = 7.116\n",
      "epoch=723, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.005, test mae = 7.115\n",
      "epoch=724, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.004, test mae = 7.113\n",
      "epoch=725, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.003, test mae = 7.112\n",
      "epoch=726, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.002, test mae = 7.111\n",
      "epoch=727, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.001, test mae = 7.109\n",
      "epoch=728, loss=0.039, validation loss = 0.016, test loss=0.012, test mse = 1588.000, test mae = 7.108\n",
      "epoch=729, loss=0.039, validation loss = 0.015, test loss=0.012, test mse = 1587.999, test mae = 7.107\n",
      "epoch=730, loss=0.039, validation loss = 0.015, test loss=0.012, test mse = 1587.998, test mae = 7.105\n",
      "epoch=731, loss=0.039, validation loss = 0.015, test loss=0.012, test mse = 1587.997, test mae = 7.104\n",
      "epoch=732, loss=0.039, validation loss = 0.015, test loss=0.012, test mse = 1587.996, test mae = 7.103\n",
      "epoch=733, loss=0.039, validation loss = 0.015, test loss=0.012, test mse = 1587.995, test mae = 7.101\n",
      "epoch=734, loss=0.039, validation loss = 0.015, test loss=0.012, test mse = 1587.994, test mae = 7.100\n",
      "epoch=735, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.994, test mae = 7.099\n",
      "epoch=736, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.993, test mae = 7.098\n",
      "epoch=737, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.992, test mae = 7.096\n",
      "epoch=738, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.991, test mae = 7.095\n",
      "epoch=739, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.990, test mae = 7.094\n",
      "epoch=740, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.990, test mae = 7.093\n",
      "epoch=741, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.989, test mae = 7.092\n",
      "epoch=742, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.988, test mae = 7.090\n",
      "epoch=743, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.987, test mae = 7.089\n",
      "epoch=744, loss=0.038, validation loss = 0.015, test loss=0.012, test mse = 1587.986, test mae = 7.088\n",
      "epoch=745, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.986, test mae = 7.087\n",
      "epoch=746, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.985, test mae = 7.086\n",
      "epoch=747, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.985, test mae = 7.084\n",
      "epoch=748, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.984, test mae = 7.083\n",
      "epoch=749, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.983, test mae = 7.082\n",
      "epoch=750, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.982, test mae = 7.081\n",
      "epoch=751, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.982, test mae = 7.080\n",
      "epoch=752, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.981, test mae = 7.079\n",
      "epoch=753, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.981, test mae = 7.078\n",
      "epoch=754, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.980, test mae = 7.076\n",
      "epoch=755, loss=0.038, validation loss = 0.015, test loss=0.011, test mse = 1587.980, test mae = 7.075\n",
      "epoch=756, loss=0.038, validation loss = 0.014, test loss=0.011, test mse = 1587.979, test mae = 7.074\n",
      "epoch=757, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.979, test mae = 7.073\n",
      "epoch=758, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.978, test mae = 7.072\n",
      "epoch=759, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.978, test mae = 7.071\n",
      "epoch=760, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.977, test mae = 7.070\n",
      "epoch=761, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.977, test mae = 7.069\n",
      "epoch=762, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.976, test mae = 7.068\n",
      "epoch=763, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.976, test mae = 7.067\n",
      "epoch=764, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.975, test mae = 7.066\n",
      "epoch=765, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.975, test mae = 7.065\n",
      "epoch=766, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.975, test mae = 7.064\n",
      "epoch=767, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.974, test mae = 7.063\n",
      "epoch=768, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.974, test mae = 7.062\n",
      "epoch=769, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.973, test mae = 7.060\n",
      "epoch=770, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.973, test mae = 7.059\n",
      "epoch=771, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.973, test mae = 7.058\n",
      "epoch=772, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.972, test mae = 7.057\n",
      "epoch=773, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.972, test mae = 7.056\n",
      "epoch=774, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.971, test mae = 7.055\n",
      "epoch=775, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.971, test mae = 7.055\n",
      "epoch=776, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.971, test mae = 7.054\n",
      "epoch=777, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.971, test mae = 7.053\n",
      "epoch=778, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.970, test mae = 7.052\n",
      "epoch=779, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.970, test mae = 7.051\n",
      "epoch=780, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.970, test mae = 7.050\n",
      "epoch=781, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.969, test mae = 7.049\n",
      "epoch=782, loss=0.037, validation loss = 0.014, test loss=0.011, test mse = 1587.969, test mae = 7.048\n",
      "epoch=783, loss=0.037, validation loss = 0.014, test loss=0.010, test mse = 1587.969, test mae = 7.047\n",
      "epoch=784, loss=0.037, validation loss = 0.014, test loss=0.010, test mse = 1587.969, test mae = 7.046\n",
      "epoch=785, loss=0.036, validation loss = 0.014, test loss=0.010, test mse = 1587.969, test mae = 7.045\n",
      "epoch=786, loss=0.036, validation loss = 0.014, test loss=0.010, test mse = 1587.968, test mae = 7.044\n",
      "epoch=787, loss=0.036, validation loss = 0.014, test loss=0.010, test mse = 1587.968, test mae = 7.043\n",
      "epoch=788, loss=0.036, validation loss = 0.014, test loss=0.010, test mse = 1587.968, test mae = 7.042\n",
      "epoch=789, loss=0.036, validation loss = 0.014, test loss=0.010, test mse = 1587.968, test mae = 7.041\n",
      "epoch=790, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.968, test mae = 7.041\n",
      "epoch=791, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.967, test mae = 7.040\n",
      "epoch=792, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.967, test mae = 7.039\n",
      "epoch=793, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.967, test mae = 7.038\n",
      "epoch=794, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.967, test mae = 7.037\n",
      "epoch=795, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.967, test mae = 7.036\n",
      "epoch=796, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.967, test mae = 7.035\n",
      "epoch=797, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.966, test mae = 7.034\n",
      "epoch=798, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.966, test mae = 7.034\n",
      "epoch=799, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.966, test mae = 7.033\n",
      "epoch=800, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.966, test mae = 7.032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=801, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.966, test mae = 7.031\n",
      "epoch=802, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.966, test mae = 7.030\n",
      "epoch=803, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.966, test mae = 7.029\n",
      "epoch=804, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.966, test mae = 7.029\n",
      "epoch=805, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.028\n",
      "epoch=806, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.027\n",
      "epoch=807, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.026\n",
      "epoch=808, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.025\n",
      "epoch=809, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.025\n",
      "epoch=810, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.024\n",
      "epoch=811, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.023\n",
      "epoch=812, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.022\n",
      "epoch=813, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.021\n",
      "epoch=814, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.021\n",
      "epoch=815, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.020\n",
      "epoch=816, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.019\n",
      "epoch=817, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.018\n",
      "epoch=818, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.018\n",
      "epoch=819, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.017\n",
      "epoch=820, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.016\n",
      "epoch=821, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.015\n",
      "epoch=822, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.015\n",
      "epoch=823, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.014\n",
      "epoch=824, loss=0.036, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.013\n",
      "epoch=825, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.013\n",
      "epoch=826, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.012\n",
      "epoch=827, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.011\n",
      "epoch=828, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.010\n",
      "epoch=829, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.010\n",
      "epoch=830, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.009\n",
      "epoch=831, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.008\n",
      "epoch=832, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.008\n",
      "epoch=833, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.007\n",
      "epoch=834, loss=0.035, validation loss = 0.013, test loss=0.010, test mse = 1587.965, test mae = 7.006\n",
      "epoch=835, loss=0.035, validation loss = 0.012, test loss=0.010, test mse = 1587.965, test mae = 7.006\n",
      "epoch=836, loss=0.035, validation loss = 0.012, test loss=0.010, test mse = 1587.965, test mae = 7.005\n",
      "epoch=837, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 7.004\n",
      "epoch=838, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 7.004\n",
      "epoch=839, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 7.003\n",
      "epoch=840, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 7.002\n",
      "epoch=841, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 7.002\n",
      "epoch=842, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 7.001\n",
      "epoch=843, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 7.000\n",
      "epoch=844, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 7.000\n",
      "epoch=845, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.999\n",
      "epoch=846, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 6.998\n",
      "epoch=847, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.965, test mae = 6.998\n",
      "epoch=848, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.997\n",
      "epoch=849, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.997\n",
      "epoch=850, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.996\n",
      "epoch=851, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.995\n",
      "epoch=852, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.995\n",
      "epoch=853, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.994\n",
      "epoch=854, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.993\n",
      "epoch=855, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.993\n",
      "epoch=856, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.966, test mae = 6.992\n",
      "epoch=857, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.992\n",
      "epoch=858, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.991\n",
      "epoch=859, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.991\n",
      "epoch=860, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.990\n",
      "epoch=861, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.989\n",
      "epoch=862, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.989\n",
      "epoch=863, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.988\n",
      "epoch=864, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.988\n",
      "epoch=865, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.987\n",
      "epoch=866, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.967, test mae = 6.987\n",
      "epoch=867, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.968, test mae = 6.986\n",
      "epoch=868, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.968, test mae = 6.986\n",
      "epoch=869, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.968, test mae = 6.985\n",
      "epoch=870, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.968, test mae = 6.984\n",
      "epoch=871, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.968, test mae = 6.984\n",
      "epoch=872, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.968, test mae = 6.983\n",
      "epoch=873, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.968, test mae = 6.983\n",
      "epoch=874, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.968, test mae = 6.982\n",
      "epoch=875, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.969, test mae = 6.982\n",
      "epoch=876, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.969, test mae = 6.981\n",
      "epoch=877, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.969, test mae = 6.981\n",
      "epoch=878, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.969, test mae = 6.980\n",
      "epoch=879, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.969, test mae = 6.980\n",
      "epoch=880, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.969, test mae = 6.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=881, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.969, test mae = 6.979\n",
      "epoch=882, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.970, test mae = 6.978\n",
      "epoch=883, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.970, test mae = 6.978\n",
      "epoch=884, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.970, test mae = 6.977\n",
      "epoch=885, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.970, test mae = 6.977\n",
      "epoch=886, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.970, test mae = 6.976\n",
      "epoch=887, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.970, test mae = 6.976\n",
      "epoch=888, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.971, test mae = 6.975\n",
      "epoch=889, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.971, test mae = 6.975\n",
      "epoch=890, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.971, test mae = 6.974\n",
      "epoch=891, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.971, test mae = 6.974\n",
      "epoch=892, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.971, test mae = 6.973\n",
      "epoch=893, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.971, test mae = 6.973\n",
      "epoch=894, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.971, test mae = 6.973\n",
      "epoch=895, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.971, test mae = 6.972\n",
      "epoch=896, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.972, test mae = 6.972\n",
      "epoch=897, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.972, test mae = 6.971\n",
      "epoch=898, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.972, test mae = 6.971\n",
      "epoch=899, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.972, test mae = 6.970\n",
      "epoch=900, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.972, test mae = 6.970\n",
      "epoch=901, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.972, test mae = 6.969\n",
      "epoch=902, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.972, test mae = 6.969\n",
      "epoch=903, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.973, test mae = 6.969\n",
      "epoch=904, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.973, test mae = 6.968\n",
      "epoch=905, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.973, test mae = 6.968\n",
      "epoch=906, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.973, test mae = 6.967\n",
      "epoch=907, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.973, test mae = 6.967\n",
      "epoch=908, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.973, test mae = 6.967\n",
      "epoch=909, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.974, test mae = 6.966\n",
      "epoch=910, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.974, test mae = 6.966\n",
      "epoch=911, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.974, test mae = 6.965\n",
      "epoch=912, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.974, test mae = 6.965\n",
      "epoch=913, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.974, test mae = 6.964\n",
      "epoch=914, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.974, test mae = 6.964\n",
      "epoch=915, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.974, test mae = 6.964\n",
      "epoch=916, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.974, test mae = 6.963\n",
      "epoch=917, loss=0.035, validation loss = 0.012, test loss=0.009, test mse = 1587.975, test mae = 6.963\n",
      "epoch=918, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.975, test mae = 6.963\n",
      "epoch=919, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.975, test mae = 6.962\n",
      "epoch=920, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.975, test mae = 6.962\n",
      "epoch=921, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.975, test mae = 6.961\n",
      "epoch=922, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.976, test mae = 6.961\n",
      "epoch=923, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.976, test mae = 6.961\n",
      "epoch=924, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.976, test mae = 6.960\n",
      "epoch=925, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.976, test mae = 6.960\n",
      "epoch=926, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.976, test mae = 6.960\n",
      "epoch=927, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.976, test mae = 6.959\n",
      "epoch=928, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.976, test mae = 6.959\n",
      "epoch=929, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.977, test mae = 6.958\n",
      "epoch=930, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.977, test mae = 6.958\n",
      "epoch=931, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.977, test mae = 6.958\n",
      "epoch=932, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.977, test mae = 6.957\n",
      "epoch=933, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.977, test mae = 6.957\n",
      "epoch=934, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.977, test mae = 6.957\n",
      "epoch=935, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.978, test mae = 6.956\n",
      "epoch=936, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.978, test mae = 6.956\n",
      "epoch=937, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.978, test mae = 6.956\n",
      "epoch=938, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.978, test mae = 6.955\n",
      "epoch=939, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.978, test mae = 6.955\n",
      "epoch=940, loss=0.034, validation loss = 0.011, test loss=0.009, test mse = 1587.978, test mae = 6.955\n",
      "epoch=941, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.978, test mae = 6.954\n",
      "epoch=942, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.979, test mae = 6.954\n",
      "epoch=943, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.979, test mae = 6.954\n",
      "epoch=944, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.979, test mae = 6.953\n",
      "epoch=945, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.979, test mae = 6.953\n",
      "epoch=946, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.979, test mae = 6.953\n",
      "epoch=947, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.979, test mae = 6.953\n",
      "epoch=948, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.979, test mae = 6.952\n",
      "epoch=949, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.980, test mae = 6.952\n",
      "epoch=950, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.980, test mae = 6.952\n",
      "epoch=951, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.980, test mae = 6.951\n",
      "epoch=952, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.980, test mae = 6.951\n",
      "epoch=953, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.980, test mae = 6.951\n",
      "epoch=954, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.980, test mae = 6.950\n",
      "epoch=955, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.980, test mae = 6.950\n",
      "epoch=956, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.980, test mae = 6.950\n",
      "epoch=957, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.981, test mae = 6.950\n",
      "epoch=958, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.981, test mae = 6.949\n",
      "epoch=959, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.981, test mae = 6.949\n",
      "epoch=960, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.981, test mae = 6.949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=961, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.981, test mae = 6.948\n",
      "epoch=962, loss=0.035, validation loss = 0.011, test loss=0.009, test mse = 1587.981, test mae = 6.948\n",
      "epoch=963, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.981, test mae = 6.948\n",
      "epoch=964, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.981, test mae = 6.948\n",
      "epoch=965, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.982, test mae = 6.947\n",
      "epoch=966, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.982, test mae = 6.947\n",
      "epoch=967, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.982, test mae = 6.947\n",
      "epoch=968, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.982, test mae = 6.947\n",
      "epoch=969, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.982, test mae = 6.946\n",
      "epoch=970, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.982, test mae = 6.946\n",
      "epoch=971, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.982, test mae = 6.946\n",
      "epoch=972, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.983, test mae = 6.946\n",
      "epoch=973, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.983, test mae = 6.945\n",
      "epoch=974, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.983, test mae = 6.945\n",
      "epoch=975, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.983, test mae = 6.945\n",
      "epoch=976, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.983, test mae = 6.945\n",
      "epoch=977, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.983, test mae = 6.944\n",
      "epoch=978, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.983, test mae = 6.944\n",
      "epoch=979, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.944\n",
      "epoch=980, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.944\n",
      "epoch=981, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.943\n",
      "epoch=982, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.943\n",
      "epoch=983, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.943\n",
      "epoch=984, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.943\n",
      "epoch=985, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.942\n",
      "epoch=986, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.942\n",
      "epoch=987, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.984, test mae = 6.942\n",
      "epoch=988, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.942\n",
      "epoch=989, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.941\n",
      "epoch=990, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.941\n",
      "epoch=991, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.941\n",
      "epoch=992, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.941\n",
      "epoch=993, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.941\n",
      "epoch=994, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.940\n",
      "epoch=995, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.940\n",
      "epoch=996, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.985, test mae = 6.940\n",
      "epoch=997, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.986, test mae = 6.940\n",
      "epoch=998, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.986, test mae = 6.940\n",
      "epoch=999, loss=0.035, validation loss = 0.011, test loss=0.008, test mse = 1587.986, test mae = 6.939\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "learning_rate = 0.0000005\n",
    "num_epochs = 1000\n",
    "batch_size = 1000\n",
    "output_size = 2\n",
    "\n",
    "device = th.device('cuda:0')\n",
    "input_size = train_past_cases_1d[0].shape[1] + attrs.shape[1]\n",
    "mlp_sir = Net_SIR(input_size, hidden_size, output_size)\n",
    "print('#features:', input_size)\n",
    "\n",
    "# Move model to GPU\n",
    "mlp_sir = mlp_sir.to(device)\n",
    "\n",
    "# Move data to GPU\n",
    "pop = pop.to(device)\n",
    "attrs = attrs.to(device)\n",
    "for i in range(len(train_past_cases_1d)):\n",
    "    train_past_cases_1d[i] = train_past_cases_1d[i].to(device)\n",
    "    train_past_deaths_1d[i] = train_past_deaths_1d[i].to(device)\n",
    "    train_labels_cases_1d[i] = train_labels_cases_1d[i].to(device)\n",
    "    train_labels_deaths_1d[i] = train_labels_deaths_1d[i].to(device)\n",
    "    if len(train_labels_cases_1d[i].shape) == 1:\n",
    "        train_labels_cases_1d[i] = train_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(train_labels_deaths_1d[i].shape) == 1:\n",
    "        train_labels_deaths_1d[i] = train_labels_deaths_1d[i].unsqueeze(1)\n",
    "        \n",
    "for i in range(len(valid_past_cases_1d)):\n",
    "    valid_past_cases_1d[i] = valid_past_cases_1d[i].to(device)\n",
    "    valid_past_deaths_1d[i] = valid_past_deaths_1d[i].to(device)\n",
    "    valid_labels_cases_1d[i] = valid_labels_cases_1d[i].to(device)\n",
    "    valid_labels_deaths_1d[i] = valid_labels_deaths_1d[i].to(device)\n",
    "    if len(valid_labels_cases_1d[i].shape) == 1:\n",
    "         valid_labels_cases_1d[i] = valid_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths_1d[i].shape) == 1:\n",
    "        valid_labels_deaths_1d[i] = valid_labels_deaths_1d[i].unsqueeze(1)\n",
    "\n",
    "for i in range(len(test_past_cases_1d)):\n",
    "    test_past_cases_1d[i] = test_past_cases_1d[i].to(device)\n",
    "    test_past_deaths_1d[i] = test_past_deaths_1d[i].to(device)\n",
    "    test_labels_cases_1d[i] = test_labels_cases_1d[i].to(device)\n",
    "    test_labels_deaths_1d[i] = test_labels_deaths_1d[i].to(device)\n",
    "    if len(test_labels_cases_1d[i].shape) == 1:\n",
    "        test_labels_cases_1d[i] = test_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths_1d[i].shape) == 1:\n",
    "        test_labels_deaths_1d[i] = test_labels_deaths_1d[i].unsqueeze(1)\n",
    "        \n",
    "# Normalize attrs\n",
    "attrs[th.isnan(attrs)] = 0\n",
    "attr_mean = th.mean(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs - attr_mean\n",
    "attr_std = th.std(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs / attr_std\n",
    "\n",
    "new_eval_err = 1000\n",
    "optimizer = th.optim.Adam(mlp_sir.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for idx in range(len(train_past_cases_1d)):\n",
    "        labels_cases = train_labels_cases_1d[idx]\n",
    "        labels_deaths = train_labels_deaths_1d[idx]\n",
    "        batch = th.cat([train_past_cases_1d[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = mlp_sir(batch)\n",
    "        I = train_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "        D = train_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "        I_new, D_new = sir_1d_output(vals, I, D)\n",
    "        loss = my_msle_ID(I_new, D_new, labels_cases, labels_deaths)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    count = 0\n",
    "    with th.no_grad():\n",
    "        eval_errs = []\n",
    "        test_errs = []\n",
    "        test_mses = []\n",
    "        test_maes = []\n",
    "        for idx in range(14):\n",
    "            valid_feats = th.cat([valid_past_cases_1d[idx], attrs], dim=1)\n",
    "            eval_vals = mlp_sir(valid_feats)\n",
    "            eval_I = valid_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "            eval_D = valid_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "            eval_labels_cases = valid_labels_cases_1d[idx]\n",
    "            eval_labels_deaths = valid_labels_deaths_1d[idx]\n",
    "            eval_I_new, eval_D_new = sir_1d_output(eval_vals, eval_I, eval_D)\n",
    "            err = my_msle_ID(eval_I_new, eval_D_new, eval_labels_cases, eval_labels_deaths)\n",
    "            eval_errs.append(err.cpu().numpy())\n",
    "            \n",
    "            test_feats = th.cat([test_past_cases_1d[idx], attrs], dim=1)\n",
    "            test_vals = mlp_sir(test_feats)\n",
    "            test_I = test_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "            test_D = test_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "            test_cases = test_labels_cases_1d[idx]\n",
    "            test_deaths = test_labels_deaths_1d[idx]\n",
    "            test_I_new, test_D_new = sir_1d_output(test_vals, test_I, test_D)\n",
    "            test_err = my_msle_ID(test_I_new, test_D_new, test_cases, test_deaths)\n",
    "            test_mse = th.mean((test_I_new - test_labels_cases_1d[idx])**2)\n",
    "            test_mae = th.mean(th.abs(test_I_new - test_labels_cases_1d[idx]))\n",
    "            test_errs.append(test_err.cpu().numpy())\n",
    "            test_mses.append(test_mse.cpu().numpy())\n",
    "            test_maes.append(test_mae.cpu().numpy())\n",
    "        print('epoch={}, loss={:.3f}, validation loss = {:.3f}, test loss={:.3f}, test mse = {:.3f}, test mae = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs), np.mean(test_errs), np.mean(test_mses), np.mean(test_maes)))\n",
    "        # print('epoch={}, loss={:.3f}, test loss={:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs)))\n",
    "            \n",
    "#        old_eval_err = new_eval_err\n",
    "#        new_eval_err = np.mean(eval_errs)\n",
    "#        if old_eval_err <= new_eval_err:\n",
    "#            R0_NYC = []\n",
    "#            R0_Sacramento = []\n",
    "#            gamma_NYC = []\n",
    "#            beta_NYC = []\n",
    "#            gamma_Sacramento = []\n",
    "#            beta_Sacramento = []\n",
    "#            train_vals = []\n",
    "#            for idx in range(19, len(train_past_cases)):\n",
    "#                labels = train_labels_cases[idx]\n",
    "#                batch = th.cat([train_past_cases[idx], attrs], dim=1)\n",
    "#                th.manual_seed(1)\n",
    "#                vals = mlp_sir(batch)\n",
    "#                gamma_NYC.append(vals[4][0])\n",
    "#                gamma_Sacramento.append(vals[202][0])\n",
    "#                beta_NYC.append(vals[4][1])\n",
    "#                beta_Sacramento.append(vals[202][1])\n",
    "#                R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "#                R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "#                R0_NYC.append(R_NYC_div)\n",
    "#                R0_Sacramento.append(R_Sacramento_div)  \n",
    "#                I = train_past_cases[idx][:,-1].view(3142,1)\n",
    "#                D = train_past_deaths[idx][:,-1].view(3142,1)\n",
    "#                I_new, D_new = sir_1d_output(vals, I, D)\n",
    "#                train_vals.append(I_new)\n",
    "#            break\n",
    "    # print('epoch={}, loss={:.3f}, validation loss = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP - SIR (loss = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 97\n",
      "epoch=0, loss=56344880.000, validation loss = 207803.828, test loss=9941405.000, test mse = 8357227.000, test mae = 418.947\n",
      "epoch=1, loss=56344880.000, validation loss = 207803.625, test loss=9941403.000, test mse = 8350281.000, test mae = 415.092\n",
      "epoch=2, loss=56344880.000, validation loss = 207803.406, test loss=9941403.000, test mse = 8340584.500, test mae = 409.948\n",
      "epoch=3, loss=56344876.000, validation loss = 207803.156, test loss=9941402.000, test mse = 8326105.500, test mae = 402.920\n",
      "epoch=4, loss=56344876.000, validation loss = 207802.875, test loss=9941401.000, test mse = 8299595.000, test mae = 392.327\n",
      "epoch=5, loss=56344876.000, validation loss = 207802.422, test loss=9941400.000, test mse = 8207257.000, test mae = 370.916\n",
      "epoch=6, loss=56344876.000, validation loss = 207801.797, test loss=9941399.000, test mse = 6243357.500, test mae = 257.647\n",
      "epoch=7, loss=56344868.000, validation loss = 207801.156, test loss=9941395.000, test mse = 16536.811, test mae = 23.778\n",
      "epoch=8, loss=56344864.000, validation loss = 207800.781, test loss=9941394.000, test mse = 18815.080, test mae = 29.947\n",
      "epoch=9, loss=56344864.000, validation loss = 207800.516, test loss=9941394.000, test mse = 28035.666, test mae = 40.797\n",
      "epoch=10, loss=56344864.000, validation loss = 207800.266, test loss=9941393.000, test mse = 55573.059, test mae = 53.356\n",
      "epoch=11, loss=56344864.000, validation loss = 207800.078, test loss=9941393.000, test mse = 459377.188, test mae = 84.479\n",
      "epoch=12, loss=56344864.000, validation loss = 207799.859, test loss=9941393.000, test mse = 2223076.750, test mae = 141.821\n",
      "epoch=13, loss=56344864.000, validation loss = 207799.672, test loss=9941391.000, test mse = 3578355.500, test mae = 184.743\n",
      "epoch=14, loss=56344864.000, validation loss = 207799.531, test loss=9941391.000, test mse = 4425883.000, test mae = 213.858\n",
      "epoch=15, loss=56344864.000, validation loss = 207799.375, test loss=9941391.000, test mse = 4714793.500, test mae = 230.998\n",
      "epoch=16, loss=56344864.000, validation loss = 207799.234, test loss=9941391.000, test mse = 4868228.500, test mae = 244.977\n",
      "epoch=17, loss=56344864.000, validation loss = 207799.125, test loss=9941391.000, test mse = 5059409.000, test mae = 258.613\n",
      "epoch=18, loss=56344860.000, validation loss = 207798.984, test loss=9941391.000, test mse = 5231703.500, test mae = 270.309\n",
      "epoch=19, loss=56344860.000, validation loss = 207798.875, test loss=9941391.000, test mse = 5339909.500, test mae = 280.130\n",
      "epoch=20, loss=56344860.000, validation loss = 207798.781, test loss=9941391.000, test mse = 5423314.500, test mae = 288.119\n",
      "epoch=21, loss=56344856.000, validation loss = 207798.656, test loss=9941391.000, test mse = 5486211.500, test mae = 294.663\n",
      "epoch=22, loss=56344856.000, validation loss = 207798.578, test loss=9941391.000, test mse = 5551260.000, test mae = 300.535\n",
      "epoch=23, loss=56344856.000, validation loss = 207798.500, test loss=9941391.000, test mse = 5652162.500, test mae = 306.288\n",
      "epoch=24, loss=56344856.000, validation loss = 207798.359, test loss=9941391.000, test mse = 5767522.500, test mae = 311.932\n",
      "epoch=25, loss=56344856.000, validation loss = 207798.281, test loss=9941391.000, test mse = 5921684.000, test mae = 317.431\n",
      "epoch=26, loss=56344856.000, validation loss = 207798.250, test loss=9941391.000, test mse = 6060788.500, test mae = 322.833\n",
      "epoch=27, loss=56344856.000, validation loss = 207798.125, test loss=9941390.000, test mse = 6220613.500, test mae = 328.578\n",
      "epoch=28, loss=56344856.000, validation loss = 207798.047, test loss=9941390.000, test mse = 6412375.000, test mae = 333.978\n",
      "epoch=29, loss=56344856.000, validation loss = 207797.984, test loss=9941390.000, test mse = 6529801.000, test mae = 338.286\n",
      "epoch=30, loss=56344856.000, validation loss = 207797.891, test loss=9941390.000, test mse = 6596199.000, test mae = 342.123\n",
      "epoch=31, loss=56344852.000, validation loss = 207797.859, test loss=9941390.000, test mse = 6650835.500, test mae = 345.814\n",
      "epoch=32, loss=56344852.000, validation loss = 207797.766, test loss=9941390.000, test mse = 6707356.000, test mae = 349.501\n",
      "epoch=33, loss=56344852.000, validation loss = 207797.719, test loss=9941389.000, test mse = 6787976.500, test mae = 353.324\n",
      "epoch=34, loss=56344844.000, validation loss = 207797.625, test loss=9941389.000, test mse = 6881840.500, test mae = 356.921\n",
      "epoch=35, loss=56344844.000, validation loss = 207797.578, test loss=9941389.000, test mse = 6969828.000, test mae = 360.428\n",
      "epoch=36, loss=56344844.000, validation loss = 207797.500, test loss=9941389.000, test mse = 7053375.500, test mae = 363.936\n",
      "epoch=37, loss=56344844.000, validation loss = 207797.453, test loss=9941389.000, test mse = 7161233.000, test mae = 367.677\n",
      "epoch=38, loss=56344844.000, validation loss = 207797.375, test loss=9941389.000, test mse = 7260839.000, test mae = 371.149\n",
      "epoch=39, loss=56344844.000, validation loss = 207797.297, test loss=9941389.000, test mse = 7346819.500, test mae = 374.316\n",
      "epoch=40, loss=56344844.000, validation loss = 207797.250, test loss=9941389.000, test mse = 7398828.000, test mae = 376.682\n",
      "epoch=41, loss=56344844.000, validation loss = 207797.219, test loss=9941389.000, test mse = 7420493.000, test mae = 378.648\n",
      "epoch=42, loss=56344844.000, validation loss = 207797.172, test loss=9941389.000, test mse = 7439437.500, test mae = 380.552\n",
      "epoch=43, loss=56344844.000, validation loss = 207797.109, test loss=9941389.000, test mse = 7457131.000, test mae = 382.437\n",
      "epoch=44, loss=56344844.000, validation loss = 207797.078, test loss=9941389.000, test mse = 7473763.000, test mae = 384.313\n",
      "epoch=45, loss=56344844.000, validation loss = 207797.000, test loss=9941389.000, test mse = 7489817.000, test mae = 386.222\n",
      "epoch=46, loss=56344836.000, validation loss = 207796.969, test loss=9941387.000, test mse = 7505612.500, test mae = 388.192\n",
      "epoch=47, loss=56344836.000, validation loss = 207796.906, test loss=9941387.000, test mse = 7522656.500, test mae = 390.272\n",
      "epoch=48, loss=56344836.000, validation loss = 207796.844, test loss=9941387.000, test mse = 7539659.000, test mae = 392.413\n",
      "epoch=49, loss=56344836.000, validation loss = 207796.828, test loss=9941387.000, test mse = 7554924.500, test mae = 394.556\n",
      "epoch=50, loss=56344836.000, validation loss = 207796.766, test loss=9941387.000, test mse = 7568981.500, test mae = 396.695\n",
      "epoch=51, loss=56344836.000, validation loss = 207796.750, test loss=9941387.000, test mse = 7582184.500, test mae = 398.797\n",
      "epoch=52, loss=56344836.000, validation loss = 207796.672, test loss=9941387.000, test mse = 7594287.000, test mae = 400.804\n",
      "epoch=53, loss=56344836.000, validation loss = 207796.641, test loss=9941386.000, test mse = 7605380.500, test mae = 402.707\n",
      "epoch=54, loss=56344836.000, validation loss = 207796.578, test loss=9941386.000, test mse = 7615247.500, test mae = 404.481\n",
      "epoch=55, loss=56344836.000, validation loss = 207796.516, test loss=9941386.000, test mse = 7623953.000, test mae = 406.121\n",
      "epoch=56, loss=56344836.000, validation loss = 207796.484, test loss=9941386.000, test mse = 7631515.500, test mae = 407.636\n",
      "epoch=57, loss=56344832.000, validation loss = 207796.469, test loss=9941385.000, test mse = 7638169.000, test mae = 409.041\n",
      "epoch=58, loss=56344832.000, validation loss = 207796.422, test loss=9941385.000, test mse = 7644196.000, test mae = 410.357\n",
      "epoch=59, loss=56344832.000, validation loss = 207796.391, test loss=9941385.000, test mse = 7649718.500, test mae = 411.588\n",
      "epoch=60, loss=56344832.000, validation loss = 207796.297, test loss=9941385.000, test mse = 7654872.500, test mae = 412.753\n",
      "epoch=61, loss=56344828.000, validation loss = 207796.266, test loss=9941385.000, test mse = 7659757.000, test mae = 413.865\n",
      "epoch=62, loss=56344828.000, validation loss = 207796.250, test loss=9941385.000, test mse = 7664443.500, test mae = 414.938\n",
      "epoch=63, loss=56344828.000, validation loss = 207796.203, test loss=9941385.000, test mse = 7668995.000, test mae = 415.981\n",
      "epoch=64, loss=56344828.000, validation loss = 207796.156, test loss=9941385.000, test mse = 7673452.000, test mae = 417.003\n",
      "epoch=65, loss=56344828.000, validation loss = 207796.141, test loss=9941385.000, test mse = 7677770.500, test mae = 418.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=66, loss=56344828.000, validation loss = 207796.109, test loss=9941385.000, test mse = 7682071.000, test mae = 419.013\n",
      "epoch=67, loss=56344828.000, validation loss = 207796.031, test loss=9941385.000, test mse = 7686408.500, test mae = 420.028\n",
      "epoch=68, loss=56344828.000, validation loss = 207796.016, test loss=9941385.000, test mse = 7690680.500, test mae = 421.050\n",
      "epoch=69, loss=56344820.000, validation loss = 207796.000, test loss=9941384.000, test mse = 7694843.500, test mae = 422.075\n",
      "epoch=70, loss=56344820.000, validation loss = 207795.969, test loss=9941384.000, test mse = 7698840.000, test mae = 423.096\n",
      "epoch=71, loss=56344820.000, validation loss = 207795.922, test loss=9941384.000, test mse = 7702727.000, test mae = 424.117\n",
      "epoch=72, loss=56344820.000, validation loss = 207795.859, test loss=9941384.000, test mse = 7706403.000, test mae = 425.119\n",
      "epoch=73, loss=56344820.000, validation loss = 207795.859, test loss=9941384.000, test mse = 7709891.500, test mae = 426.103\n",
      "epoch=74, loss=56344820.000, validation loss = 207795.828, test loss=9941384.000, test mse = 7713145.500, test mae = 427.062\n",
      "epoch=75, loss=56344820.000, validation loss = 207795.766, test loss=9941384.000, test mse = 7716171.000, test mae = 427.994\n",
      "epoch=76, loss=56344820.000, validation loss = 207795.766, test loss=9941384.000, test mse = 7718970.500, test mae = 428.900\n",
      "epoch=77, loss=56344820.000, validation loss = 207795.734, test loss=9941384.000, test mse = 7721555.000, test mae = 429.779\n",
      "epoch=78, loss=56344820.000, validation loss = 207795.672, test loss=9941384.000, test mse = 7723928.000, test mae = 430.632\n",
      "epoch=79, loss=56344820.000, validation loss = 207795.656, test loss=9941384.000, test mse = 7726124.000, test mae = 431.466\n",
      "epoch=80, loss=56344820.000, validation loss = 207795.625, test loss=9941384.000, test mse = 7728159.500, test mae = 432.282\n",
      "epoch=81, loss=56344820.000, validation loss = 207795.609, test loss=9941384.000, test mse = 7730056.000, test mae = 433.084\n",
      "epoch=82, loss=56344820.000, validation loss = 207795.578, test loss=9941384.000, test mse = 7731852.500, test mae = 433.879\n",
      "epoch=83, loss=56344820.000, validation loss = 207795.531, test loss=9941384.000, test mse = 7733563.000, test mae = 434.667\n",
      "epoch=84, loss=56344820.000, validation loss = 207795.484, test loss=9941384.000, test mse = 7735187.500, test mae = 435.446\n",
      "epoch=85, loss=56344820.000, validation loss = 207795.453, test loss=9941384.000, test mse = 7736711.000, test mae = 436.206\n",
      "epoch=86, loss=56344820.000, validation loss = 207795.422, test loss=9941383.000, test mse = 7738123.500, test mae = 436.941\n",
      "epoch=87, loss=56344820.000, validation loss = 207795.391, test loss=9941383.000, test mse = 7739425.000, test mae = 437.647\n",
      "epoch=88, loss=56344820.000, validation loss = 207795.359, test loss=9941383.000, test mse = 7740620.000, test mae = 438.323\n",
      "epoch=89, loss=56344820.000, validation loss = 207795.344, test loss=9941383.000, test mse = 7741716.000, test mae = 438.970\n",
      "epoch=90, loss=56344820.000, validation loss = 207795.328, test loss=9941383.000, test mse = 7742724.000, test mae = 439.589\n",
      "epoch=91, loss=56344816.000, validation loss = 207795.266, test loss=9941383.000, test mse = 7743651.500, test mae = 440.181\n",
      "epoch=92, loss=56344816.000, validation loss = 207795.266, test loss=9941383.000, test mse = 7744507.000, test mae = 440.748\n",
      "epoch=93, loss=56344816.000, validation loss = 207795.219, test loss=9941383.000, test mse = 7745298.500, test mae = 441.290\n",
      "epoch=94, loss=56344816.000, validation loss = 207795.219, test loss=9941383.000, test mse = 7746032.500, test mae = 441.810\n",
      "epoch=95, loss=56344816.000, validation loss = 207795.172, test loss=9941383.000, test mse = 7746713.000, test mae = 442.310\n",
      "epoch=96, loss=56344816.000, validation loss = 207795.156, test loss=9941383.000, test mse = 7747348.000, test mae = 442.789\n",
      "epoch=97, loss=56344816.000, validation loss = 207795.125, test loss=9941383.000, test mse = 7747939.000, test mae = 443.251\n",
      "epoch=98, loss=56344816.000, validation loss = 207795.109, test loss=9941383.000, test mse = 7748493.000, test mae = 443.695\n",
      "epoch=99, loss=56344816.000, validation loss = 207795.047, test loss=9941383.000, test mse = 7749011.000, test mae = 444.124\n",
      "epoch=100, loss=56344812.000, validation loss = 207795.031, test loss=9941383.000, test mse = 7749498.500, test mae = 444.538\n",
      "epoch=101, loss=56344812.000, validation loss = 207795.016, test loss=9941383.000, test mse = 7749955.000, test mae = 444.939\n",
      "epoch=102, loss=56344812.000, validation loss = 207795.000, test loss=9941383.000, test mse = 7750387.500, test mae = 445.328\n",
      "epoch=103, loss=56344812.000, validation loss = 207794.969, test loss=9941383.000, test mse = 7750795.500, test mae = 445.707\n",
      "epoch=104, loss=56344812.000, validation loss = 207794.953, test loss=9941383.000, test mse = 7751185.000, test mae = 446.077\n",
      "epoch=105, loss=56344812.000, validation loss = 207794.891, test loss=9941383.000, test mse = 7751557.500, test mae = 446.439\n",
      "epoch=106, loss=56344812.000, validation loss = 207794.859, test loss=9941383.000, test mse = 7751916.000, test mae = 446.797\n",
      "epoch=107, loss=56344812.000, validation loss = 207794.859, test loss=9941382.000, test mse = 7752261.500, test mae = 447.148\n",
      "epoch=108, loss=56344812.000, validation loss = 207794.844, test loss=9941382.000, test mse = 7752595.500, test mae = 447.494\n",
      "epoch=109, loss=56344812.000, validation loss = 207794.828, test loss=9941382.000, test mse = 7752916.500, test mae = 447.833\n",
      "epoch=110, loss=56344812.000, validation loss = 207794.781, test loss=9941382.000, test mse = 7753225.500, test mae = 448.166\n",
      "epoch=111, loss=56344804.000, validation loss = 207794.766, test loss=9941382.000, test mse = 7753522.500, test mae = 448.492\n",
      "epoch=112, loss=56344804.000, validation loss = 207794.734, test loss=9941382.000, test mse = 7753806.500, test mae = 448.810\n",
      "epoch=113, loss=56344804.000, validation loss = 207794.734, test loss=9941382.000, test mse = 7754077.000, test mae = 449.121\n",
      "epoch=114, loss=56344804.000, validation loss = 207794.656, test loss=9941382.000, test mse = 7754337.000, test mae = 449.423\n",
      "epoch=115, loss=56344804.000, validation loss = 207794.656, test loss=9941382.000, test mse = 7754584.500, test mae = 449.718\n",
      "epoch=116, loss=56344804.000, validation loss = 207794.625, test loss=9941382.000, test mse = 7754820.500, test mae = 450.006\n",
      "epoch=117, loss=56344804.000, validation loss = 207794.609, test loss=9941382.000, test mse = 7755045.000, test mae = 450.286\n",
      "epoch=118, loss=56344804.000, validation loss = 207794.609, test loss=9941382.000, test mse = 7755260.500, test mae = 450.558\n",
      "epoch=119, loss=56344804.000, validation loss = 207794.578, test loss=9941382.000, test mse = 7755465.500, test mae = 450.824\n",
      "epoch=120, loss=56344804.000, validation loss = 207794.547, test loss=9941382.000, test mse = 7755662.500, test mae = 451.083\n",
      "epoch=121, loss=56344804.000, validation loss = 207794.531, test loss=9941382.000, test mse = 7755851.000, test mae = 451.336\n",
      "epoch=122, loss=56344804.000, validation loss = 207794.516, test loss=9941382.000, test mse = 7756031.000, test mae = 451.582\n",
      "epoch=123, loss=56344804.000, validation loss = 207794.500, test loss=9941382.000, test mse = 7756203.500, test mae = 451.823\n",
      "epoch=124, loss=56344804.000, validation loss = 207794.453, test loss=9941382.000, test mse = 7756368.500, test mae = 452.057\n",
      "epoch=125, loss=56344804.000, validation loss = 207794.422, test loss=9941382.000, test mse = 7756528.000, test mae = 452.287\n",
      "epoch=126, loss=56344804.000, validation loss = 207794.391, test loss=9941382.000, test mse = 7756681.000, test mae = 452.511\n",
      "epoch=127, loss=56344804.000, validation loss = 207794.375, test loss=9941382.000, test mse = 7756829.000, test mae = 452.731\n",
      "epoch=128, loss=56344804.000, validation loss = 207794.328, test loss=9941382.000, test mse = 7756970.500, test mae = 452.947\n",
      "epoch=129, loss=56344804.000, validation loss = 207794.328, test loss=9941382.000, test mse = 7757108.500, test mae = 453.158\n",
      "epoch=130, loss=56344804.000, validation loss = 207794.281, test loss=9941382.000, test mse = 7757241.000, test mae = 453.366\n",
      "epoch=131, loss=56344804.000, validation loss = 207794.250, test loss=9941382.000, test mse = 7757371.500, test mae = 453.571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=132, loss=56344800.000, validation loss = 207794.250, test loss=9941382.000, test mse = 7757497.000, test mae = 453.772\n",
      "epoch=133, loss=56344800.000, validation loss = 207794.219, test loss=9941382.000, test mse = 7757620.000, test mae = 453.970\n",
      "epoch=134, loss=56344800.000, validation loss = 207794.219, test loss=9941382.000, test mse = 7757738.500, test mae = 454.166\n",
      "epoch=135, loss=56344800.000, validation loss = 207794.203, test loss=9941382.000, test mse = 7757855.000, test mae = 454.360\n",
      "epoch=136, loss=56344800.000, validation loss = 207794.156, test loss=9941382.000, test mse = 7757968.000, test mae = 454.551\n",
      "epoch=137, loss=56344800.000, validation loss = 207794.156, test loss=9941382.000, test mse = 7758079.500, test mae = 454.741\n",
      "epoch=138, loss=56344800.000, validation loss = 207794.125, test loss=9941382.000, test mse = 7758186.500, test mae = 454.928\n",
      "epoch=139, loss=56344796.000, validation loss = 207794.109, test loss=9941382.000, test mse = 7758291.000, test mae = 455.112\n",
      "epoch=140, loss=56344796.000, validation loss = 207794.078, test loss=9941382.000, test mse = 7758392.000, test mae = 455.294\n",
      "epoch=141, loss=56344796.000, validation loss = 207794.078, test loss=9941382.000, test mse = 7758489.500, test mae = 455.474\n",
      "epoch=142, loss=56344796.000, validation loss = 207794.031, test loss=9941382.000, test mse = 7758585.000, test mae = 455.651\n",
      "epoch=143, loss=56344796.000, validation loss = 207794.016, test loss=9941382.000, test mse = 7758677.500, test mae = 455.826\n",
      "epoch=144, loss=56344796.000, validation loss = 207793.984, test loss=9941382.000, test mse = 7758768.500, test mae = 455.998\n",
      "epoch=145, loss=56344796.000, validation loss = 207793.969, test loss=9941382.000, test mse = 7758856.000, test mae = 456.169\n",
      "epoch=146, loss=56344796.000, validation loss = 207793.953, test loss=9941382.000, test mse = 7758942.500, test mae = 456.339\n",
      "epoch=147, loss=56344796.000, validation loss = 207793.922, test loss=9941382.000, test mse = 7759027.000, test mae = 456.506\n",
      "epoch=148, loss=56344796.000, validation loss = 207793.922, test loss=9941382.000, test mse = 7759108.000, test mae = 456.671\n",
      "epoch=149, loss=56344796.000, validation loss = 207793.891, test loss=9941382.000, test mse = 7759187.000, test mae = 456.834\n",
      "epoch=150, loss=56344796.000, validation loss = 207793.891, test loss=9941382.000, test mse = 7759264.000, test mae = 456.994\n",
      "epoch=151, loss=56344796.000, validation loss = 207793.859, test loss=9941382.000, test mse = 7759337.500, test mae = 457.151\n",
      "epoch=152, loss=56344796.000, validation loss = 207793.828, test loss=9941382.000, test mse = 7759409.500, test mae = 457.305\n",
      "epoch=153, loss=56344796.000, validation loss = 207793.797, test loss=9941382.000, test mse = 7759479.000, test mae = 457.456\n",
      "epoch=154, loss=56344796.000, validation loss = 207793.781, test loss=9941382.000, test mse = 7759546.500, test mae = 457.605\n",
      "epoch=155, loss=56344796.000, validation loss = 207793.781, test loss=9941382.000, test mse = 7759612.000, test mae = 457.752\n",
      "epoch=156, loss=56344796.000, validation loss = 207793.750, test loss=9941382.000, test mse = 7759675.000, test mae = 457.896\n",
      "epoch=157, loss=56344796.000, validation loss = 207793.750, test loss=9941382.000, test mse = 7759737.000, test mae = 458.038\n",
      "epoch=158, loss=56344792.000, validation loss = 207793.719, test loss=9941382.000, test mse = 7759797.000, test mae = 458.179\n",
      "epoch=159, loss=56344792.000, validation loss = 207793.719, test loss=9941382.000, test mse = 7759855.500, test mae = 458.317\n",
      "epoch=160, loss=56344792.000, validation loss = 207793.672, test loss=9941382.000, test mse = 7759912.000, test mae = 458.453\n",
      "epoch=161, loss=56344792.000, validation loss = 207793.672, test loss=9941382.000, test mse = 7759967.000, test mae = 458.587\n",
      "epoch=162, loss=56344792.000, validation loss = 207793.656, test loss=9941382.000, test mse = 7760021.000, test mae = 458.719\n",
      "epoch=163, loss=56344788.000, validation loss = 207793.625, test loss=9941382.000, test mse = 7760073.000, test mae = 458.849\n",
      "epoch=164, loss=56344788.000, validation loss = 207793.594, test loss=9941382.000, test mse = 7760123.500, test mae = 458.976\n",
      "epoch=165, loss=56344788.000, validation loss = 207793.547, test loss=9941382.000, test mse = 7760173.000, test mae = 459.102\n",
      "epoch=166, loss=56344788.000, validation loss = 207793.531, test loss=9941382.000, test mse = 7760221.500, test mae = 459.226\n",
      "epoch=167, loss=56344788.000, validation loss = 207793.531, test loss=9941382.000, test mse = 7760268.500, test mae = 459.347\n",
      "epoch=168, loss=56344788.000, validation loss = 207793.516, test loss=9941382.000, test mse = 7760313.000, test mae = 459.467\n",
      "epoch=169, loss=56344788.000, validation loss = 207793.500, test loss=9941382.000, test mse = 7760357.500, test mae = 459.585\n",
      "epoch=170, loss=56344788.000, validation loss = 207793.484, test loss=9941382.000, test mse = 7760400.000, test mae = 459.700\n",
      "epoch=171, loss=56344788.000, validation loss = 207793.484, test loss=9941382.000, test mse = 7760441.500, test mae = 459.814\n",
      "epoch=172, loss=56344788.000, validation loss = 207793.453, test loss=9941382.000, test mse = 7760481.500, test mae = 459.927\n",
      "epoch=173, loss=56344788.000, validation loss = 207793.453, test loss=9941382.000, test mse = 7760521.000, test mae = 460.038\n",
      "epoch=174, loss=56344788.000, validation loss = 207793.422, test loss=9941382.000, test mse = 7760560.000, test mae = 460.148\n",
      "epoch=175, loss=56344788.000, validation loss = 207793.391, test loss=9941382.000, test mse = 7760597.500, test mae = 460.257\n",
      "epoch=176, loss=56344788.000, validation loss = 207793.391, test loss=9941382.000, test mse = 7760635.000, test mae = 460.365\n",
      "epoch=177, loss=56344788.000, validation loss = 207793.359, test loss=9941382.000, test mse = 7760671.000, test mae = 460.471\n",
      "epoch=178, loss=56344788.000, validation loss = 207793.359, test loss=9941382.000, test mse = 7760705.000, test mae = 460.576\n",
      "epoch=179, loss=56344788.000, validation loss = 207793.297, test loss=9941382.000, test mse = 7760740.000, test mae = 460.680\n",
      "epoch=180, loss=56344788.000, validation loss = 207793.297, test loss=9941382.000, test mse = 7760773.000, test mae = 460.783\n",
      "epoch=181, loss=56344788.000, validation loss = 207793.266, test loss=9941382.000, test mse = 7760806.500, test mae = 460.884\n",
      "epoch=182, loss=56344788.000, validation loss = 207793.250, test loss=9941382.000, test mse = 7760837.000, test mae = 460.983\n",
      "epoch=183, loss=56344788.000, validation loss = 207793.250, test loss=9941382.000, test mse = 7760868.500, test mae = 461.081\n",
      "epoch=184, loss=56344788.000, validation loss = 207793.203, test loss=9941382.000, test mse = 7760898.500, test mae = 461.178\n",
      "epoch=185, loss=56344788.000, validation loss = 207793.172, test loss=9941382.000, test mse = 7760928.500, test mae = 461.274\n",
      "epoch=186, loss=56344784.000, validation loss = 207793.141, test loss=9941382.000, test mse = 7760957.000, test mae = 461.368\n",
      "epoch=187, loss=56344784.000, validation loss = 207793.141, test loss=9941382.000, test mse = 7760985.000, test mae = 461.461\n",
      "epoch=188, loss=56344784.000, validation loss = 207793.141, test loss=9941382.000, test mse = 7761013.000, test mae = 461.553\n",
      "epoch=189, loss=56344780.000, validation loss = 207793.109, test loss=9941381.000, test mse = 7761039.000, test mae = 461.643\n",
      "epoch=190, loss=56344780.000, validation loss = 207793.109, test loss=9941381.000, test mse = 7761066.500, test mae = 461.733\n",
      "epoch=191, loss=56344780.000, validation loss = 207793.094, test loss=9941379.000, test mse = 7761091.500, test mae = 461.821\n",
      "epoch=192, loss=56344780.000, validation loss = 207793.078, test loss=9941379.000, test mse = 7761115.500, test mae = 461.908\n",
      "epoch=193, loss=56344772.000, validation loss = 207793.047, test loss=9941379.000, test mse = 7761141.000, test mae = 461.994\n",
      "epoch=194, loss=56344772.000, validation loss = 207793.016, test loss=9941379.000, test mse = 7761165.000, test mae = 462.079\n",
      "epoch=195, loss=56344772.000, validation loss = 207793.016, test loss=9941379.000, test mse = 7761188.500, test mae = 462.164\n",
      "epoch=196, loss=56344772.000, validation loss = 207793.000, test loss=9941379.000, test mse = 7761211.500, test mae = 462.247\n",
      "epoch=197, loss=56344764.000, validation loss = 207792.984, test loss=9941379.000, test mse = 7761233.500, test mae = 462.329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=198, loss=56344764.000, validation loss = 207792.969, test loss=9941379.000, test mse = 7761255.000, test mae = 462.410\n",
      "epoch=199, loss=56344764.000, validation loss = 207792.922, test loss=9941379.000, test mse = 7761276.500, test mae = 462.490\n",
      "epoch=200, loss=56344764.000, validation loss = 207792.922, test loss=9941379.000, test mse = 7761296.500, test mae = 462.569\n",
      "epoch=201, loss=56344764.000, validation loss = 207792.891, test loss=9941379.000, test mse = 7761317.500, test mae = 462.647\n",
      "epoch=202, loss=56344764.000, validation loss = 207792.891, test loss=9941379.000, test mse = 7761337.500, test mae = 462.724\n",
      "epoch=203, loss=56344764.000, validation loss = 207792.891, test loss=9941379.000, test mse = 7761357.000, test mae = 462.799\n",
      "epoch=204, loss=56344764.000, validation loss = 207792.859, test loss=9941379.000, test mse = 7761376.000, test mae = 462.874\n",
      "epoch=205, loss=56344764.000, validation loss = 207792.844, test loss=9941379.000, test mse = 7761394.500, test mae = 462.948\n",
      "epoch=206, loss=56344760.000, validation loss = 207792.844, test loss=9941379.000, test mse = 7761412.000, test mae = 463.020\n",
      "epoch=207, loss=56344760.000, validation loss = 207792.797, test loss=9941379.000, test mse = 7761429.500, test mae = 463.092\n",
      "epoch=208, loss=56344760.000, validation loss = 207792.797, test loss=9941379.000, test mse = 7761447.000, test mae = 463.163\n",
      "epoch=209, loss=56344760.000, validation loss = 207792.734, test loss=9941379.000, test mse = 7761464.000, test mae = 463.233\n",
      "epoch=210, loss=56344760.000, validation loss = 207792.734, test loss=9941379.000, test mse = 7761480.500, test mae = 463.301\n",
      "epoch=211, loss=56344760.000, validation loss = 207792.719, test loss=9941379.000, test mse = 7761496.500, test mae = 463.370\n",
      "epoch=212, loss=56344760.000, validation loss = 207792.703, test loss=9941379.000, test mse = 7761513.000, test mae = 463.437\n",
      "epoch=213, loss=56344760.000, validation loss = 207792.672, test loss=9941379.000, test mse = 7761528.000, test mae = 463.504\n",
      "epoch=214, loss=56344760.000, validation loss = 207792.656, test loss=9941379.000, test mse = 7761544.000, test mae = 463.571\n",
      "epoch=215, loss=56344760.000, validation loss = 207792.656, test loss=9941379.000, test mse = 7761559.500, test mae = 463.638\n",
      "epoch=216, loss=56344756.000, validation loss = 207792.656, test loss=9941379.000, test mse = 7761575.000, test mae = 463.704\n",
      "epoch=217, loss=56344756.000, validation loss = 207792.641, test loss=9941379.000, test mse = 7761589.500, test mae = 463.771\n",
      "epoch=218, loss=56344756.000, validation loss = 207792.625, test loss=9941379.000, test mse = 7761605.000, test mae = 463.836\n",
      "epoch=219, loss=56344756.000, validation loss = 207792.609, test loss=9941379.000, test mse = 7761619.500, test mae = 463.902\n",
      "epoch=220, loss=56344752.000, validation loss = 207792.594, test loss=9941379.000, test mse = 7761633.000, test mae = 463.966\n",
      "epoch=221, loss=56344752.000, validation loss = 207792.594, test loss=9941379.000, test mse = 7761648.000, test mae = 464.030\n",
      "epoch=222, loss=56344752.000, validation loss = 207792.547, test loss=9941379.000, test mse = 7761661.000, test mae = 464.094\n",
      "epoch=223, loss=56344752.000, validation loss = 207792.547, test loss=9941379.000, test mse = 7761674.500, test mae = 464.156\n",
      "epoch=224, loss=56344752.000, validation loss = 207792.547, test loss=9941379.000, test mse = 7761687.000, test mae = 464.217\n",
      "epoch=225, loss=56344752.000, validation loss = 207792.516, test loss=9941379.000, test mse = 7761700.000, test mae = 464.278\n",
      "epoch=226, loss=56344752.000, validation loss = 207792.469, test loss=9941379.000, test mse = 7761712.500, test mae = 464.337\n",
      "epoch=227, loss=56344752.000, validation loss = 207792.453, test loss=9941379.000, test mse = 7761725.000, test mae = 464.396\n",
      "epoch=228, loss=56344748.000, validation loss = 207792.406, test loss=9941379.000, test mse = 7761736.500, test mae = 464.454\n",
      "epoch=229, loss=56344748.000, validation loss = 207792.406, test loss=9941379.000, test mse = 7761748.500, test mae = 464.510\n",
      "epoch=230, loss=56344748.000, validation loss = 207792.406, test loss=9941379.000, test mse = 7761759.000, test mae = 464.566\n",
      "epoch=231, loss=56344748.000, validation loss = 207792.391, test loss=9941379.000, test mse = 7761770.500, test mae = 464.621\n",
      "epoch=232, loss=56344748.000, validation loss = 207792.375, test loss=9941379.000, test mse = 7761780.500, test mae = 464.675\n",
      "epoch=233, loss=56344748.000, validation loss = 207792.359, test loss=9941379.000, test mse = 7761791.500, test mae = 464.728\n",
      "epoch=234, loss=56344748.000, validation loss = 207792.344, test loss=9941379.000, test mse = 7761801.000, test mae = 464.780\n",
      "epoch=235, loss=56344744.000, validation loss = 207792.328, test loss=9941379.000, test mse = 7761810.500, test mae = 464.832\n",
      "epoch=236, loss=56344744.000, validation loss = 207792.297, test loss=9941379.000, test mse = 7761820.500, test mae = 464.883\n",
      "epoch=237, loss=56344744.000, validation loss = 207792.281, test loss=9941379.000, test mse = 7761831.000, test mae = 464.933\n",
      "epoch=238, loss=56344744.000, validation loss = 207792.281, test loss=9941379.000, test mse = 7761839.500, test mae = 464.983\n",
      "epoch=239, loss=56344744.000, validation loss = 207792.250, test loss=9941379.000, test mse = 7761848.000, test mae = 465.031\n",
      "epoch=240, loss=56344744.000, validation loss = 207792.234, test loss=9941378.000, test mse = 7761857.000, test mae = 465.080\n",
      "epoch=241, loss=56344744.000, validation loss = 207792.219, test loss=9941378.000, test mse = 7761866.500, test mae = 465.127\n",
      "epoch=242, loss=56344744.000, validation loss = 207792.219, test loss=9941378.000, test mse = 7761876.500, test mae = 465.174\n",
      "epoch=243, loss=56344744.000, validation loss = 207792.203, test loss=9941378.000, test mse = 7761884.500, test mae = 465.221\n",
      "epoch=244, loss=56344744.000, validation loss = 207792.172, test loss=9941378.000, test mse = 7761892.500, test mae = 465.267\n",
      "epoch=245, loss=56344744.000, validation loss = 207792.156, test loss=9941378.000, test mse = 7761900.500, test mae = 465.312\n",
      "epoch=246, loss=56344744.000, validation loss = 207792.156, test loss=9941378.000, test mse = 7761908.500, test mae = 465.357\n",
      "epoch=247, loss=56344744.000, validation loss = 207792.141, test loss=9941378.000, test mse = 7761916.000, test mae = 465.401\n",
      "epoch=248, loss=56344744.000, validation loss = 207792.125, test loss=9941378.000, test mse = 7761923.500, test mae = 465.445\n",
      "epoch=249, loss=56344744.000, validation loss = 207792.109, test loss=9941378.000, test mse = 7761931.500, test mae = 465.488\n",
      "epoch=250, loss=56344744.000, validation loss = 207792.047, test loss=9941378.000, test mse = 7761938.500, test mae = 465.531\n",
      "epoch=251, loss=56344740.000, validation loss = 207792.031, test loss=9941378.000, test mse = 7761944.500, test mae = 465.573\n",
      "epoch=252, loss=56344740.000, validation loss = 207792.016, test loss=9941378.000, test mse = 7761952.000, test mae = 465.615\n",
      "epoch=253, loss=56344740.000, validation loss = 207792.000, test loss=9941378.000, test mse = 7761959.500, test mae = 465.656\n",
      "epoch=254, loss=56344740.000, validation loss = 207792.000, test loss=9941378.000, test mse = 7761966.500, test mae = 465.697\n",
      "epoch=255, loss=56344740.000, validation loss = 207792.000, test loss=9941378.000, test mse = 7761972.500, test mae = 465.738\n",
      "epoch=256, loss=56344740.000, validation loss = 207791.984, test loss=9941378.000, test mse = 7761979.500, test mae = 465.778\n",
      "epoch=257, loss=56344740.000, validation loss = 207791.969, test loss=9941378.000, test mse = 7761985.500, test mae = 465.817\n",
      "epoch=258, loss=56344740.000, validation loss = 207791.969, test loss=9941378.000, test mse = 7761991.500, test mae = 465.856\n",
      "epoch=259, loss=56344740.000, validation loss = 207791.922, test loss=9941378.000, test mse = 7761998.500, test mae = 465.895\n",
      "epoch=260, loss=56344740.000, validation loss = 207791.906, test loss=9941378.000, test mse = 7762004.500, test mae = 465.933\n",
      "epoch=261, loss=56344740.000, validation loss = 207791.875, test loss=9941378.000, test mse = 7762010.500, test mae = 465.971\n",
      "epoch=262, loss=56344736.000, validation loss = 207791.875, test loss=9941378.000, test mse = 7762015.500, test mae = 466.009\n",
      "epoch=263, loss=56344736.000, validation loss = 207791.859, test loss=9941378.000, test mse = 7762021.500, test mae = 466.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=264, loss=56344736.000, validation loss = 207791.844, test loss=9941378.000, test mse = 7762028.500, test mae = 466.083\n",
      "epoch=265, loss=56344736.000, validation loss = 207791.844, test loss=9941378.000, test mse = 7762032.500, test mae = 466.119\n",
      "epoch=266, loss=56344736.000, validation loss = 207791.828, test loss=9941378.000, test mse = 7762038.500, test mae = 466.155\n",
      "epoch=267, loss=56344736.000, validation loss = 207791.797, test loss=9941378.000, test mse = 7762044.000, test mae = 466.191\n",
      "epoch=268, loss=56344736.000, validation loss = 207791.781, test loss=9941378.000, test mse = 7762049.000, test mae = 466.227\n",
      "epoch=269, loss=56344736.000, validation loss = 207791.781, test loss=9941378.000, test mse = 7762054.500, test mae = 466.262\n",
      "epoch=270, loss=56344736.000, validation loss = 207791.766, test loss=9941378.000, test mse = 7762060.000, test mae = 466.296\n",
      "epoch=271, loss=56344736.000, validation loss = 207791.750, test loss=9941378.000, test mse = 7762064.500, test mae = 466.331\n",
      "epoch=272, loss=56344736.000, validation loss = 207791.750, test loss=9941378.000, test mse = 7762069.500, test mae = 466.365\n",
      "epoch=273, loss=56344736.000, validation loss = 207791.734, test loss=9941378.000, test mse = 7762075.000, test mae = 466.399\n",
      "epoch=274, loss=56344736.000, validation loss = 207791.719, test loss=9941378.000, test mse = 7762078.500, test mae = 466.432\n",
      "epoch=275, loss=56344736.000, validation loss = 207791.719, test loss=9941378.000, test mse = 7762083.500, test mae = 466.466\n",
      "epoch=276, loss=56344736.000, validation loss = 207791.672, test loss=9941378.000, test mse = 7762088.000, test mae = 466.499\n",
      "epoch=277, loss=56344736.000, validation loss = 207791.641, test loss=9941378.000, test mse = 7762093.000, test mae = 466.531\n",
      "epoch=278, loss=56344736.000, validation loss = 207791.641, test loss=9941378.000, test mse = 7762097.500, test mae = 466.564\n",
      "epoch=279, loss=56344736.000, validation loss = 207791.609, test loss=9941378.000, test mse = 7762101.500, test mae = 466.596\n",
      "epoch=280, loss=56344736.000, validation loss = 207791.609, test loss=9941378.000, test mse = 7762107.500, test mae = 466.628\n",
      "epoch=281, loss=56344736.000, validation loss = 207791.594, test loss=9941378.000, test mse = 7762111.000, test mae = 466.660\n",
      "epoch=282, loss=56344736.000, validation loss = 207791.578, test loss=9941378.000, test mse = 7762115.500, test mae = 466.692\n",
      "epoch=283, loss=56344736.000, validation loss = 207791.547, test loss=9941378.000, test mse = 7762119.500, test mae = 466.723\n",
      "epoch=284, loss=56344736.000, validation loss = 207791.547, test loss=9941378.000, test mse = 7762124.000, test mae = 466.755\n",
      "epoch=285, loss=56344732.000, validation loss = 207791.531, test loss=9941378.000, test mse = 7762128.000, test mae = 466.786\n",
      "epoch=286, loss=56344732.000, validation loss = 207791.531, test loss=9941378.000, test mse = 7762132.000, test mae = 466.817\n",
      "epoch=287, loss=56344732.000, validation loss = 207791.516, test loss=9941378.000, test mse = 7762136.000, test mae = 466.847\n",
      "epoch=288, loss=56344732.000, validation loss = 207791.516, test loss=9941378.000, test mse = 7762140.000, test mae = 466.878\n",
      "epoch=289, loss=56344732.000, validation loss = 207791.516, test loss=9941378.000, test mse = 7762144.000, test mae = 466.908\n",
      "epoch=290, loss=56344732.000, validation loss = 207791.484, test loss=9941378.000, test mse = 7762148.000, test mae = 466.939\n",
      "epoch=291, loss=56344732.000, validation loss = 207791.484, test loss=9941378.000, test mse = 7762152.000, test mae = 466.969\n",
      "epoch=292, loss=56344728.000, validation loss = 207791.422, test loss=9941378.000, test mse = 7762155.500, test mae = 466.999\n",
      "epoch=293, loss=56344728.000, validation loss = 207791.422, test loss=9941378.000, test mse = 7762159.000, test mae = 467.029\n",
      "epoch=294, loss=56344728.000, validation loss = 207791.406, test loss=9941378.000, test mse = 7762163.000, test mae = 467.058\n",
      "epoch=295, loss=56344724.000, validation loss = 207791.391, test loss=9941377.000, test mse = 7762166.500, test mae = 467.088\n",
      "epoch=296, loss=56344724.000, validation loss = 207791.391, test loss=9941377.000, test mse = 7762170.500, test mae = 467.117\n",
      "epoch=297, loss=56344724.000, validation loss = 207791.391, test loss=9941377.000, test mse = 7762173.500, test mae = 467.146\n",
      "epoch=298, loss=56344724.000, validation loss = 207791.359, test loss=9941377.000, test mse = 7762177.500, test mae = 467.175\n",
      "epoch=299, loss=56344724.000, validation loss = 207791.344, test loss=9941377.000, test mse = 7762181.000, test mae = 467.204\n",
      "epoch=300, loss=56344724.000, validation loss = 207791.344, test loss=9941377.000, test mse = 7762184.500, test mae = 467.232\n",
      "epoch=301, loss=56344724.000, validation loss = 207791.328, test loss=9941377.000, test mse = 7762187.500, test mae = 467.260\n",
      "epoch=302, loss=56344724.000, validation loss = 207791.297, test loss=9941377.000, test mse = 7762191.000, test mae = 467.289\n",
      "epoch=303, loss=56344724.000, validation loss = 207791.297, test loss=9941377.000, test mse = 7762194.500, test mae = 467.317\n",
      "epoch=304, loss=56344724.000, validation loss = 207791.281, test loss=9941377.000, test mse = 7762197.500, test mae = 467.344\n",
      "epoch=305, loss=56344724.000, validation loss = 207791.250, test loss=9941376.000, test mse = 7762201.000, test mae = 467.372\n",
      "epoch=306, loss=56344724.000, validation loss = 207791.234, test loss=9941376.000, test mse = 7762204.500, test mae = 467.399\n",
      "epoch=307, loss=56344724.000, validation loss = 207791.234, test loss=9941376.000, test mse = 7762207.000, test mae = 467.426\n",
      "epoch=308, loss=56344724.000, validation loss = 207791.219, test loss=9941376.000, test mse = 7762209.500, test mae = 467.453\n",
      "epoch=309, loss=56344720.000, validation loss = 207791.219, test loss=9941376.000, test mse = 7762213.500, test mae = 467.479\n",
      "epoch=310, loss=56344720.000, validation loss = 207791.172, test loss=9941376.000, test mse = 7762216.500, test mae = 467.506\n",
      "epoch=311, loss=56344720.000, validation loss = 207791.172, test loss=9941376.000, test mse = 7762219.500, test mae = 467.532\n",
      "epoch=312, loss=56344720.000, validation loss = 207791.172, test loss=9941376.000, test mse = 7762222.500, test mae = 467.558\n",
      "epoch=313, loss=56344716.000, validation loss = 207791.156, test loss=9941376.000, test mse = 7762224.500, test mae = 467.584\n",
      "epoch=314, loss=56344716.000, validation loss = 207791.141, test loss=9941376.000, test mse = 7762228.000, test mae = 467.609\n",
      "epoch=315, loss=56344716.000, validation loss = 207791.141, test loss=9941376.000, test mse = 7762231.000, test mae = 467.635\n",
      "epoch=316, loss=56344716.000, validation loss = 207791.125, test loss=9941376.000, test mse = 7762234.500, test mae = 467.660\n",
      "epoch=317, loss=56344708.000, validation loss = 207791.125, test loss=9941376.000, test mse = 7762236.000, test mae = 467.685\n",
      "epoch=318, loss=56344708.000, validation loss = 207791.094, test loss=9941376.000, test mse = 7762239.000, test mae = 467.710\n",
      "epoch=319, loss=56344708.000, validation loss = 207791.078, test loss=9941376.000, test mse = 7762241.500, test mae = 467.734\n",
      "epoch=320, loss=56344708.000, validation loss = 207791.047, test loss=9941376.000, test mse = 7762244.000, test mae = 467.759\n",
      "epoch=321, loss=56344708.000, validation loss = 207791.047, test loss=9941376.000, test mse = 7762247.000, test mae = 467.783\n",
      "epoch=322, loss=56344708.000, validation loss = 207791.031, test loss=9941376.000, test mse = 7762250.500, test mae = 467.807\n",
      "epoch=323, loss=56344708.000, validation loss = 207791.016, test loss=9941376.000, test mse = 7762252.000, test mae = 467.831\n",
      "epoch=324, loss=56344708.000, validation loss = 207791.016, test loss=9941376.000, test mse = 7762253.500, test mae = 467.855\n",
      "epoch=325, loss=56344708.000, validation loss = 207790.984, test loss=9941376.000, test mse = 7762256.000, test mae = 467.879\n",
      "epoch=326, loss=56344708.000, validation loss = 207790.984, test loss=9941376.000, test mse = 7762259.500, test mae = 467.902\n",
      "epoch=327, loss=56344708.000, validation loss = 207791.000, test loss=9941376.000, test mse = 7762261.000, test mae = 467.926\n",
      "epoch=328, loss=56344708.000, validation loss = 207791.000, test loss=9941376.000, test mse = 7762263.500, test mae = 467.949\n",
      "epoch=329, loss=56344708.000, validation loss = 207790.969, test loss=9941376.000, test mse = 7762267.000, test mae = 467.972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=330, loss=56344708.000, validation loss = 207790.969, test loss=9941375.000, test mse = 7762268.000, test mae = 467.994\n",
      "epoch=331, loss=56344708.000, validation loss = 207790.953, test loss=9941374.000, test mse = 7762269.500, test mae = 468.017\n",
      "epoch=332, loss=56344708.000, validation loss = 207790.922, test loss=9941374.000, test mse = 7762273.000, test mae = 468.039\n",
      "epoch=333, loss=56344708.000, validation loss = 207790.906, test loss=9941374.000, test mse = 7762275.000, test mae = 468.061\n",
      "epoch=334, loss=56344708.000, validation loss = 207790.906, test loss=9941374.000, test mse = 7762276.500, test mae = 468.083\n",
      "epoch=335, loss=56344708.000, validation loss = 207790.891, test loss=9941374.000, test mse = 7762279.000, test mae = 468.105\n",
      "epoch=336, loss=56344708.000, validation loss = 207790.875, test loss=9941374.000, test mse = 7762281.000, test mae = 468.126\n",
      "epoch=337, loss=56344708.000, validation loss = 207790.859, test loss=9941374.000, test mse = 7762283.500, test mae = 468.147\n",
      "epoch=338, loss=56344708.000, validation loss = 207790.859, test loss=9941374.000, test mse = 7762284.500, test mae = 468.168\n",
      "epoch=339, loss=56344708.000, validation loss = 207790.828, test loss=9941374.000, test mse = 7762287.000, test mae = 468.189\n",
      "epoch=340, loss=56344708.000, validation loss = 207790.828, test loss=9941374.000, test mse = 7762289.000, test mae = 468.210\n",
      "epoch=341, loss=56344708.000, validation loss = 207790.781, test loss=9941374.000, test mse = 7762291.000, test mae = 468.230\n",
      "epoch=342, loss=56344704.000, validation loss = 207790.766, test loss=9941374.000, test mse = 7762292.500, test mae = 468.251\n",
      "epoch=343, loss=56344704.000, validation loss = 207790.750, test loss=9941374.000, test mse = 7762295.000, test mae = 468.271\n",
      "epoch=344, loss=56344696.000, validation loss = 207790.750, test loss=9941374.000, test mse = 7762296.500, test mae = 468.290\n",
      "epoch=345, loss=56344696.000, validation loss = 207790.750, test loss=9941374.000, test mse = 7762298.500, test mae = 468.310\n",
      "epoch=346, loss=56344696.000, validation loss = 207790.734, test loss=9941374.000, test mse = 7762300.000, test mae = 468.330\n",
      "epoch=347, loss=56344696.000, validation loss = 207790.734, test loss=9941374.000, test mse = 7762301.000, test mae = 468.349\n",
      "epoch=348, loss=56344696.000, validation loss = 207790.719, test loss=9941374.000, test mse = 7762304.000, test mae = 468.368\n",
      "epoch=349, loss=56344696.000, validation loss = 207790.719, test loss=9941374.000, test mse = 7762305.000, test mae = 468.387\n",
      "epoch=350, loss=56344696.000, validation loss = 207790.672, test loss=9941374.000, test mse = 7762307.000, test mae = 468.406\n",
      "epoch=351, loss=56344696.000, validation loss = 207790.672, test loss=9941374.000, test mse = 7762308.000, test mae = 468.425\n",
      "epoch=352, loss=56344696.000, validation loss = 207790.672, test loss=9941374.000, test mse = 7762309.000, test mae = 468.443\n",
      "epoch=353, loss=56344696.000, validation loss = 207790.672, test loss=9941374.000, test mse = 7762312.000, test mae = 468.462\n",
      "epoch=354, loss=56344696.000, validation loss = 207790.641, test loss=9941374.000, test mse = 7762312.500, test mae = 468.480\n",
      "epoch=355, loss=56344696.000, validation loss = 207790.641, test loss=9941374.000, test mse = 7762314.500, test mae = 468.498\n",
      "epoch=356, loss=56344696.000, validation loss = 207790.641, test loss=9941374.000, test mse = 7762316.000, test mae = 468.516\n",
      "epoch=357, loss=56344696.000, validation loss = 207790.609, test loss=9941374.000, test mse = 7762316.500, test mae = 468.534\n",
      "epoch=358, loss=56344696.000, validation loss = 207790.594, test loss=9941374.000, test mse = 7762319.000, test mae = 468.551\n",
      "epoch=359, loss=56344692.000, validation loss = 207790.594, test loss=9941374.000, test mse = 7762320.500, test mae = 468.568\n",
      "epoch=360, loss=56344692.000, validation loss = 207790.594, test loss=9941374.000, test mse = 7762321.000, test mae = 468.586\n",
      "epoch=361, loss=56344692.000, validation loss = 207790.547, test loss=9941374.000, test mse = 7762323.000, test mae = 468.603\n",
      "epoch=362, loss=56344692.000, validation loss = 207790.547, test loss=9941374.000, test mse = 7762324.000, test mae = 468.620\n",
      "epoch=363, loss=56344692.000, validation loss = 207790.547, test loss=9941374.000, test mse = 7762325.500, test mae = 468.637\n",
      "epoch=364, loss=56344692.000, validation loss = 207790.516, test loss=9941374.000, test mse = 7762328.000, test mae = 468.653\n",
      "epoch=365, loss=56344692.000, validation loss = 207790.516, test loss=9941374.000, test mse = 7762328.500, test mae = 468.670\n",
      "epoch=366, loss=56344688.000, validation loss = 207790.500, test loss=9941374.000, test mse = 7762329.000, test mae = 468.687\n",
      "epoch=367, loss=56344688.000, validation loss = 207790.500, test loss=9941373.000, test mse = 7762330.500, test mae = 468.703\n",
      "epoch=368, loss=56344688.000, validation loss = 207790.484, test loss=9941373.000, test mse = 7762332.000, test mae = 468.719\n",
      "epoch=369, loss=56344688.000, validation loss = 207790.469, test loss=9941373.000, test mse = 7762332.500, test mae = 468.735\n",
      "epoch=370, loss=56344684.000, validation loss = 207790.453, test loss=9941373.000, test mse = 7762335.000, test mae = 468.751\n",
      "epoch=371, loss=56344684.000, validation loss = 207790.422, test loss=9941373.000, test mse = 7762336.500, test mae = 468.767\n",
      "epoch=372, loss=56344684.000, validation loss = 207790.422, test loss=9941373.000, test mse = 7762337.000, test mae = 468.783\n",
      "epoch=373, loss=56344684.000, validation loss = 207790.422, test loss=9941373.000, test mse = 7762339.000, test mae = 468.798\n",
      "epoch=374, loss=56344684.000, validation loss = 207790.406, test loss=9941373.000, test mse = 7762339.500, test mae = 468.814\n",
      "epoch=375, loss=56344680.000, validation loss = 207790.406, test loss=9941373.000, test mse = 7762340.000, test mae = 468.829\n",
      "epoch=376, loss=56344680.000, validation loss = 207790.375, test loss=9941373.000, test mse = 7762341.000, test mae = 468.844\n",
      "epoch=377, loss=56344680.000, validation loss = 207790.375, test loss=9941373.000, test mse = 7762343.000, test mae = 468.859\n",
      "epoch=378, loss=56344680.000, validation loss = 207790.359, test loss=9941373.000, test mse = 7762344.000, test mae = 468.875\n",
      "epoch=379, loss=56344680.000, validation loss = 207790.344, test loss=9941373.000, test mse = 7762344.500, test mae = 468.889\n",
      "epoch=380, loss=56344680.000, validation loss = 207790.328, test loss=9941373.000, test mse = 7762346.500, test mae = 468.904\n",
      "epoch=381, loss=56344680.000, validation loss = 207790.297, test loss=9941373.000, test mse = 7762347.500, test mae = 468.919\n",
      "epoch=382, loss=56344680.000, validation loss = 207790.297, test loss=9941373.000, test mse = 7762347.500, test mae = 468.933\n",
      "epoch=383, loss=56344680.000, validation loss = 207790.297, test loss=9941373.000, test mse = 7762348.500, test mae = 468.948\n",
      "epoch=384, loss=56344680.000, validation loss = 207790.281, test loss=9941373.000, test mse = 7762351.000, test mae = 468.962\n",
      "epoch=385, loss=56344680.000, validation loss = 207790.266, test loss=9941373.000, test mse = 7762352.000, test mae = 468.976\n",
      "epoch=386, loss=56344676.000, validation loss = 207790.266, test loss=9941373.000, test mse = 7762352.000, test mae = 468.990\n",
      "epoch=387, loss=56344676.000, validation loss = 207790.266, test loss=9941373.000, test mse = 7762353.000, test mae = 469.004\n",
      "epoch=388, loss=56344676.000, validation loss = 207790.250, test loss=9941373.000, test mse = 7762354.500, test mae = 469.018\n",
      "epoch=389, loss=56344676.000, validation loss = 207790.219, test loss=9941373.000, test mse = 7762355.500, test mae = 469.032\n",
      "epoch=390, loss=56344676.000, validation loss = 207790.219, test loss=9941373.000, test mse = 7762356.000, test mae = 469.045\n",
      "epoch=391, loss=56344676.000, validation loss = 207790.219, test loss=9941373.000, test mse = 7762356.500, test mae = 469.059\n",
      "epoch=392, loss=56344676.000, validation loss = 207790.172, test loss=9941373.000, test mse = 7762357.500, test mae = 469.072\n",
      "epoch=393, loss=56344672.000, validation loss = 207790.172, test loss=9941373.000, test mse = 7762359.000, test mae = 469.086\n",
      "epoch=394, loss=56344672.000, validation loss = 207790.172, test loss=9941373.000, test mse = 7762360.000, test mae = 469.099\n",
      "epoch=395, loss=56344672.000, validation loss = 207790.172, test loss=9941373.000, test mse = 7762360.500, test mae = 469.112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=396, loss=56344672.000, validation loss = 207790.141, test loss=9941373.000, test mse = 7762362.500, test mae = 469.125\n",
      "epoch=397, loss=56344672.000, validation loss = 207790.141, test loss=9941373.000, test mse = 7762362.500, test mae = 469.138\n",
      "epoch=398, loss=56344672.000, validation loss = 207790.141, test loss=9941373.000, test mse = 7762362.500, test mae = 469.151\n",
      "epoch=399, loss=56344672.000, validation loss = 207790.109, test loss=9941373.000, test mse = 7762363.500, test mae = 469.163\n",
      "epoch=400, loss=56344672.000, validation loss = 207790.109, test loss=9941373.000, test mse = 7762364.000, test mae = 469.176\n",
      "epoch=401, loss=56344672.000, validation loss = 207790.109, test loss=9941373.000, test mse = 7762365.500, test mae = 469.188\n",
      "epoch=402, loss=56344672.000, validation loss = 207790.094, test loss=9941373.000, test mse = 7762367.000, test mae = 469.201\n",
      "epoch=403, loss=56344672.000, validation loss = 207790.094, test loss=9941373.000, test mse = 7762368.000, test mae = 469.213\n",
      "epoch=404, loss=56344672.000, validation loss = 207790.078, test loss=9941373.000, test mse = 7762368.000, test mae = 469.225\n",
      "epoch=405, loss=56344672.000, validation loss = 207790.078, test loss=9941373.000, test mse = 7762368.500, test mae = 469.237\n",
      "epoch=406, loss=56344672.000, validation loss = 207790.047, test loss=9941373.000, test mse = 7762369.500, test mae = 469.249\n",
      "epoch=407, loss=56344672.000, validation loss = 207790.031, test loss=9941373.000, test mse = 7762371.000, test mae = 469.261\n",
      "epoch=408, loss=56344672.000, validation loss = 207790.031, test loss=9941373.000, test mse = 7762371.000, test mae = 469.273\n",
      "epoch=409, loss=56344672.000, validation loss = 207790.016, test loss=9941373.000, test mse = 7762371.500, test mae = 469.284\n",
      "epoch=410, loss=56344672.000, validation loss = 207790.000, test loss=9941373.000, test mse = 7762372.000, test mae = 469.296\n",
      "epoch=411, loss=56344672.000, validation loss = 207790.000, test loss=9941373.000, test mse = 7762373.000, test mae = 469.307\n",
      "epoch=412, loss=56344672.000, validation loss = 207790.000, test loss=9941373.000, test mse = 7762374.500, test mae = 469.319\n",
      "epoch=413, loss=56344672.000, validation loss = 207789.984, test loss=9941373.000, test mse = 7762374.500, test mae = 469.330\n",
      "epoch=414, loss=56344672.000, validation loss = 207789.969, test loss=9941373.000, test mse = 7762375.500, test mae = 469.341\n",
      "epoch=415, loss=56344668.000, validation loss = 207789.953, test loss=9941373.000, test mse = 7762376.000, test mae = 469.353\n",
      "epoch=416, loss=56344668.000, validation loss = 207789.953, test loss=9941373.000, test mse = 7762376.500, test mae = 469.364\n",
      "epoch=417, loss=56344668.000, validation loss = 207789.953, test loss=9941373.000, test mse = 7762377.000, test mae = 469.374\n",
      "epoch=418, loss=56344668.000, validation loss = 207789.906, test loss=9941373.000, test mse = 7762377.000, test mae = 469.385\n",
      "epoch=419, loss=56344668.000, validation loss = 207789.891, test loss=9941373.000, test mse = 7762378.500, test mae = 469.396\n",
      "epoch=420, loss=56344668.000, validation loss = 207789.891, test loss=9941373.000, test mse = 7762378.500, test mae = 469.407\n",
      "epoch=421, loss=56344668.000, validation loss = 207789.875, test loss=9941373.000, test mse = 7762379.500, test mae = 469.417\n",
      "epoch=422, loss=56344668.000, validation loss = 207789.859, test loss=9941373.000, test mse = 7762380.000, test mae = 469.428\n",
      "epoch=423, loss=56344664.000, validation loss = 207789.859, test loss=9941373.000, test mse = 7762380.000, test mae = 469.438\n",
      "epoch=424, loss=56344664.000, validation loss = 207789.859, test loss=9941373.000, test mse = 7762381.500, test mae = 469.449\n",
      "epoch=425, loss=56344664.000, validation loss = 207789.859, test loss=9941373.000, test mse = 7762381.500, test mae = 469.459\n",
      "epoch=426, loss=56344664.000, validation loss = 207789.844, test loss=9941373.000, test mse = 7762382.500, test mae = 469.469\n",
      "epoch=427, loss=56344664.000, validation loss = 207789.844, test loss=9941373.000, test mse = 7762384.000, test mae = 469.479\n",
      "epoch=428, loss=56344664.000, validation loss = 207789.828, test loss=9941373.000, test mse = 7762384.000, test mae = 469.489\n",
      "epoch=429, loss=56344664.000, validation loss = 207789.828, test loss=9941373.000, test mse = 7762384.500, test mae = 469.499\n",
      "epoch=430, loss=56344656.000, validation loss = 207789.797, test loss=9941373.000, test mse = 7762384.500, test mae = 469.509\n",
      "epoch=431, loss=56344656.000, validation loss = 207789.797, test loss=9941373.000, test mse = 7762385.000, test mae = 469.518\n",
      "epoch=432, loss=56344656.000, validation loss = 207789.781, test loss=9941373.000, test mse = 7762385.500, test mae = 469.528\n",
      "epoch=433, loss=56344656.000, validation loss = 207789.781, test loss=9941373.000, test mse = 7762387.000, test mae = 469.537\n",
      "epoch=434, loss=56344656.000, validation loss = 207789.766, test loss=9941373.000, test mse = 7762387.000, test mae = 469.547\n",
      "epoch=435, loss=56344656.000, validation loss = 207789.766, test loss=9941373.000, test mse = 7762387.500, test mae = 469.556\n",
      "epoch=436, loss=56344656.000, validation loss = 207789.766, test loss=9941373.000, test mse = 7762387.500, test mae = 469.565\n",
      "epoch=437, loss=56344656.000, validation loss = 207789.719, test loss=9941373.000, test mse = 7762388.000, test mae = 469.575\n",
      "epoch=438, loss=56344656.000, validation loss = 207789.719, test loss=9941373.000, test mse = 7762389.000, test mae = 469.584\n",
      "epoch=439, loss=56344652.000, validation loss = 207789.719, test loss=9941373.000, test mse = 7762389.000, test mae = 469.593\n",
      "epoch=440, loss=56344652.000, validation loss = 207789.672, test loss=9941373.000, test mse = 7762390.500, test mae = 469.602\n",
      "epoch=441, loss=56344652.000, validation loss = 207789.672, test loss=9941373.000, test mse = 7762390.500, test mae = 469.611\n",
      "epoch=442, loss=56344652.000, validation loss = 207789.672, test loss=9941373.000, test mse = 7762391.000, test mae = 469.620\n",
      "epoch=443, loss=56344652.000, validation loss = 207789.656, test loss=9941373.000, test mse = 7762391.000, test mae = 469.628\n",
      "epoch=444, loss=56344652.000, validation loss = 207789.656, test loss=9941373.000, test mse = 7762392.000, test mae = 469.637\n",
      "epoch=445, loss=56344652.000, validation loss = 207789.641, test loss=9941373.000, test mse = 7762392.000, test mae = 469.646\n",
      "epoch=446, loss=56344652.000, validation loss = 207789.625, test loss=9941373.000, test mse = 7762392.500, test mae = 469.654\n",
      "epoch=447, loss=56344652.000, validation loss = 207789.609, test loss=9941373.000, test mse = 7762393.000, test mae = 469.662\n",
      "epoch=448, loss=56344652.000, validation loss = 207789.609, test loss=9941373.000, test mse = 7762393.000, test mae = 469.671\n",
      "epoch=449, loss=56344652.000, validation loss = 207789.594, test loss=9941373.000, test mse = 7762393.500, test mae = 469.679\n",
      "epoch=450, loss=56344652.000, validation loss = 207789.594, test loss=9941373.000, test mse = 7762394.500, test mae = 469.687\n",
      "epoch=451, loss=56344652.000, validation loss = 207789.578, test loss=9941373.000, test mse = 7762394.500, test mae = 469.695\n",
      "epoch=452, loss=56344652.000, validation loss = 207789.578, test loss=9941373.000, test mse = 7762394.500, test mae = 469.703\n",
      "epoch=453, loss=56344652.000, validation loss = 207789.578, test loss=9941373.000, test mse = 7762395.500, test mae = 469.711\n",
      "epoch=454, loss=56344644.000, validation loss = 207789.547, test loss=9941373.000, test mse = 7762396.000, test mae = 469.719\n",
      "epoch=455, loss=56344644.000, validation loss = 207789.531, test loss=9941373.000, test mse = 7762396.000, test mae = 469.727\n",
      "epoch=456, loss=56344644.000, validation loss = 207789.531, test loss=9941373.000, test mse = 7762396.500, test mae = 469.734\n",
      "epoch=457, loss=56344644.000, validation loss = 207789.531, test loss=9941373.000, test mse = 7762396.500, test mae = 469.742\n",
      "epoch=458, loss=56344644.000, validation loss = 207789.516, test loss=9941373.000, test mse = 7762397.000, test mae = 469.750\n",
      "epoch=459, loss=56344644.000, validation loss = 207789.500, test loss=9941373.000, test mse = 7762397.500, test mae = 469.757\n",
      "epoch=460, loss=56344644.000, validation loss = 207789.500, test loss=9941373.000, test mse = 7762397.500, test mae = 469.765\n",
      "epoch=461, loss=56344640.000, validation loss = 207789.484, test loss=9941373.000, test mse = 7762399.000, test mae = 469.772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=462, loss=56344640.000, validation loss = 207789.484, test loss=9941373.000, test mse = 7762399.000, test mae = 469.780\n",
      "epoch=463, loss=56344640.000, validation loss = 207789.484, test loss=9941373.000, test mse = 7762399.000, test mae = 469.787\n",
      "epoch=464, loss=56344640.000, validation loss = 207789.484, test loss=9941373.000, test mse = 7762400.000, test mae = 469.794\n",
      "epoch=465, loss=56344640.000, validation loss = 207789.484, test loss=9941373.000, test mse = 7762400.000, test mae = 469.801\n",
      "epoch=466, loss=56344640.000, validation loss = 207789.453, test loss=9941373.000, test mse = 7762400.000, test mae = 469.809\n",
      "epoch=467, loss=56344636.000, validation loss = 207789.453, test loss=9941373.000, test mse = 7762401.000, test mae = 469.816\n",
      "epoch=468, loss=56344636.000, validation loss = 207789.453, test loss=9941373.000, test mse = 7762401.000, test mae = 469.823\n",
      "epoch=469, loss=56344636.000, validation loss = 207789.422, test loss=9941373.000, test mse = 7762401.000, test mae = 469.830\n",
      "epoch=470, loss=56344636.000, validation loss = 207789.406, test loss=9941373.000, test mse = 7762401.500, test mae = 469.837\n",
      "epoch=471, loss=56344636.000, validation loss = 207789.406, test loss=9941373.000, test mse = 7762401.500, test mae = 469.844\n",
      "epoch=472, loss=56344636.000, validation loss = 207789.406, test loss=9941373.000, test mse = 7762401.500, test mae = 469.851\n",
      "epoch=473, loss=56344636.000, validation loss = 207789.406, test loss=9941373.000, test mse = 7762402.500, test mae = 469.858\n",
      "epoch=474, loss=56344636.000, validation loss = 207789.391, test loss=9941373.000, test mse = 7762403.000, test mae = 469.865\n",
      "epoch=475, loss=56344636.000, validation loss = 207789.391, test loss=9941373.000, test mse = 7762403.000, test mae = 469.872\n",
      "epoch=476, loss=56344636.000, validation loss = 207789.375, test loss=9941373.000, test mse = 7762403.000, test mae = 469.879\n",
      "epoch=477, loss=56344636.000, validation loss = 207789.359, test loss=9941373.000, test mse = 7762403.000, test mae = 469.885\n",
      "epoch=478, loss=56344636.000, validation loss = 207789.359, test loss=9941373.000, test mse = 7762403.500, test mae = 469.892\n",
      "epoch=479, loss=56344636.000, validation loss = 207789.344, test loss=9941373.000, test mse = 7762404.000, test mae = 469.899\n",
      "epoch=480, loss=56344636.000, validation loss = 207789.344, test loss=9941373.000, test mse = 7762404.000, test mae = 469.906\n",
      "epoch=481, loss=56344636.000, validation loss = 207789.328, test loss=9941373.000, test mse = 7762405.000, test mae = 469.912\n",
      "epoch=482, loss=56344636.000, validation loss = 207789.328, test loss=9941373.000, test mse = 7762405.000, test mae = 469.919\n",
      "epoch=483, loss=56344636.000, validation loss = 207789.328, test loss=9941373.000, test mse = 7762405.500, test mae = 469.925\n",
      "epoch=484, loss=56344636.000, validation loss = 207789.328, test loss=9941373.000, test mse = 7762406.500, test mae = 469.932\n",
      "epoch=485, loss=56344636.000, validation loss = 207789.281, test loss=9941373.000, test mse = 7762406.500, test mae = 469.939\n",
      "epoch=486, loss=56344632.000, validation loss = 207789.281, test loss=9941373.000, test mse = 7762406.500, test mae = 469.945\n",
      "epoch=487, loss=56344632.000, validation loss = 207789.281, test loss=9941373.000, test mse = 7762406.500, test mae = 469.951\n",
      "epoch=488, loss=56344632.000, validation loss = 207789.281, test loss=9941373.000, test mse = 7762406.500, test mae = 469.958\n",
      "epoch=489, loss=56344632.000, validation loss = 207789.266, test loss=9941373.000, test mse = 7762407.500, test mae = 469.964\n",
      "epoch=490, loss=56344624.000, validation loss = 207789.266, test loss=9941373.000, test mse = 7762408.000, test mae = 469.971\n",
      "epoch=491, loss=56344624.000, validation loss = 207789.250, test loss=9941373.000, test mse = 7762408.000, test mae = 469.977\n",
      "epoch=492, loss=56344620.000, validation loss = 207789.250, test loss=9941373.000, test mse = 7762408.000, test mae = 469.983\n",
      "epoch=493, loss=56344620.000, validation loss = 207789.234, test loss=9941373.000, test mse = 7762408.500, test mae = 469.989\n",
      "epoch=494, loss=56344620.000, validation loss = 207789.234, test loss=9941373.000, test mse = 7762408.500, test mae = 469.995\n",
      "epoch=495, loss=56344620.000, validation loss = 207789.234, test loss=9941373.000, test mse = 7762408.500, test mae = 470.002\n",
      "epoch=496, loss=56344620.000, validation loss = 207789.219, test loss=9941373.000, test mse = 7762409.000, test mae = 470.008\n",
      "epoch=497, loss=56344620.000, validation loss = 207789.219, test loss=9941373.000, test mse = 7762409.000, test mae = 470.014\n",
      "epoch=498, loss=56344620.000, validation loss = 207789.172, test loss=9941373.000, test mse = 7762409.500, test mae = 470.020\n",
      "epoch=499, loss=56344620.000, validation loss = 207789.172, test loss=9941373.000, test mse = 7762409.500, test mae = 470.026\n",
      "epoch=500, loss=56344620.000, validation loss = 207789.172, test loss=9941373.000, test mse = 7762409.500, test mae = 470.032\n",
      "epoch=501, loss=56344620.000, validation loss = 207789.172, test loss=9941373.000, test mse = 7762409.500, test mae = 470.038\n",
      "epoch=502, loss=56344620.000, validation loss = 207789.172, test loss=9941373.000, test mse = 7762409.500, test mae = 470.044\n",
      "epoch=503, loss=56344620.000, validation loss = 207789.156, test loss=9941373.000, test mse = 7762410.500, test mae = 470.049\n",
      "epoch=504, loss=56344620.000, validation loss = 207789.141, test loss=9941373.000, test mse = 7762410.500, test mae = 470.055\n",
      "epoch=505, loss=56344620.000, validation loss = 207789.141, test loss=9941373.000, test mse = 7762411.500, test mae = 470.061\n",
      "epoch=506, loss=56344620.000, validation loss = 207789.141, test loss=9941373.000, test mse = 7762411.500, test mae = 470.067\n",
      "epoch=507, loss=56344620.000, validation loss = 207789.125, test loss=9941373.000, test mse = 7762411.500, test mae = 470.072\n",
      "epoch=508, loss=56344620.000, validation loss = 207789.125, test loss=9941373.000, test mse = 7762411.500, test mae = 470.078\n",
      "epoch=509, loss=56344620.000, validation loss = 207789.109, test loss=9941373.000, test mse = 7762411.500, test mae = 470.084\n",
      "epoch=510, loss=56344620.000, validation loss = 207789.109, test loss=9941373.000, test mse = 7762411.500, test mae = 470.089\n",
      "epoch=511, loss=56344620.000, validation loss = 207789.094, test loss=9941373.000, test mse = 7762412.500, test mae = 470.095\n",
      "epoch=512, loss=56344620.000, validation loss = 207789.078, test loss=9941373.000, test mse = 7762412.500, test mae = 470.100\n",
      "epoch=513, loss=56344620.000, validation loss = 207789.078, test loss=9941373.000, test mse = 7762412.500, test mae = 470.106\n",
      "epoch=514, loss=56344616.000, validation loss = 207789.078, test loss=9941373.000, test mse = 7762412.500, test mae = 470.111\n",
      "epoch=515, loss=56344616.000, validation loss = 207789.078, test loss=9941373.000, test mse = 7762412.500, test mae = 470.117\n",
      "epoch=516, loss=56344616.000, validation loss = 207789.031, test loss=9941373.000, test mse = 7762413.500, test mae = 470.122\n",
      "epoch=517, loss=56344616.000, validation loss = 207789.031, test loss=9941373.000, test mse = 7762413.500, test mae = 470.127\n",
      "epoch=518, loss=56344616.000, validation loss = 207789.031, test loss=9941373.000, test mse = 7762413.500, test mae = 470.133\n",
      "epoch=519, loss=56344616.000, validation loss = 207789.031, test loss=9941373.000, test mse = 7762413.500, test mae = 470.138\n",
      "epoch=520, loss=56344612.000, validation loss = 207789.016, test loss=9941373.000, test mse = 7762413.500, test mae = 470.143\n",
      "epoch=521, loss=56344612.000, validation loss = 207789.000, test loss=9941373.000, test mse = 7762414.500, test mae = 470.148\n",
      "epoch=522, loss=56344612.000, validation loss = 207789.000, test loss=9941373.000, test mse = 7762414.500, test mae = 470.153\n",
      "epoch=523, loss=56344612.000, validation loss = 207789.000, test loss=9941373.000, test mse = 7762414.500, test mae = 470.159\n",
      "epoch=524, loss=56344612.000, validation loss = 207789.000, test loss=9941373.000, test mse = 7762415.000, test mae = 470.164\n",
      "epoch=525, loss=56344612.000, validation loss = 207788.984, test loss=9941373.000, test mse = 7762415.000, test mae = 470.169\n",
      "epoch=526, loss=56344612.000, validation loss = 207788.984, test loss=9941373.000, test mse = 7762416.000, test mae = 470.174\n",
      "epoch=527, loss=56344612.000, validation loss = 207788.984, test loss=9941373.000, test mse = 7762416.000, test mae = 470.179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=528, loss=56344612.000, validation loss = 207788.984, test loss=9941373.000, test mse = 7762416.000, test mae = 470.184\n",
      "epoch=529, loss=56344612.000, validation loss = 207788.969, test loss=9941373.000, test mse = 7762416.000, test mae = 470.188\n",
      "epoch=530, loss=56344608.000, validation loss = 207788.969, test loss=9941373.000, test mse = 7762416.000, test mae = 470.193\n",
      "epoch=531, loss=56344608.000, validation loss = 207788.953, test loss=9941373.000, test mse = 7762416.500, test mae = 470.198\n",
      "epoch=532, loss=56344608.000, validation loss = 207788.953, test loss=9941373.000, test mse = 7762417.000, test mae = 470.203\n",
      "epoch=533, loss=56344608.000, validation loss = 207788.953, test loss=9941373.000, test mse = 7762417.000, test mae = 470.208\n",
      "epoch=534, loss=56344608.000, validation loss = 207788.953, test loss=9941373.000, test mse = 7762417.000, test mae = 470.212\n",
      "epoch=535, loss=56344608.000, validation loss = 207788.922, test loss=9941373.000, test mse = 7762417.000, test mae = 470.217\n",
      "epoch=536, loss=56344608.000, validation loss = 207788.922, test loss=9941373.000, test mse = 7762417.000, test mae = 470.222\n",
      "epoch=537, loss=56344608.000, validation loss = 207788.922, test loss=9941373.000, test mse = 7762417.500, test mae = 470.226\n",
      "epoch=538, loss=56344608.000, validation loss = 207788.922, test loss=9941373.000, test mse = 7762417.500, test mae = 470.231\n",
      "epoch=539, loss=56344608.000, validation loss = 207788.922, test loss=9941373.000, test mse = 7762417.500, test mae = 470.236\n",
      "epoch=540, loss=56344608.000, validation loss = 207788.922, test loss=9941373.000, test mse = 7762417.500, test mae = 470.240\n",
      "epoch=541, loss=56344604.000, validation loss = 207788.891, test loss=9941373.000, test mse = 7762417.500, test mae = 470.244\n",
      "epoch=542, loss=56344604.000, validation loss = 207788.891, test loss=9941373.000, test mse = 7762417.500, test mae = 470.249\n",
      "epoch=543, loss=56344604.000, validation loss = 207788.891, test loss=9941373.000, test mse = 7762417.500, test mae = 470.253\n",
      "epoch=544, loss=56344604.000, validation loss = 207788.891, test loss=9941373.000, test mse = 7762417.500, test mae = 470.258\n",
      "epoch=545, loss=56344604.000, validation loss = 207788.891, test loss=9941373.000, test mse = 7762417.500, test mae = 470.262\n",
      "epoch=546, loss=56344604.000, validation loss = 207788.891, test loss=9941373.000, test mse = 7762419.000, test mae = 470.266\n",
      "epoch=547, loss=56344604.000, validation loss = 207788.859, test loss=9941373.000, test mse = 7762419.000, test mae = 470.271\n",
      "epoch=548, loss=56344604.000, validation loss = 207788.859, test loss=9941373.000, test mse = 7762419.000, test mae = 470.275\n",
      "epoch=549, loss=56344600.000, validation loss = 207788.859, test loss=9941373.000, test mse = 7762419.000, test mae = 470.279\n",
      "epoch=550, loss=56344592.000, validation loss = 207788.859, test loss=9941373.000, test mse = 7762419.000, test mae = 470.283\n",
      "epoch=551, loss=56344592.000, validation loss = 207788.859, test loss=9941373.000, test mse = 7762419.000, test mae = 470.288\n",
      "epoch=552, loss=56344592.000, validation loss = 207788.859, test loss=9941373.000, test mse = 7762419.000, test mae = 470.292\n",
      "epoch=553, loss=56344592.000, validation loss = 207788.859, test loss=9941373.000, test mse = 7762419.000, test mae = 470.296\n",
      "epoch=554, loss=56344592.000, validation loss = 207788.828, test loss=9941373.000, test mse = 7762419.000, test mae = 470.300\n",
      "epoch=555, loss=56344592.000, validation loss = 207788.828, test loss=9941373.000, test mse = 7762419.000, test mae = 470.304\n",
      "epoch=556, loss=56344592.000, validation loss = 207788.828, test loss=9941373.000, test mse = 7762419.000, test mae = 470.308\n",
      "epoch=557, loss=56344592.000, validation loss = 207788.781, test loss=9941373.000, test mse = 7762419.000, test mae = 470.312\n",
      "epoch=558, loss=56344592.000, validation loss = 207788.781, test loss=9941373.000, test mse = 7762419.500, test mae = 470.316\n",
      "epoch=559, loss=56344592.000, validation loss = 207788.781, test loss=9941373.000, test mse = 7762419.500, test mae = 470.320\n",
      "epoch=560, loss=56344592.000, validation loss = 207788.781, test loss=9941373.000, test mse = 7762419.500, test mae = 470.324\n",
      "epoch=561, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762420.000, test mae = 470.327\n",
      "epoch=562, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762420.000, test mae = 470.331\n",
      "epoch=563, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762420.000, test mae = 470.335\n",
      "epoch=564, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762420.500, test mae = 470.339\n",
      "epoch=565, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762420.500, test mae = 470.343\n",
      "epoch=566, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762421.000, test mae = 470.346\n",
      "epoch=567, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762421.000, test mae = 470.350\n",
      "epoch=568, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762421.000, test mae = 470.354\n",
      "epoch=569, loss=56344592.000, validation loss = 207788.734, test loss=9941373.000, test mse = 7762421.500, test mae = 470.357\n",
      "epoch=570, loss=56344592.000, validation loss = 207788.703, test loss=9941373.000, test mse = 7762421.500, test mae = 470.361\n",
      "epoch=571, loss=56344592.000, validation loss = 207788.703, test loss=9941373.000, test mse = 7762421.500, test mae = 470.364\n",
      "epoch=572, loss=56344592.000, validation loss = 207788.703, test loss=9941373.000, test mse = 7762421.500, test mae = 470.368\n",
      "epoch=573, loss=56344592.000, validation loss = 207788.703, test loss=9941373.000, test mse = 7762421.500, test mae = 470.371\n",
      "epoch=574, loss=56344592.000, validation loss = 207788.703, test loss=9941373.000, test mse = 7762421.500, test mae = 470.375\n",
      "epoch=575, loss=56344588.000, validation loss = 207788.703, test loss=9941373.000, test mse = 7762421.500, test mae = 470.378\n",
      "epoch=576, loss=56344588.000, validation loss = 207788.672, test loss=9941373.000, test mse = 7762421.500, test mae = 470.382\n",
      "epoch=577, loss=56344588.000, validation loss = 207788.672, test loss=9941373.000, test mse = 7762422.500, test mae = 470.385\n",
      "epoch=578, loss=56344588.000, validation loss = 207788.672, test loss=9941373.000, test mse = 7762422.500, test mae = 470.389\n",
      "epoch=579, loss=56344588.000, validation loss = 207788.656, test loss=9941373.000, test mse = 7762422.500, test mae = 470.392\n",
      "epoch=580, loss=56344588.000, validation loss = 207788.656, test loss=9941373.000, test mse = 7762422.500, test mae = 470.395\n",
      "epoch=581, loss=56344588.000, validation loss = 207788.656, test loss=9941373.000, test mse = 7762422.500, test mae = 470.398\n",
      "epoch=582, loss=56344588.000, validation loss = 207788.656, test loss=9941373.000, test mse = 7762422.500, test mae = 470.402\n",
      "epoch=583, loss=56344588.000, validation loss = 207788.656, test loss=9941373.000, test mse = 7762422.500, test mae = 470.405\n",
      "epoch=584, loss=56344588.000, validation loss = 207788.641, test loss=9941373.000, test mse = 7762422.500, test mae = 470.408\n",
      "epoch=585, loss=56344588.000, validation loss = 207788.641, test loss=9941373.000, test mse = 7762422.500, test mae = 470.412\n",
      "epoch=586, loss=56344588.000, validation loss = 207788.641, test loss=9941373.000, test mse = 7762423.000, test mae = 470.415\n",
      "epoch=587, loss=56344588.000, validation loss = 207788.625, test loss=9941373.000, test mse = 7762423.000, test mae = 470.418\n",
      "epoch=588, loss=56344580.000, validation loss = 207788.625, test loss=9941373.000, test mse = 7762423.000, test mae = 470.421\n",
      "epoch=589, loss=56344580.000, validation loss = 207788.625, test loss=9941373.000, test mse = 7762424.000, test mae = 470.424\n",
      "epoch=590, loss=56344580.000, validation loss = 207788.609, test loss=9941373.000, test mse = 7762424.000, test mae = 470.427\n",
      "epoch=591, loss=56344580.000, validation loss = 207788.609, test loss=9941373.000, test mse = 7762424.000, test mae = 470.430\n",
      "epoch=592, loss=56344580.000, validation loss = 207788.594, test loss=9941373.000, test mse = 7762424.000, test mae = 470.433\n",
      "epoch=593, loss=56344580.000, validation loss = 207788.594, test loss=9941373.000, test mse = 7762424.000, test mae = 470.436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=594, loss=56344580.000, validation loss = 207788.594, test loss=9941373.000, test mse = 7762424.000, test mae = 470.439\n",
      "epoch=595, loss=56344580.000, validation loss = 207788.594, test loss=9941373.000, test mse = 7762424.000, test mae = 470.442\n",
      "epoch=596, loss=56344580.000, validation loss = 207788.578, test loss=9941371.000, test mse = 7762424.000, test mae = 470.445\n",
      "epoch=597, loss=56344580.000, validation loss = 207788.578, test loss=9941371.000, test mse = 7762424.000, test mae = 470.448\n",
      "epoch=598, loss=56344580.000, validation loss = 207788.578, test loss=9941371.000, test mse = 7762424.000, test mae = 470.451\n",
      "epoch=599, loss=56344580.000, validation loss = 207788.578, test loss=9941371.000, test mse = 7762424.000, test mae = 470.454\n",
      "epoch=600, loss=56344580.000, validation loss = 207788.578, test loss=9941371.000, test mse = 7762424.000, test mae = 470.456\n",
      "epoch=601, loss=56344580.000, validation loss = 207788.547, test loss=9941371.000, test mse = 7762424.000, test mae = 470.459\n",
      "epoch=602, loss=56344580.000, validation loss = 207788.547, test loss=9941371.000, test mse = 7762424.000, test mae = 470.462\n",
      "epoch=603, loss=56344580.000, validation loss = 207788.547, test loss=9941370.000, test mse = 7762424.500, test mae = 470.465\n",
      "epoch=604, loss=56344580.000, validation loss = 207788.547, test loss=9941370.000, test mse = 7762424.500, test mae = 470.467\n",
      "epoch=605, loss=56344580.000, validation loss = 207788.531, test loss=9941370.000, test mse = 7762424.500, test mae = 470.470\n",
      "epoch=606, loss=56344576.000, validation loss = 207788.531, test loss=9941370.000, test mse = 7762424.500, test mae = 470.473\n",
      "epoch=607, loss=56344576.000, validation loss = 207788.516, test loss=9941370.000, test mse = 7762424.500, test mae = 470.475\n",
      "epoch=608, loss=56344576.000, validation loss = 207788.516, test loss=9941370.000, test mse = 7762425.000, test mae = 470.478\n",
      "epoch=609, loss=56344576.000, validation loss = 207788.516, test loss=9941370.000, test mse = 7762425.000, test mae = 470.481\n",
      "epoch=610, loss=56344576.000, validation loss = 207788.516, test loss=9941370.000, test mse = 7762425.000, test mae = 470.483\n",
      "epoch=611, loss=56344576.000, validation loss = 207788.500, test loss=9941370.000, test mse = 7762425.000, test mae = 470.486\n",
      "epoch=612, loss=56344576.000, validation loss = 207788.500, test loss=9941370.000, test mse = 7762425.000, test mae = 470.489\n",
      "epoch=613, loss=56344572.000, validation loss = 207788.484, test loss=9941370.000, test mse = 7762425.000, test mae = 470.491\n",
      "epoch=614, loss=56344572.000, validation loss = 207788.484, test loss=9941370.000, test mse = 7762425.000, test mae = 470.494\n",
      "epoch=615, loss=56344572.000, validation loss = 207788.484, test loss=9941370.000, test mse = 7762425.000, test mae = 470.496\n",
      "epoch=616, loss=56344572.000, validation loss = 207788.484, test loss=9941370.000, test mse = 7762425.500, test mae = 470.499\n",
      "epoch=617, loss=56344572.000, validation loss = 207788.469, test loss=9941370.000, test mse = 7762425.500, test mae = 470.501\n",
      "epoch=618, loss=56344572.000, validation loss = 207788.469, test loss=9941370.000, test mse = 7762425.500, test mae = 470.504\n",
      "epoch=619, loss=56344572.000, validation loss = 207788.469, test loss=9941370.000, test mse = 7762425.500, test mae = 470.506\n",
      "epoch=620, loss=56344572.000, validation loss = 207788.469, test loss=9941370.000, test mse = 7762425.500, test mae = 470.508\n",
      "epoch=621, loss=56344572.000, validation loss = 207788.469, test loss=9941370.000, test mse = 7762425.500, test mae = 470.511\n",
      "epoch=622, loss=56344568.000, validation loss = 207788.469, test loss=9941370.000, test mse = 7762425.500, test mae = 470.513\n",
      "epoch=623, loss=56344568.000, validation loss = 207788.469, test loss=9941370.000, test mse = 7762425.500, test mae = 470.516\n",
      "epoch=624, loss=56344568.000, validation loss = 207788.453, test loss=9941370.000, test mse = 7762425.500, test mae = 470.518\n",
      "epoch=625, loss=56344568.000, validation loss = 207788.453, test loss=9941370.000, test mse = 7762425.500, test mae = 470.520\n",
      "epoch=626, loss=56344568.000, validation loss = 207788.453, test loss=9941370.000, test mse = 7762425.500, test mae = 470.522\n",
      "epoch=627, loss=56344568.000, validation loss = 207788.422, test loss=9941370.000, test mse = 7762425.500, test mae = 470.525\n",
      "epoch=628, loss=56344568.000, validation loss = 207788.422, test loss=9941370.000, test mse = 7762425.500, test mae = 470.527\n",
      "epoch=629, loss=56344568.000, validation loss = 207788.422, test loss=9941370.000, test mse = 7762425.500, test mae = 470.529\n",
      "epoch=630, loss=56344568.000, validation loss = 207788.422, test loss=9941370.000, test mse = 7762425.500, test mae = 470.531\n",
      "epoch=631, loss=56344568.000, validation loss = 207788.422, test loss=9941370.000, test mse = 7762425.500, test mae = 470.534\n",
      "epoch=632, loss=56344568.000, validation loss = 207788.422, test loss=9941370.000, test mse = 7762425.500, test mae = 470.536\n",
      "epoch=633, loss=56344568.000, validation loss = 207788.422, test loss=9941370.000, test mse = 7762425.500, test mae = 470.538\n",
      "epoch=634, loss=56344568.000, validation loss = 207788.422, test loss=9941370.000, test mse = 7762425.500, test mae = 470.540\n",
      "epoch=635, loss=56344568.000, validation loss = 207788.391, test loss=9941370.000, test mse = 7762425.500, test mae = 470.542\n",
      "epoch=636, loss=56344568.000, validation loss = 207788.391, test loss=9941370.000, test mse = 7762425.500, test mae = 470.544\n",
      "epoch=637, loss=56344568.000, validation loss = 207788.391, test loss=9941370.000, test mse = 7762425.500, test mae = 470.546\n",
      "epoch=638, loss=56344568.000, validation loss = 207788.391, test loss=9941370.000, test mse = 7762426.500, test mae = 470.549\n",
      "epoch=639, loss=56344568.000, validation loss = 207788.375, test loss=9941370.000, test mse = 7762426.500, test mae = 470.551\n",
      "epoch=640, loss=56344568.000, validation loss = 207788.375, test loss=9941370.000, test mse = 7762426.500, test mae = 470.553\n",
      "epoch=641, loss=56344568.000, validation loss = 207788.375, test loss=9941370.000, test mse = 7762426.500, test mae = 470.555\n",
      "epoch=642, loss=56344568.000, validation loss = 207788.375, test loss=9941370.000, test mse = 7762426.500, test mae = 470.557\n",
      "epoch=643, loss=56344564.000, validation loss = 207788.375, test loss=9941370.000, test mse = 7762426.500, test mae = 470.559\n",
      "epoch=644, loss=56344564.000, validation loss = 207788.375, test loss=9941370.000, test mse = 7762426.500, test mae = 470.561\n",
      "epoch=645, loss=56344564.000, validation loss = 207788.359, test loss=9941370.000, test mse = 7762426.500, test mae = 470.563\n",
      "epoch=646, loss=56344564.000, validation loss = 207788.359, test loss=9941370.000, test mse = 7762426.500, test mae = 470.565\n",
      "epoch=647, loss=56344564.000, validation loss = 207788.359, test loss=9941370.000, test mse = 7762426.500, test mae = 470.566\n",
      "epoch=648, loss=56344564.000, validation loss = 207788.344, test loss=9941370.000, test mse = 7762426.500, test mae = 470.568\n",
      "epoch=649, loss=56344564.000, validation loss = 207788.344, test loss=9941370.000, test mse = 7762426.500, test mae = 470.570\n",
      "epoch=650, loss=56344564.000, validation loss = 207788.344, test loss=9941370.000, test mse = 7762426.500, test mae = 470.572\n",
      "epoch=651, loss=56344564.000, validation loss = 207788.328, test loss=9941370.000, test mse = 7762426.500, test mae = 470.574\n",
      "epoch=652, loss=56344564.000, validation loss = 207788.328, test loss=9941370.000, test mse = 7762426.500, test mae = 470.576\n",
      "epoch=653, loss=56344564.000, validation loss = 207788.328, test loss=9941370.000, test mse = 7762426.500, test mae = 470.578\n",
      "epoch=654, loss=56344564.000, validation loss = 207788.328, test loss=9941370.000, test mse = 7762426.500, test mae = 470.580\n",
      "epoch=655, loss=56344564.000, validation loss = 207788.328, test loss=9941370.000, test mse = 7762426.500, test mae = 470.581\n",
      "epoch=656, loss=56344564.000, validation loss = 207788.328, test loss=9941370.000, test mse = 7762426.500, test mae = 470.583\n",
      "epoch=657, loss=56344564.000, validation loss = 207788.297, test loss=9941370.000, test mse = 7762426.500, test mae = 470.585\n",
      "epoch=658, loss=56344564.000, validation loss = 207788.297, test loss=9941370.000, test mse = 7762427.500, test mae = 470.587\n",
      "epoch=659, loss=56344556.000, validation loss = 207788.297, test loss=9941370.000, test mse = 7762427.500, test mae = 470.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=660, loss=56344556.000, validation loss = 207788.297, test loss=9941370.000, test mse = 7762427.500, test mae = 470.590\n",
      "epoch=661, loss=56344556.000, validation loss = 207788.297, test loss=9941370.000, test mse = 7762427.500, test mae = 470.592\n",
      "epoch=662, loss=56344556.000, validation loss = 207788.281, test loss=9941370.000, test mse = 7762427.500, test mae = 470.594\n",
      "epoch=663, loss=56344556.000, validation loss = 207788.281, test loss=9941370.000, test mse = 7762427.500, test mae = 470.595\n",
      "epoch=664, loss=56344556.000, validation loss = 207788.281, test loss=9941370.000, test mse = 7762427.500, test mae = 470.597\n",
      "epoch=665, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.599\n",
      "epoch=666, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.600\n",
      "epoch=667, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.602\n",
      "epoch=668, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.604\n",
      "epoch=669, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.605\n",
      "epoch=670, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.607\n",
      "epoch=671, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.608\n",
      "epoch=672, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.610\n",
      "epoch=673, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.612\n",
      "epoch=674, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.613\n",
      "epoch=675, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.615\n",
      "epoch=676, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.616\n",
      "epoch=677, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.618\n",
      "epoch=678, loss=56344556.000, validation loss = 207788.266, test loss=9941370.000, test mse = 7762427.500, test mae = 470.619\n",
      "epoch=679, loss=56344556.000, validation loss = 207788.250, test loss=9941370.000, test mse = 7762427.500, test mae = 470.621\n",
      "epoch=680, loss=56344556.000, validation loss = 207788.250, test loss=9941370.000, test mse = 7762427.500, test mae = 470.622\n",
      "epoch=681, loss=56344556.000, validation loss = 207788.250, test loss=9941370.000, test mse = 7762427.500, test mae = 470.624\n",
      "epoch=682, loss=56344556.000, validation loss = 207788.250, test loss=9941370.000, test mse = 7762427.500, test mae = 470.625\n",
      "epoch=683, loss=56344556.000, validation loss = 207788.250, test loss=9941370.000, test mse = 7762427.500, test mae = 470.627\n",
      "epoch=684, loss=56344556.000, validation loss = 207788.250, test loss=9941370.000, test mse = 7762427.500, test mae = 470.628\n",
      "epoch=685, loss=56344552.000, validation loss = 207788.250, test loss=9941370.000, test mse = 7762427.500, test mae = 470.629\n",
      "epoch=686, loss=56344552.000, validation loss = 207788.250, test loss=9941370.000, test mse = 7762427.500, test mae = 470.631\n",
      "epoch=687, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762427.500, test mae = 470.632\n",
      "epoch=688, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762427.500, test mae = 470.634\n",
      "epoch=689, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762427.500, test mae = 470.635\n",
      "epoch=690, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762427.500, test mae = 470.636\n",
      "epoch=691, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762427.500, test mae = 470.638\n",
      "epoch=692, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762427.500, test mae = 470.639\n",
      "epoch=693, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762428.000, test mae = 470.640\n",
      "epoch=694, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762428.000, test mae = 470.642\n",
      "epoch=695, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762428.000, test mae = 470.643\n",
      "epoch=696, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762428.000, test mae = 470.644\n",
      "epoch=697, loss=56344552.000, validation loss = 207788.219, test loss=9941370.000, test mse = 7762428.000, test mae = 470.646\n",
      "epoch=698, loss=56344552.000, validation loss = 207788.203, test loss=9941370.000, test mse = 7762428.000, test mae = 470.647\n",
      "epoch=699, loss=56344552.000, validation loss = 207788.203, test loss=9941370.000, test mse = 7762428.000, test mae = 470.648\n",
      "epoch=700, loss=56344552.000, validation loss = 207788.203, test loss=9941370.000, test mse = 7762428.000, test mae = 470.649\n",
      "epoch=701, loss=56344552.000, validation loss = 207788.203, test loss=9941370.000, test mse = 7762428.000, test mae = 470.651\n",
      "epoch=702, loss=56344552.000, validation loss = 207788.203, test loss=9941370.000, test mse = 7762428.000, test mae = 470.652\n",
      "epoch=703, loss=56344552.000, validation loss = 207788.203, test loss=9941370.000, test mse = 7762428.000, test mae = 470.653\n",
      "epoch=704, loss=56344552.000, validation loss = 207788.203, test loss=9941370.000, test mse = 7762428.000, test mae = 470.654\n",
      "epoch=705, loss=56344548.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.000, test mae = 470.655\n",
      "epoch=706, loss=56344548.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.000, test mae = 470.657\n",
      "epoch=707, loss=56344548.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.000, test mae = 470.658\n",
      "epoch=708, loss=56344548.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.000, test mae = 470.659\n",
      "epoch=709, loss=56344548.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.000, test mae = 470.660\n",
      "epoch=710, loss=56344548.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.000, test mae = 470.661\n",
      "epoch=711, loss=56344544.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.000, test mae = 470.662\n",
      "epoch=712, loss=56344544.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.000, test mae = 470.663\n",
      "epoch=713, loss=56344544.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762428.500, test mae = 470.665\n",
      "epoch=714, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762428.500, test mae = 470.666\n",
      "epoch=715, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.000, test mae = 470.667\n",
      "epoch=716, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.668\n",
      "epoch=717, loss=56344544.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762429.500, test mae = 470.669\n",
      "epoch=718, loss=56344544.000, validation loss = 207788.156, test loss=9941370.000, test mse = 7762429.500, test mae = 470.670\n",
      "epoch=719, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.671\n",
      "epoch=720, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.672\n",
      "epoch=721, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.673\n",
      "epoch=722, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.674\n",
      "epoch=723, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.675\n",
      "epoch=724, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.676\n",
      "epoch=725, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=726, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.678\n",
      "epoch=727, loss=56344544.000, validation loss = 207788.141, test loss=9941370.000, test mse = 7762429.500, test mae = 470.679\n",
      "epoch=728, loss=56344544.000, validation loss = 207788.109, test loss=9941370.000, test mse = 7762429.500, test mae = 470.680\n",
      "epoch=729, loss=56344544.000, validation loss = 207788.109, test loss=9941370.000, test mse = 7762429.500, test mae = 470.681\n",
      "epoch=730, loss=56344544.000, validation loss = 207788.109, test loss=9941370.000, test mse = 7762429.500, test mae = 470.682\n",
      "epoch=731, loss=56344544.000, validation loss = 207788.109, test loss=9941370.000, test mse = 7762429.500, test mae = 470.683\n",
      "epoch=732, loss=56344544.000, validation loss = 207788.109, test loss=9941370.000, test mse = 7762429.500, test mae = 470.684\n",
      "epoch=733, loss=56344544.000, validation loss = 207788.109, test loss=9941370.000, test mse = 7762429.500, test mae = 470.685\n",
      "epoch=734, loss=56344544.000, validation loss = 207788.109, test loss=9941370.000, test mse = 7762429.500, test mae = 470.686\n",
      "epoch=735, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.687\n",
      "epoch=736, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.688\n",
      "epoch=737, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.688\n",
      "epoch=738, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.689\n",
      "epoch=739, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.690\n",
      "epoch=740, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.691\n",
      "epoch=741, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.692\n",
      "epoch=742, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.693\n",
      "epoch=743, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.694\n",
      "epoch=744, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.694\n",
      "epoch=745, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.695\n",
      "epoch=746, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.696\n",
      "epoch=747, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.697\n",
      "epoch=748, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.698\n",
      "epoch=749, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.699\n",
      "epoch=750, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.699\n",
      "epoch=751, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.700\n",
      "epoch=752, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.701\n",
      "epoch=753, loss=56344544.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.702\n",
      "epoch=754, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.703\n",
      "epoch=755, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.703\n",
      "epoch=756, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.704\n",
      "epoch=757, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.705\n",
      "epoch=758, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.706\n",
      "epoch=759, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.706\n",
      "epoch=760, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.707\n",
      "epoch=761, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.708\n",
      "epoch=762, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.709\n",
      "epoch=763, loss=56344540.000, validation loss = 207788.094, test loss=9941370.000, test mse = 7762429.500, test mae = 470.709\n",
      "epoch=764, loss=56344540.000, validation loss = 207788.078, test loss=9941370.000, test mse = 7762429.500, test mae = 470.710\n",
      "epoch=765, loss=56344540.000, validation loss = 207788.078, test loss=9941370.000, test mse = 7762429.500, test mae = 470.711\n",
      "epoch=766, loss=56344540.000, validation loss = 207788.078, test loss=9941370.000, test mse = 7762429.500, test mae = 470.711\n",
      "epoch=767, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.712\n",
      "epoch=768, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.713\n",
      "epoch=769, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.714\n",
      "epoch=770, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.714\n",
      "epoch=771, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.715\n",
      "epoch=772, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.716\n",
      "epoch=773, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.716\n",
      "epoch=774, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.717\n",
      "epoch=775, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.717\n",
      "epoch=776, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.718\n",
      "epoch=777, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.719\n",
      "epoch=778, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.719\n",
      "epoch=779, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.720\n",
      "epoch=780, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.721\n",
      "epoch=781, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.721\n",
      "epoch=782, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.722\n",
      "epoch=783, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.723\n",
      "epoch=784, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.723\n",
      "epoch=785, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.724\n",
      "epoch=786, loss=56344540.000, validation loss = 207788.047, test loss=9941370.000, test mse = 7762429.500, test mae = 470.724\n",
      "epoch=787, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.725\n",
      "epoch=788, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.725\n",
      "epoch=789, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.726\n",
      "epoch=790, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.727\n",
      "epoch=791, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=792, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.728\n",
      "epoch=793, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.728\n",
      "epoch=794, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.729\n",
      "epoch=795, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.729\n",
      "epoch=796, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.730\n",
      "epoch=797, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.731\n",
      "epoch=798, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.731\n",
      "epoch=799, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.732\n",
      "epoch=800, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.732\n",
      "epoch=801, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.733\n",
      "epoch=802, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.733\n",
      "epoch=803, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.734\n",
      "epoch=804, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.734\n",
      "epoch=805, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.735\n",
      "epoch=806, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.735\n",
      "epoch=807, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.736\n",
      "epoch=808, loss=56344540.000, validation loss = 207788.031, test loss=9941370.000, test mse = 7762429.500, test mae = 470.736\n",
      "epoch=809, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.737\n",
      "epoch=810, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.737\n",
      "epoch=811, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.738\n",
      "epoch=812, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.738\n",
      "epoch=813, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.739\n",
      "epoch=814, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.739\n",
      "epoch=815, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.740\n",
      "epoch=816, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.740\n",
      "epoch=817, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.740\n",
      "epoch=818, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.741\n",
      "epoch=819, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.741\n",
      "epoch=820, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.742\n",
      "epoch=821, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.742\n",
      "epoch=822, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.743\n",
      "epoch=823, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.743\n",
      "epoch=824, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.743\n",
      "epoch=825, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.744\n",
      "epoch=826, loss=56344540.000, validation loss = 207788.016, test loss=9941370.000, test mse = 7762429.500, test mae = 470.744\n",
      "epoch=827, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.745\n",
      "epoch=828, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.745\n",
      "epoch=829, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.746\n",
      "epoch=830, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.746\n",
      "epoch=831, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.746\n",
      "epoch=832, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.747\n",
      "epoch=833, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.747\n",
      "epoch=834, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.748\n",
      "epoch=835, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.748\n",
      "epoch=836, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.748\n",
      "epoch=837, loss=56344540.000, validation loss = 207788.000, test loss=9941370.000, test mse = 7762429.500, test mae = 470.749\n",
      "epoch=838, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.749\n",
      "epoch=839, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.749\n",
      "epoch=840, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.750\n",
      "epoch=841, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.750\n",
      "epoch=842, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.751\n",
      "epoch=843, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.751\n",
      "epoch=844, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.751\n",
      "epoch=845, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.752\n",
      "epoch=846, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.752\n",
      "epoch=847, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.752\n",
      "epoch=848, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.753\n",
      "epoch=849, loss=56344540.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.753\n",
      "epoch=850, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.753\n",
      "epoch=851, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.754\n",
      "epoch=852, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.754\n",
      "epoch=853, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.754\n",
      "epoch=854, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.755\n",
      "epoch=855, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.755\n",
      "epoch=856, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.755\n",
      "epoch=857, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=858, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.756\n",
      "epoch=859, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.756\n",
      "epoch=860, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.757\n",
      "epoch=861, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.757\n",
      "epoch=862, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.757\n",
      "epoch=863, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.758\n",
      "epoch=864, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.758\n",
      "epoch=865, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.758\n",
      "epoch=866, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.758\n",
      "epoch=867, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.759\n",
      "epoch=868, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.759\n",
      "epoch=869, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.759\n",
      "epoch=870, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.760\n",
      "epoch=871, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.760\n",
      "epoch=872, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.760\n",
      "epoch=873, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.760\n",
      "epoch=874, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.761\n",
      "epoch=875, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.761\n",
      "epoch=876, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.761\n",
      "epoch=877, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.761\n",
      "epoch=878, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.762\n",
      "epoch=879, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.762\n",
      "epoch=880, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.762\n",
      "epoch=881, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.763\n",
      "epoch=882, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.763\n",
      "epoch=883, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.763\n",
      "epoch=884, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.763\n",
      "epoch=885, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.763\n",
      "epoch=886, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.764\n",
      "epoch=887, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.764\n",
      "epoch=888, loss=56344536.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.764\n",
      "epoch=889, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.764\n",
      "epoch=890, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.765\n",
      "epoch=891, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.765\n",
      "epoch=892, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.765\n",
      "epoch=893, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.765\n",
      "epoch=894, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.766\n",
      "epoch=895, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.766\n",
      "epoch=896, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.766\n",
      "epoch=897, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.766\n",
      "epoch=898, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.767\n",
      "epoch=899, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.767\n",
      "epoch=900, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.767\n",
      "epoch=901, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.767\n",
      "epoch=902, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.767\n",
      "epoch=903, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.768\n",
      "epoch=904, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.768\n",
      "epoch=905, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.768\n",
      "epoch=906, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.768\n",
      "epoch=907, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.768\n",
      "epoch=908, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.769\n",
      "epoch=909, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.769\n",
      "epoch=910, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.769\n",
      "epoch=911, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.769\n",
      "epoch=912, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.769\n",
      "epoch=913, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.770\n",
      "epoch=914, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.770\n",
      "epoch=915, loss=56344532.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.770\n",
      "epoch=916, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.770\n",
      "epoch=917, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.770\n",
      "epoch=918, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.770\n",
      "epoch=919, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.771\n",
      "epoch=920, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.771\n",
      "epoch=921, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.771\n",
      "epoch=922, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.771\n",
      "epoch=923, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=924, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.771\n",
      "epoch=925, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.772\n",
      "epoch=926, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.772\n",
      "epoch=927, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.772\n",
      "epoch=928, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.772\n",
      "epoch=929, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.772\n",
      "epoch=930, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.772\n",
      "epoch=931, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.773\n",
      "epoch=932, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.773\n",
      "epoch=933, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.773\n",
      "epoch=934, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.773\n",
      "epoch=935, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.773\n",
      "epoch=936, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.773\n",
      "epoch=937, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.773\n",
      "epoch=938, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.774\n",
      "epoch=939, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.774\n",
      "epoch=940, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.774\n",
      "epoch=941, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.774\n",
      "epoch=942, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.774\n",
      "epoch=943, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.774\n",
      "epoch=944, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.774\n",
      "epoch=945, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.775\n",
      "epoch=946, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.775\n",
      "epoch=947, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.775\n",
      "epoch=948, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.775\n",
      "epoch=949, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.775\n",
      "epoch=950, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.775\n",
      "epoch=951, loss=56344528.000, validation loss = 207787.984, test loss=9941370.000, test mse = 7762429.500, test mae = 470.775\n",
      "epoch=952, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.775\n",
      "epoch=953, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.776\n",
      "epoch=954, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.776\n",
      "epoch=955, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.776\n",
      "epoch=956, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.776\n",
      "epoch=957, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.776\n",
      "epoch=958, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.776\n",
      "epoch=959, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.776\n",
      "epoch=960, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.776\n",
      "epoch=961, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=962, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=963, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=964, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=965, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=966, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=967, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=968, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=969, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=970, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.777\n",
      "epoch=971, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=972, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=973, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=974, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=975, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=976, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=977, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=978, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=979, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.778\n",
      "epoch=980, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=981, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=982, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=983, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=984, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=985, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=986, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=987, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=988, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=989, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=990, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=991, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.779\n",
      "epoch=992, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.780\n",
      "epoch=993, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.780\n",
      "epoch=994, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.780\n",
      "epoch=995, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.780\n",
      "epoch=996, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.780\n",
      "epoch=997, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.780\n",
      "epoch=998, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.780\n",
      "epoch=999, loss=56344528.000, validation loss = 207787.969, test loss=9941370.000, test mse = 7762429.500, test mae = 470.780\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "learning_rate = 0.0000005\n",
    "num_epochs = 1000\n",
    "batch_size = 1000\n",
    "output_size = 2\n",
    "\n",
    "device = th.device('cuda:0')\n",
    "input_size = train_past_cases_1d[0].shape[1] + attrs.shape[1]\n",
    "mlp_sir = Net_SIR(input_size, hidden_size, output_size)\n",
    "print('#features:', input_size)\n",
    "\n",
    "# Move model to GPU\n",
    "mlp_sir = mlp_sir.to(device)\n",
    "\n",
    "# Move data to GPU\n",
    "pop = pop.to(device)\n",
    "attrs = attrs.to(device)\n",
    "for i in range(len(train_past_cases_1d)):\n",
    "    train_past_cases_1d[i] = train_past_cases_1d[i].to(device)\n",
    "    train_past_deaths_1d[i] = train_past_deaths_1d[i].to(device)\n",
    "    train_past_gamma_1d[i] = train_past_gamma_1d[i].to(device)\n",
    "    train_past_beta_1d[i] = train_past_beta_1d[i].to(device)\n",
    "    train_labels_cases_1d[i] = train_labels_cases_1d[i].to(device)\n",
    "    train_labels_deaths_1d[i] = train_labels_deaths_1d[i].to(device)\n",
    "    train_labels_gamma_1d[i] = train_labels_gamma_1d[i].to(device)\n",
    "    train_labels_beta_1d[i] = train_labels_beta_1d[i].to(device)\n",
    "    if len(train_labels_cases_1d[i].shape) == 1:\n",
    "        train_labels_cases_1d[i] = train_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(train_labels_deaths_1d[i].shape) == 1:\n",
    "        train_labels_deaths_1d[i] = train_labels_deaths_1d[i].unsqueeze(1)\n",
    "    if len(train_labels_gamma_1d[i].shape) == 1:\n",
    "        train_labels_gamma_1d[i] = train_labels_gamma_1d[i].unsqueeze(1)\n",
    "    if len(train_labels_beta_1d[i].shape) == 1:\n",
    "        train_labels_beta_1d[i] = train_labels_beta_1d[i].unsqueeze(1)\n",
    "        \n",
    "for i in range(len(valid_past_cases_1d)):\n",
    "    valid_past_cases_1d[i] = valid_past_cases_1d[i].to(device)\n",
    "    valid_past_deaths_1d[i] = valid_past_deaths_1d[i].to(device)\n",
    "    valid_past_gamma_1d[i] = valid_past_gamma_1d[i].to(device)\n",
    "    valid_past_beta_1d[i] = valid_past_beta_1d[i].to(device)\n",
    "    valid_labels_cases_1d[i] = valid_labels_cases_1d[i].to(device)\n",
    "    valid_labels_deaths_1d[i] = valid_labels_deaths_1d[i].to(device)\n",
    "    valid_labels_gamma_1d[i] = valid_labels_gamma_1d[i].to(device)\n",
    "    valid_labels_beta_1d[i] = valid_labels_beta_1d[i].to(device)\n",
    "    if len(valid_labels_cases_1d[i].shape) == 1:\n",
    "         valid_labels_cases_1d[i] = valid_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths_1d[i].shape) == 1:\n",
    "        valid_labels_deaths_1d[i] = valid_labels_deaths_1d[i].unsqueeze(1)\n",
    "    if len(valid_labels_gamma_1d[i].shape) == 1:\n",
    "         valid_labels_gamma_1d[i] = valid_labels_gamma_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_beta_1d[i].shape) == 1:\n",
    "        valid_labels_beta_1d[i] = valid_labels_beta_1d[i].unsqueeze(1)\n",
    "\n",
    "for i in range(len(test_past_cases_1d)):\n",
    "    test_past_cases_1d[i] = test_past_cases_1d[i].to(device)\n",
    "    test_past_deaths_1d[i] = test_past_deaths_1d[i].to(device)\n",
    "    test_past_gamma_1d[i] = test_past_gamma_1d[i].to(device)\n",
    "    test_past_beta_1d[i] = test_past_beta_1d[i].to(device)\n",
    "    test_labels_cases_1d[i] = test_labels_cases_1d[i].to(device)\n",
    "    test_labels_deaths_1d[i] = test_labels_deaths_1d[i].to(device)\n",
    "    test_labels_gamma_1d[i] = test_labels_gamma_1d[i].to(device)\n",
    "    test_labels_beta_1d[i] = test_labels_beta_1d[i].to(device)\n",
    "    if len(test_labels_cases_1d[i].shape) == 1:\n",
    "        test_labels_cases_1d[i] = test_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths_1d[i].shape) == 1:\n",
    "        test_labels_deaths_1d[i] = test_labels_deaths_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_gamma_1d[i].shape) == 1:\n",
    "        test_labels_gamma_1d[i] = test_labels_gamma_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_beta_1d[i].shape) == 1:\n",
    "        test_labels_beta_1d[i] = test_labels_beta_1d[i].unsqueeze(1)\n",
    "        \n",
    "# Normalize attrs\n",
    "attrs[th.isnan(attrs)] = 0\n",
    "attr_mean = th.mean(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs - attr_mean\n",
    "attr_std = th.std(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs / attr_std\n",
    "\n",
    "\n",
    "optimizer = th.optim.Adam(mlp_sir.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for idx in range(len(train_past_cases_1d)):\n",
    "        batch = th.cat([train_past_cases_1d[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = mlp_sir(batch)\n",
    "        loss = th.mean((train_labels_gamma_1d[idx] - vals[:,0])**2 + (train_labels_beta_1d[idx] - vals[:,1])**2)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    count = 0\n",
    "    with th.no_grad():\n",
    "        eval_loss1 = []\n",
    "        eval_errs = []\n",
    "        test_loss1 = []\n",
    "        test_errs = []\n",
    "        test_mses = []\n",
    "        test_maes = []\n",
    "        for idx in range(14):\n",
    "            valid_feats = th.cat([valid_past_cases_1d[idx], attrs], dim=1)\n",
    "            eval_vals = mlp_sir(valid_feats)\n",
    "            eval_I = valid_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "            eval_D = valid_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "            eval_labels_cases = valid_labels_cases_1d[idx]\n",
    "            eval_labels_deaths = valid_labels_deaths_1d[idx]\n",
    "            eval_I_new, eval_D_new = sir_1d_output(eval_vals, eval_I, eval_D)\n",
    "            err = my_msle_ID(eval_I_new, eval_D_new, eval_labels_cases, eval_labels_deaths)\n",
    "            eval_loss = th.mean((valid_labels_gamma_1d[idx] - eval_vals[:,0])**2 + (valid_labels_beta_1d[idx] - eval_vals[:,1])**2)\n",
    "            eval_errs.append(err.cpu().numpy())\n",
    "            eval_loss1.append(eval_loss.cpu().numpy())\n",
    "            \n",
    "            test_feats = th.cat([test_past_cases_1d[idx], attrs], dim=1)\n",
    "            test_vals = mlp_sir(test_feats)\n",
    "            test_I = test_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "            test_D = test_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "            test_cases = test_labels_cases_1d[idx]\n",
    "            test_deaths = test_labels_deaths_1d[idx]\n",
    "            test_I_new, test_D_new = sir_1d_output(test_vals, test_I, test_D)\n",
    "            test_err = my_msle_ID(test_I_new, test_D_new, test_cases, test_deaths)\n",
    "            test_mse = th.mean((test_I_new - test_labels_cases_1d[idx])**2)\n",
    "            test_mae = th.mean(th.abs(test_I_new - test_labels_cases_1d[idx]))\n",
    "            test_errs.append(test_err.cpu().numpy())\n",
    "            test_mses.append(test_mse.cpu().numpy())\n",
    "            test_maes.append(test_mae.cpu().numpy())\n",
    "            test_loss = th.mean((test_labels_gamma_1d[idx] - test_vals[:,0])**2 + (test_labels_beta_1d[idx] - test_vals[:,1])**2)\n",
    "            test_loss1.append(test_loss.cpu().numpy())\n",
    "        print('epoch={}, loss={:.3f}, validation loss = {:.3f}, test loss={:.3f}, test mse = {:.3f}, test mae = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_loss1), np.mean(test_loss1), np.mean(test_mses), np.mean(test_maes)))\n",
    "        # print('epoch={}, loss={:.3f}, test loss={:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs)))\n",
    "            \n",
    "#        old_eval_err = new_eval_err\n",
    "#        new_eval_err = np.mean(eval_errs)\n",
    "#        if old_eval_err <= new_eval_err:\n",
    "#            R0_NYC = []\n",
    "#            R0_Sacramento = []\n",
    "#            gamma_NYC = []\n",
    "#            beta_NYC = []\n",
    "#            gamma_Sacramento = []\n",
    "#            beta_Sacramento = []\n",
    "#            train_vals = []\n",
    "#            for idx in range(19, len(train_past_cases)):\n",
    "#                labels = train_labels_cases[idx]\n",
    "#                batch = th.cat([train_past_cases[idx], attrs], dim=1)\n",
    "#                th.manual_seed(1)\n",
    "#                vals = mlp_sir(batch)\n",
    "#                gamma_NYC.append(vals[4][0])\n",
    "#                gamma_Sacramento.append(vals[202][0])\n",
    "#                beta_NYC.append(vals[4][1])\n",
    "#                beta_Sacramento.append(vals[202][1])\n",
    "#                R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "#                R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "#                R0_NYC.append(R_NYC_div)\n",
    "#                R0_Sacramento.append(R_Sacramento_div)  \n",
    "#                I = train_past_cases[idx][:,-1].view(3142,1)\n",
    "#                D = train_past_deaths[idx][:,-1].view(3142,1)\n",
    "#                I_new, D_new = sir_1d_output(vals, I, D)\n",
    "#                train_vals.append(I_new)\n",
    "#            break\n",
    "    # print('epoch={}, loss={:.3f}, validation loss = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_past_cases_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with th.no_grad():\n",
    "    R0_NYC = []\n",
    "    R0_Sacramento = []\n",
    "    gamma_NYC = []\n",
    "    beta_NYC = []\n",
    "    gamma_Sacramento = []\n",
    "    beta_Sacramento = []\n",
    "    train_vals = []\n",
    "    death_vals = []\n",
    "    for idx in range(len(train_past_cases_1d)):\n",
    "        labels = train_labels_cases_1d[idx]\n",
    "        batch = th.cat([train_past_cases_1d[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = mlp_sir(batch)\n",
    "        gamma_NYC.append(vals[4][0])\n",
    "        gamma_Sacramento.append(vals[202][0])\n",
    "        beta_NYC.append(vals[4][1])\n",
    "        beta_Sacramento.append(vals[202][1])\n",
    "        R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "        R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "        R0_NYC.append(R_NYC_div)\n",
    "        R0_Sacramento.append(R_Sacramento_div)  \n",
    "        I = train_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "        D = train_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "        I_new, D_new = sir_1d_output(vals, I, D)\n",
    "        train_vals.append(I_new)\n",
    "        death_vals.append(D_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[202][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0') tensor(2.2265e-16, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(2.5813e-19, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1.1820e-21, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(6.2836e-26, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(2.3755e-28, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(6.2804e-33, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1.0197e-37, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(beta_Sacramento, gamma_Sacramento):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(len(R0_Sacramento))\n",
    "y1 = R0_Sacramento\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Sacramento R0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_vals = []\n",
    "for i in range(len(train_past_cases_1d)):\n",
    "    pred_vals.append(train_vals[i][202].cpu().numpy())\n",
    "\n",
    "x = range(len(pred_vals))\n",
    "y1 = train_labels_Sacramento\n",
    "y2 = pred_vals\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Real\")\n",
    "plt.plot(x, y2, ls=\"-\", lw=2, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0') tensor(2.2265e-16, device='cuda:0') tensor(4.4913e+15, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(2.5813e-19, device='cuda:0') tensor(3.8741e+18, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1.1820e-21, device='cuda:0') tensor(8.4599e+20, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(6.2836e-26, device='cuda:0') tensor(1.5914e+25, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(2.3755e-28, device='cuda:0') tensor(4.2097e+27, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(6.2804e-33, device='cuda:0') tensor(1.5923e+32, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(1.0197e-37, device='cuda:0') tensor(9.8064e+36, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i,j,k in zip(beta_Sacramento, gamma_Sacramento, R0_Sacramento):\n",
    "    print(i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(R0_NYC))\n",
    "y_NYC = R0_NYC\n",
    "plt.plot(x, y_NYC, ls=\"-\", lw=2, label=\"NYC R0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_vals_NYC = []\n",
    "for i in range(len(R0_NYC)):\n",
    "    pred_vals_NYC.append(train_vals[i][4].cpu().numpy())\n",
    "\n",
    "x = range(len(R0_NYC))\n",
    "y1 = train_labels_NYC\n",
    "y2 = pred_vals_NYC\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Real\")\n",
    "plt.plot(x, y2, ls=\"-\", lw=2, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(1., device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i,j,k in zip(beta_NYC, gamma_NYC, R0_NYC):\n",
    "    print(i, j, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT - SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=3.625, validation loss = 6.414, test loss=7.538, test mse = 1328139.375, test mae = 143.040\n",
      "epoch=1, loss=2.515, validation loss = 3.597, test loss=3.902, test mse = 57905.730, test mae = 42.500\n",
      "epoch=2, loss=1.733, validation loss = 2.053, test loss=2.063, test mse = 22330.891, test mae = 22.573\n",
      "epoch=3, loss=1.224, validation loss = 1.128, test loss=1.025, test mse = 14337.678, test mae = 14.574\n",
      "epoch=4, loss=0.906, validation loss = 0.690, test loss=0.568, test mse = 3302.091, test mae = 9.957\n",
      "epoch=5, loss=0.732, validation loss = 0.482, test loss=0.362, test mse = 3236.597, test mae = 9.140\n",
      "epoch=6, loss=0.621, validation loss = 0.355, test loss=0.251, test mse = 3303.890, test mae = 8.981\n",
      "epoch=7, loss=0.541, validation loss = 0.271, test loss=0.190, test mse = 4346.214, test mae = 9.590\n",
      "epoch=8, loss=0.480, validation loss = 0.216, test loss=0.152, test mse = 5454.673, test mae = 10.301\n",
      "epoch=9, loss=0.432, validation loss = 0.179, test loss=0.126, test mse = 7198.953, test mae = 11.350\n",
      "epoch=10, loss=0.393, validation loss = 0.152, test loss=0.108, test mse = 168975.359, test mae = 15.694\n",
      "epoch=11, loss=0.360, validation loss = 0.133, test loss=0.095, test mse = 1320029.375, test mae = 37.459\n",
      "epoch=12, loss=0.333, validation loss = 0.118, test loss=0.085, test mse = 1868935.625, test mae = 57.913\n",
      "epoch=13, loss=0.309, validation loss = 0.107, test loss=0.078, test mse = 1882825.750, test mae = 62.239\n",
      "epoch=14, loss=0.289, validation loss = 0.098, test loss=0.072, test mse = 1906214.375, test mae = 67.807\n",
      "epoch=15, loss=0.272, validation loss = 0.091, test loss=0.067, test mse = 1916774.625, test mae = 70.605\n",
      "epoch=16, loss=0.257, validation loss = 0.085, test loss=0.063, test mse = 1926540.000, test mae = 74.070\n",
      "epoch=17, loss=0.243, validation loss = 0.080, test loss=0.060, test mse = 1937315.125, test mae = 77.720\n",
      "epoch=18, loss=0.231, validation loss = 0.076, test loss=0.058, test mse = 2164277.750, test mae = 86.491\n",
      "epoch=19, loss=0.220, validation loss = 0.073, test loss=0.056, test mse = 2863817.500, test mae = 106.087\n",
      "epoch=20, loss=0.210, validation loss = 0.071, test loss=0.055, test mse = 2962211.500, test mae = 113.937\n",
      "epoch=21, loss=0.201, validation loss = 0.069, test loss=0.054, test mse = 3017820.000, test mae = 118.230\n",
      "epoch=22, loss=0.193, validation loss = 0.067, test loss=0.053, test mse = 3024952.750, test mae = 120.957\n",
      "epoch=23, loss=0.186, validation loss = 0.065, test loss=0.052, test mse = 2922794.750, test mae = 122.043\n",
      "epoch=24, loss=0.179, validation loss = 0.064, test loss=0.051, test mse = 2468706.750, test mae = 118.614\n",
      "epoch=25, loss=0.173, validation loss = 0.063, test loss=0.051, test mse = 2716979.750, test mae = 126.906\n",
      "epoch=26, loss=0.167, validation loss = 0.061, test loss=0.050, test mse = 3168881.250, test mae = 136.690\n",
      "epoch=27, loss=0.162, validation loss = 0.060, test loss=0.050, test mse = 3157864.500, test mae = 137.030\n",
      "epoch=28, loss=0.157, validation loss = 0.060, test loss=0.049, test mse = 3146926.250, test mae = 137.067\n",
      "epoch=29, loss=0.152, validation loss = 0.059, test loss=0.049, test mse = 3073149.250, test mae = 135.740\n",
      "epoch=30, loss=0.148, validation loss = 0.058, test loss=0.049, test mse = 3737736.000, test mae = 150.546\n",
      "epoch=31, loss=0.144, validation loss = 0.057, test loss=0.049, test mse = 3936673.750, test mae = 155.834\n",
      "epoch=32, loss=0.140, validation loss = 0.056, test loss=0.048, test mse = 3700978.500, test mae = 153.099\n",
      "epoch=33, loss=0.136, validation loss = 0.056, test loss=0.048, test mse = 3497944.000, test mae = 150.831\n",
      "epoch=34, loss=0.133, validation loss = 0.055, test loss=0.048, test mse = 3293567.250, test mae = 148.169\n",
      "epoch=35, loss=0.129, validation loss = 0.054, test loss=0.048, test mse = 2974790.250, test mae = 142.733\n",
      "epoch=36, loss=0.126, validation loss = 0.054, test loss=0.047, test mse = 3243775.750, test mae = 148.200\n",
      "epoch=37, loss=0.123, validation loss = 0.053, test loss=0.047, test mse = 3519270.500, test mae = 152.400\n",
      "epoch=38, loss=0.120, validation loss = 0.053, test loss=0.047, test mse = 3519854.250, test mae = 152.550\n",
      "epoch=39, loss=0.117, validation loss = 0.052, test loss=0.046, test mse = 3519814.250, test mae = 152.534\n",
      "epoch=40, loss=0.115, validation loss = 0.051, test loss=0.046, test mse = 3519446.250, test mae = 152.312\n",
      "epoch=41, loss=0.112, validation loss = 0.051, test loss=0.045, test mse = 3518986.750, test mae = 151.964\n",
      "epoch=42, loss=0.110, validation loss = 0.050, test loss=0.045, test mse = 3518508.250, test mae = 151.530\n",
      "epoch=43, loss=0.108, validation loss = 0.049, test loss=0.044, test mse = 3518006.250, test mae = 151.088\n",
      "epoch=44, loss=0.105, validation loss = 0.049, test loss=0.043, test mse = 3443686.500, test mae = 149.369\n",
      "epoch=45, loss=0.103, validation loss = 0.048, test loss=0.043, test mse = 3168916.000, test mae = 144.884\n",
      "epoch=46, loss=0.101, validation loss = 0.047, test loss=0.042, test mse = 2459718.750, test mae = 131.524\n",
      "epoch=47, loss=0.099, validation loss = 0.047, test loss=0.042, test mse = 2457034.000, test mae = 131.033\n",
      "epoch=48, loss=0.097, validation loss = 0.046, test loss=0.041, test mse = 2445365.250, test mae = 129.999\n",
      "epoch=49, loss=0.096, validation loss = 0.045, test loss=0.041, test mse = 2437059.250, test mae = 129.012\n",
      "epoch=50, loss=0.094, validation loss = 0.045, test loss=0.040, test mse = 2377588.750, test mae = 126.182\n",
      "epoch=51, loss=0.092, validation loss = 0.044, test loss=0.039, test mse = 2333082.250, test mae = 122.559\n",
      "epoch=52, loss=0.090, validation loss = 0.043, test loss=0.039, test mse = 2321466.750, test mae = 121.065\n",
      "epoch=53, loss=0.089, validation loss = 0.042, test loss=0.038, test mse = 2292153.500, test mae = 117.665\n",
      "epoch=54, loss=0.087, validation loss = 0.042, test loss=0.037, test mse = 2289672.250, test mae = 116.461\n",
      "epoch=55, loss=0.086, validation loss = 0.041, test loss=0.036, test mse = 2289044.000, test mae = 115.886\n",
      "epoch=56, loss=0.084, validation loss = 0.040, test loss=0.036, test mse = 2281480.500, test mae = 114.591\n",
      "epoch=57, loss=0.083, validation loss = 0.039, test loss=0.035, test mse = 2274869.750, test mae = 112.998\n",
      "epoch=58, loss=0.081, validation loss = 0.038, test loss=0.034, test mse = 2270001.750, test mae = 111.892\n",
      "epoch=59, loss=0.080, validation loss = 0.038, test loss=0.033, test mse = 2268068.250, test mae = 111.149\n",
      "epoch=60, loss=0.078, validation loss = 0.037, test loss=0.033, test mse = 2267383.500, test mae = 110.618\n",
      "epoch=61, loss=0.077, validation loss = 0.036, test loss=0.032, test mse = 2266436.500, test mae = 110.040\n",
      "epoch=62, loss=0.075, validation loss = 0.035, test loss=0.031, test mse = 2265490.250, test mae = 109.453\n",
      "epoch=63, loss=0.074, validation loss = 0.034, test loss=0.031, test mse = 2263909.250, test mae = 108.721\n",
      "epoch=64, loss=0.073, validation loss = 0.034, test loss=0.030, test mse = 2261800.250, test mae = 107.696\n",
      "epoch=65, loss=0.071, validation loss = 0.033, test loss=0.029, test mse = 2259826.750, test mae = 106.687\n",
      "epoch=66, loss=0.070, validation loss = 0.032, test loss=0.029, test mse = 2257562.250, test mae = 105.601\n",
      "epoch=67, loss=0.068, validation loss = 0.031, test loss=0.027, test mse = 2182973.250, test mae = 100.774\n",
      "epoch=68, loss=0.067, validation loss = 0.030, test loss=0.026, test mse = 2055227.750, test mae = 90.813\n",
      "epoch=69, loss=0.066, validation loss = 0.028, test loss=0.025, test mse = 2011441.000, test mae = 84.850\n",
      "epoch=70, loss=0.064, validation loss = 0.027, test loss=0.024, test mse = 1935084.750, test mae = 76.895\n",
      "epoch=71, loss=0.063, validation loss = 0.026, test loss=0.023, test mse = 1923973.625, test mae = 73.903\n",
      "epoch=72, loss=0.062, validation loss = 0.025, test loss=0.021, test mse = 1915764.625, test mae = 70.934\n",
      "epoch=73, loss=0.061, validation loss = 0.024, test loss=0.020, test mse = 1900986.625, test mae = 67.227\n",
      "epoch=74, loss=0.060, validation loss = 0.023, test loss=0.020, test mse = 1892917.375, test mae = 64.814\n",
      "epoch=75, loss=0.059, validation loss = 0.022, test loss=0.018, test mse = 1885977.375, test mae = 62.422\n",
      "epoch=76, loss=0.058, validation loss = 0.021, test loss=0.017, test mse = 1875122.250, test mae = 58.676\n",
      "epoch=77, loss=0.057, validation loss = 0.020, test loss=0.016, test mse = 1860494.375, test mae = 55.452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=78, loss=0.056, validation loss = 0.019, test loss=0.015, test mse = 1829705.375, test mae = 49.984\n",
      "epoch=79, loss=0.055, validation loss = 0.019, test loss=0.015, test mse = 1820590.875, test mae = 47.375\n",
      "epoch=80, loss=0.055, validation loss = 0.018, test loss=0.014, test mse = 1531372.000, test mae = 40.114\n",
      "epoch=81, loss=0.054, validation loss = 0.017, test loss=0.013, test mse = 9044.791, test mae = 11.259\n",
      "epoch=82, loss=0.053, validation loss = 0.017, test loss=0.013, test mse = 5571.063, test mae = 9.714\n",
      "epoch=83, loss=0.053, validation loss = 0.017, test loss=0.012, test mse = 3534.174, test mae = 8.786\n",
      "epoch=84, loss=0.052, validation loss = 0.016, test loss=0.012, test mse = 2105.562, test mae = 7.907\n",
      "epoch=85, loss=0.052, validation loss = 0.016, test loss=0.011, test mse = 1669.316, test mae = 7.449\n",
      "epoch=86, loss=0.051, validation loss = 0.016, test loss=0.011, test mse = 1603.136, test mae = 7.280\n",
      "epoch=87, loss=0.050, validation loss = 0.015, test loss=0.011, test mse = 1592.987, test mae = 7.210\n",
      "epoch=88, loss=0.050, validation loss = 0.015, test loss=0.011, test mse = 1591.274, test mae = 7.173\n",
      "epoch=89, loss=0.050, validation loss = 0.015, test loss=0.011, test mse = 1590.538, test mae = 7.148\n",
      "epoch=90, loss=0.049, validation loss = 0.015, test loss=0.011, test mse = 1590.025, test mae = 7.129\n",
      "epoch=91, loss=0.049, validation loss = 0.015, test loss=0.011, test mse = 1589.626, test mae = 7.112\n",
      "epoch=92, loss=0.048, validation loss = 0.015, test loss=0.010, test mse = 1589.312, test mae = 7.098\n",
      "epoch=93, loss=0.048, validation loss = 0.015, test loss=0.010, test mse = 1589.062, test mae = 7.085\n",
      "epoch=94, loss=0.047, validation loss = 0.014, test loss=0.010, test mse = 1588.861, test mae = 7.074\n",
      "epoch=95, loss=0.047, validation loss = 0.014, test loss=0.010, test mse = 1588.701, test mae = 7.064\n",
      "epoch=96, loss=0.047, validation loss = 0.014, test loss=0.010, test mse = 1588.573, test mae = 7.055\n",
      "epoch=97, loss=0.046, validation loss = 0.014, test loss=0.010, test mse = 1588.469, test mae = 7.047\n",
      "epoch=98, loss=0.046, validation loss = 0.014, test loss=0.010, test mse = 1588.387, test mae = 7.040\n",
      "epoch=99, loss=0.046, validation loss = 0.014, test loss=0.010, test mse = 1588.321, test mae = 7.033\n",
      "epoch=100, loss=0.045, validation loss = 0.014, test loss=0.010, test mse = 1588.269, test mae = 7.027\n",
      "epoch=101, loss=0.045, validation loss = 0.014, test loss=0.010, test mse = 1588.227, test mae = 7.022\n",
      "epoch=102, loss=0.045, validation loss = 0.014, test loss=0.010, test mse = 1588.192, test mae = 7.017\n",
      "epoch=103, loss=0.044, validation loss = 0.014, test loss=0.010, test mse = 1588.163, test mae = 7.012\n",
      "epoch=104, loss=0.044, validation loss = 0.013, test loss=0.010, test mse = 1588.140, test mae = 7.008\n",
      "epoch=105, loss=0.044, validation loss = 0.013, test loss=0.010, test mse = 1588.120, test mae = 7.004\n",
      "epoch=106, loss=0.044, validation loss = 0.013, test loss=0.010, test mse = 1588.104, test mae = 7.000\n",
      "epoch=107, loss=0.043, validation loss = 0.013, test loss=0.010, test mse = 1588.090, test mae = 6.996\n",
      "epoch=108, loss=0.043, validation loss = 0.013, test loss=0.009, test mse = 1588.078, test mae = 6.993\n",
      "epoch=109, loss=0.043, validation loss = 0.013, test loss=0.009, test mse = 1588.068, test mae = 6.990\n",
      "epoch=110, loss=0.043, validation loss = 0.013, test loss=0.009, test mse = 1588.060, test mae = 6.987\n",
      "epoch=111, loss=0.042, validation loss = 0.013, test loss=0.009, test mse = 1588.052, test mae = 6.984\n",
      "epoch=112, loss=0.042, validation loss = 0.013, test loss=0.009, test mse = 1588.045, test mae = 6.981\n",
      "epoch=113, loss=0.042, validation loss = 0.013, test loss=0.009, test mse = 1588.039, test mae = 6.979\n",
      "epoch=114, loss=0.042, validation loss = 0.013, test loss=0.009, test mse = 1588.034, test mae = 6.976\n",
      "epoch=115, loss=0.042, validation loss = 0.013, test loss=0.009, test mse = 1588.030, test mae = 6.974\n",
      "epoch=116, loss=0.041, validation loss = 0.013, test loss=0.009, test mse = 1588.026, test mae = 6.972\n",
      "epoch=117, loss=0.041, validation loss = 0.013, test loss=0.009, test mse = 1588.023, test mae = 6.970\n",
      "epoch=118, loss=0.041, validation loss = 0.013, test loss=0.009, test mse = 1588.020, test mae = 6.968\n",
      "epoch=119, loss=0.041, validation loss = 0.013, test loss=0.009, test mse = 1588.017, test mae = 6.966\n",
      "epoch=120, loss=0.041, validation loss = 0.013, test loss=0.009, test mse = 1588.015, test mae = 6.965\n",
      "epoch=121, loss=0.040, validation loss = 0.013, test loss=0.009, test mse = 1588.012, test mae = 6.963\n",
      "epoch=122, loss=0.040, validation loss = 0.013, test loss=0.009, test mse = 1588.010, test mae = 6.961\n",
      "epoch=123, loss=0.040, validation loss = 0.012, test loss=0.009, test mse = 1588.008, test mae = 6.960\n",
      "epoch=124, loss=0.040, validation loss = 0.012, test loss=0.009, test mse = 1588.007, test mae = 6.958\n",
      "epoch=125, loss=0.040, validation loss = 0.012, test loss=0.009, test mse = 1588.005, test mae = 6.957\n",
      "epoch=126, loss=0.040, validation loss = 0.012, test loss=0.009, test mse = 1588.004, test mae = 6.956\n",
      "epoch=127, loss=0.040, validation loss = 0.012, test loss=0.009, test mse = 1588.003, test mae = 6.954\n",
      "epoch=128, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1588.002, test mae = 6.953\n",
      "epoch=129, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1588.001, test mae = 6.952\n",
      "epoch=130, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1588.000, test mae = 6.951\n",
      "epoch=131, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1587.999, test mae = 6.950\n",
      "epoch=132, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1587.999, test mae = 6.948\n",
      "epoch=133, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1587.998, test mae = 6.947\n",
      "epoch=134, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1587.998, test mae = 6.946\n",
      "epoch=135, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1587.997, test mae = 6.945\n",
      "epoch=136, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1587.997, test mae = 6.945\n",
      "epoch=137, loss=0.039, validation loss = 0.012, test loss=0.009, test mse = 1587.996, test mae = 6.944\n",
      "epoch=138, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.996, test mae = 6.943\n",
      "epoch=139, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.996, test mae = 6.942\n",
      "epoch=140, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.995, test mae = 6.941\n",
      "epoch=141, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.995, test mae = 6.940\n",
      "epoch=142, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.995, test mae = 6.940\n",
      "epoch=143, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.995, test mae = 6.939\n",
      "epoch=144, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.938\n",
      "epoch=145, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.937\n",
      "epoch=146, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.937\n",
      "epoch=147, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.936\n",
      "epoch=148, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.936\n",
      "epoch=149, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.935\n",
      "epoch=150, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.934\n",
      "epoch=151, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.934\n",
      "epoch=152, loss=0.038, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.933\n",
      "epoch=153, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.933\n",
      "epoch=154, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.932\n",
      "epoch=155, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.932\n",
      "epoch=156, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.931\n",
      "epoch=157, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=158, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.931\n",
      "epoch=159, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.930\n",
      "epoch=160, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.930\n",
      "epoch=161, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.929\n",
      "epoch=162, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.929\n",
      "epoch=163, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.929\n",
      "epoch=164, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.928\n",
      "epoch=165, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.928\n",
      "epoch=166, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.928\n",
      "epoch=167, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.927\n",
      "epoch=168, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.927\n",
      "epoch=169, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.993, test mae = 6.927\n",
      "epoch=170, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.927\n",
      "epoch=171, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.926\n",
      "epoch=172, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.926\n",
      "epoch=173, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.926\n",
      "epoch=174, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.926\n",
      "epoch=175, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.925\n",
      "epoch=176, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.925\n",
      "epoch=177, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.925\n",
      "epoch=178, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.925\n",
      "epoch=179, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.925\n",
      "epoch=180, loss=0.037, validation loss = 0.012, test loss=0.009, test mse = 1587.994, test mae = 6.924\n",
      "epoch=181, loss=0.037, validation loss = 0.011, test loss=0.009, test mse = 1587.994, test mae = 6.924\n",
      "epoch=182, loss=0.037, validation loss = 0.011, test loss=0.009, test mse = 1587.994, test mae = 6.924\n",
      "epoch=183, loss=0.037, validation loss = 0.011, test loss=0.009, test mse = 1587.994, test mae = 6.924\n",
      "epoch=184, loss=0.037, validation loss = 0.011, test loss=0.009, test mse = 1587.994, test mae = 6.924\n",
      "epoch=185, loss=0.037, validation loss = 0.011, test loss=0.009, test mse = 1587.994, test mae = 6.923\n",
      "epoch=186, loss=0.037, validation loss = 0.011, test loss=0.009, test mse = 1587.994, test mae = 6.923\n",
      "epoch=187, loss=0.037, validation loss = 0.011, test loss=0.008, test mse = 1587.994, test mae = 6.923\n",
      "epoch=188, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.994, test mae = 6.923\n",
      "epoch=189, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.994, test mae = 6.923\n",
      "epoch=190, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.923\n",
      "epoch=191, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.923\n",
      "epoch=192, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.922\n",
      "epoch=193, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.922\n",
      "epoch=194, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.922\n",
      "epoch=195, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.922\n",
      "epoch=196, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.922\n",
      "epoch=197, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.922\n",
      "epoch=198, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.922\n",
      "epoch=199, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.922\n",
      "epoch=200, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.921\n",
      "epoch=201, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.921\n",
      "epoch=202, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.921\n",
      "epoch=203, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.921\n",
      "epoch=204, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.921\n",
      "epoch=205, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.921\n",
      "epoch=206, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.921\n",
      "epoch=207, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.995, test mae = 6.921\n",
      "epoch=208, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.921\n",
      "epoch=209, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.921\n",
      "epoch=210, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=211, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=212, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=213, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=214, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=215, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=216, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=217, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=218, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=219, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=220, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=221, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=222, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=223, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n",
      "epoch=224, loss=0.036, validation loss = 0.011, test loss=0.008, test mse = 1587.996, test mae = 6.920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-1071de442a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mvalid_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_past_cases_1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0meval_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgat_sir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0meval_I\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_past_cases_1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3142\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0meval_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_past_deaths_1d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3142\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-9911f3d81ac2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/dgl/nn/pytorch/conv/gatconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# compute softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;31m# message passing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         graph.update_all(fn.u_mul_e('ft', 'a', 'm'),\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/dgl/nn/pytorch/softmax.py\u001b[0m in \u001b[0;36medge_softmax\u001b[0;34m(graph, logits, eids)\u001b[0m\n\u001b[1;32m    191\u001b[0m         [0.5000]])\n\u001b[1;32m    192\u001b[0m     \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mEdgeSoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/dgl/nn/pytorch/softmax.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, g, score, eids)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m#g.update_all(fn.copy_e('out', 'm'), fn.sum('m', 'out_sum'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mout_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargetCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEDGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m#g.apply_edges(fn.e_div_v('out', 'out_sum', 'out'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         out = F.binary_reduce(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mcopy_reduce\u001b[0;34m(reducer, graph, target, in_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 out_map=(None, None)):\n\u001b[1;32m    432\u001b[0m     \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCopyReduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, reducer, graph, target, in_data, out_data, out_size, in_map, out_map)\u001b[0m\n\u001b[1;32m    385\u001b[0m     def forward(ctx, reducer, graph, target, in_data, out_data, out_size, in_map,\n\u001b[1;32m    386\u001b[0m                 out_map):\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0min_data_nd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzerocopy_to_dgl_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0mout_data_nd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzerocopy_to_dgl_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         K.copy_reduce(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mzerocopy_to_dgl_ndarray\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzerocopy_to_dgl_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dlpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dlpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mzerocopy_from_dgl_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/dgl/_ffi/ndarray.py\u001b[0m in \u001b[0;36mfrom_dlpack\u001b[0;34m(dltensor)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0marray\u001b[0m \u001b[0mview\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_from_dlpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdltensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/dgl/_ffi/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_from_dlpack\u001b[0;34m(dltensor)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#   set restype of PyCapsule calls. But weirdly, this does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#   work out always.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDGLArrayHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcheck_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLArrayFromDLPack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(obj, typ)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0m_cast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPYFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_void_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0m_string_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPYFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_void_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_string_at_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "learning_rate = 0.0000005\n",
    "num_epochs = 1000\n",
    "batch_size = 1000\n",
    "output_size = 2\n",
    "\n",
    "device = th.device('cuda:0')\n",
    "input_size = train_past_cases_1d[0].shape[1] + attrs.shape[1]\n",
    "gat_sir = GAT_SIR(g, input_size, hidden_size, output_size, 1)\n",
    "print('#features:', input_size)\n",
    "\n",
    "# Move model to GPU\n",
    "gat_sir = gat_sir.to(device)\n",
    "\n",
    "# Move data to GPU\n",
    "pop = pop.to(device)\n",
    "attrs = attrs.to(device)\n",
    "for i in range(len(train_past_cases_1d)):\n",
    "    train_past_cases_1d[i] = train_past_cases_1d[i].to(device)\n",
    "    train_past_deaths_1d[i] = train_past_deaths_1d[i].to(device)\n",
    "    train_labels_cases_1d[i] = train_labels_cases_1d[i].to(device)\n",
    "    train_labels_deaths_1d[i] = train_labels_deaths_1d[i].to(device)\n",
    "    if len(train_labels_cases_1d[i].shape) == 1:\n",
    "        train_labels_cases_1d[i] = train_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(train_labels_deaths_1d[i].shape) == 1:\n",
    "        train_labels_deaths_1d[i] = train_labels_deaths_1d[i].unsqueeze(1)\n",
    "        \n",
    "for i in range(len(valid_past_cases_1d)):\n",
    "    valid_past_cases_1d[i] = valid_past_cases_1d[i].to(device)\n",
    "    valid_past_deaths_1d[i] = valid_past_deaths_1d[i].to(device)\n",
    "    valid_labels_cases_1d[i] = valid_labels_cases_1d[i].to(device)\n",
    "    valid_labels_deaths_1d[i] = valid_labels_deaths_1d[i].to(device)\n",
    "    if len(valid_labels_cases_1d[i].shape) == 1:\n",
    "         valid_labels_cases_1d[i] = valid_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths_1d[i].shape) == 1:\n",
    "        valid_labels_deaths_1d[i] = valid_labels_deaths_1d[i].unsqueeze(1)\n",
    "\n",
    "for i in range(len(test_past_cases_1d)):\n",
    "    test_past_cases_1d[i] = test_past_cases_1d[i].to(device)\n",
    "    test_past_deaths_1d[i] = test_past_deaths_1d[i].to(device)\n",
    "    test_labels_cases_1d[i] = test_labels_cases_1d[i].to(device)\n",
    "    test_labels_deaths_1d[i] = test_labels_deaths_1d[i].to(device)\n",
    "    if len(test_labels_cases_1d[i].shape) == 1:\n",
    "        test_labels_cases_1d[i] = test_labels_cases_1d[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths_1d[i].shape) == 1:\n",
    "        test_labels_deaths_1d[i] = test_labels_deaths_1d[i].unsqueeze(1)\n",
    "        \n",
    "# Normalize attrs\n",
    "attrs[th.isnan(attrs)] = 0\n",
    "attr_mean = th.mean(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs - attr_mean\n",
    "attr_std = th.std(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs / attr_std\n",
    "\n",
    "new_eval_err = 1000\n",
    "optimizer = th.optim.Adam(gat_sir.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for idx in range(len(train_past_cases_1d)):\n",
    "        labels_cases = train_labels_cases_1d[idx]\n",
    "        labels_deaths = train_labels_deaths_1d[idx]\n",
    "        batch = th.cat([train_past_cases_1d[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = gat_sir(batch)\n",
    "        I = train_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "        D = train_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "        I_new, D_new = sir_1d_output(vals, I, D)\n",
    "        loss = my_msle_ID(I_new, D_new, labels_cases, labels_deaths)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    count = 0\n",
    "    with th.no_grad():\n",
    "        eval_errs = []\n",
    "        test_errs = []\n",
    "        test_mses = []\n",
    "        test_maes = []\n",
    "        for idx in range(14):\n",
    "            valid_feats = th.cat([valid_past_cases_1d[idx], attrs], dim=1)\n",
    "            eval_vals = gat_sir(valid_feats)\n",
    "            eval_I = valid_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "            eval_D = valid_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "            eval_labels_cases = valid_labels_cases_1d[idx]\n",
    "            eval_labels_deaths = valid_labels_deaths_1d[idx]\n",
    "            eval_I_new, eval_D_new = sir_1d_output(eval_vals, eval_I, eval_D)\n",
    "            err = my_msle_ID(eval_I_new, eval_D_new, eval_labels_cases, eval_labels_deaths)\n",
    "            eval_errs.append(err.cpu().numpy())\n",
    "        \n",
    "\n",
    "            test_feats = th.cat([test_past_cases_1d[idx], attrs], dim=1)\n",
    "            test_vals = gat_sir(test_feats)\n",
    "            test_I = test_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "            test_D = test_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "            test_cases = test_labels_cases_1d[idx]\n",
    "            test_deaths = test_labels_deaths_1d[idx]\n",
    "            test_I_new, test_D_new = sir_1d_output(test_vals, test_I, test_D)\n",
    "            test_err = my_msle_ID(test_I_new, test_D_new, test_cases, test_deaths)\n",
    "            test_mse = th.mean((test_I_new - test_labels_cases_1d[idx])**2)\n",
    "            test_mae = th.mean(th.abs(test_I_new - test_labels_cases_1d[idx]))\n",
    "            test_errs.append(test_err.cpu().numpy())\n",
    "            test_mses.append(test_mse.cpu().numpy())\n",
    "            test_maes.append(test_mae.cpu().numpy())\n",
    "        print('epoch={}, loss={:.3f}, validation loss = {:.3f}, test loss={:.3f}, test mse = {:.3f}, test mae = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs), np.mean(test_errs), np.mean(test_mses), np.mean(test_maes)))\n",
    "#        old_eval_err = new_eval_err\n",
    "#        new_eval_err = np.mean(eval_errs)\n",
    "#        if old_eval_err <= new_eval_err:\n",
    "#            R0_NYC = []\n",
    "#            R0_Sacramento = []\n",
    "#            gamma_NYC = []\n",
    "#            beta_NYC = []\n",
    "#            gamma_Sacramento = []\n",
    "#            beta_Sacramento = []\n",
    "#            train_vals = []\n",
    "#            for idx in range(19, len(train_past_cases)):\n",
    "#                labels = train_labels_cases[idx]\n",
    "#                batch = th.cat([train_past_cases[idx], attrs], dim=1)\n",
    "#                th.manual_seed(1)\n",
    "#                vals = mlp_sir(batch)\n",
    "#                gamma_NYC.append(vals[4][0])\n",
    "#                gamma_Sacramento.append(vals[202][0])\n",
    "#                beta_NYC.append(vals[4][0])\n",
    "#                beta_Sacramento.append(vals[202][0])\n",
    "#                R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "#                R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "#                R0_NYC.append(R_NYC_div)\n",
    "#                R0_Sacramento.append(R_Sacramento_div)\n",
    "#                I = train_past_cases[idx][:,-1].view(3142,1)\n",
    "#                D = train_past_deaths[idx][:,-1].view(3142,1)\n",
    "#                I_new, D_new = sir_1d_output(vals, I, D)\n",
    "#                train_vals.append(I_new)\n",
    "#            break\n",
    "#    print('epoch={}, loss={:.3f}, validation loss = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with th.no_grad():\n",
    "    R0_NYC = []\n",
    "    R0_Sacramento = []\n",
    "    gamma_NYC = []\n",
    "    beta_NYC = []\n",
    "    gamma_Sacramento = []\n",
    "    beta_Sacramento = []\n",
    "    train_vals = []\n",
    "    for idx in range(19, len(train_past_cases_1d)):\n",
    "        labels = train_labels_cases_1d[idx]\n",
    "        batch = th.cat([train_past_cases_1d[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = gat_sir(batch)\n",
    "        gamma_NYC.append(vals[4][0])\n",
    "        gamma_Sacramento.append(vals[202][0])\n",
    "        beta_NYC.append(vals[4][1])\n",
    "        beta_Sacramento.append(vals[202][1])\n",
    "        R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "        R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "        R0_NYC.append(R_NYC_div)\n",
    "        R0_Sacramento.append(R_Sacramento_div)  \n",
    "        I = train_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "        D = train_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "        I_new, D_new = sir_1d_output(vals, I, D)\n",
    "        train_vals.append(I_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAUy0lEQVR4nO3de4yV9b3v8fdXQNRqlVtVGC26sVYu6taBamzTwVIup1GwmmgPqXhOLU3das5uS2THxrqxTajuXY3dvdFqQo1Hbd3VTWy2Fiy0TeOFAalb6mVQ2WHQtgiWFhUU/Z4/5nHOOC6EYa1hmP7er2Rlnuf3fNda39+sZD6znt8zsyIzkSSV64C+bkCS1LcMAkkqnEEgSYUzCCSpcAaBJBVuYF83sDeGDx+eo0eP7us2JKlfWbVq1UuZOaL7eL8MgtGjR9Pa2trXbUhSvxIR/11r3FNDklQ4g0CSCmcQSFLh+uUagaTe9cYbb9De3s727dv7uhXthYMOOoimpiYGDRq0R/UGgaR3aW9v57DDDmP06NFERF+3ox7ITDZv3kx7ezvHHXfcHt3HU0OS3mX79u0MGzbMEOiHIoJhw4b16N2cQSCpJkOg/+rpa2cQSFLhDAJJ+6VvfOMbjBs3jpNPPplTTz2VRx55pK9b2is33XQTr776ao/u09LSwoknnsgpp5zCxIkTWbNmTeexVatWMWHCBMaMGcOVV15JIz5TxiCQtN956KGHuO+++1i9ejWPP/44y5Yt45hjjqnrMXfu3Nmg7npmb4IA4Pbbb+d3v/sdl112GfPmzesc/+IXv8gPf/hD2traaGtr4/7776+7R4NA0n7nxRdfZPjw4QwePBiA4cOHM3LkSAAWLFjAxIkTGT9+PHPnzu38jXjdunVMmTKFU045hdNOO41nn32WFStW8LGPfYxzzz2XsWPHAjBr1ixOP/10xo0bx6JFizqf89BDD2XevHmMGzeOKVOm8Oijj9LS0sLxxx/PkiVLAHjzzTeZN28eEydO5OSTT+YHP/gBACtWrKClpYULLriAD3/4w8yePZvM5Oabb+aFF15g8uTJTJ48GYA77riDCRMmMH78eK666qrdfi/OPPNMNm7c2Pl9+ctf/sIZZ5xBRHDxxRdz77331v399vJRSe9p9Pyf98rjrl/4qV0emzp1KgsWLOBDH/oQU6ZM4cILL+TjH/84AJdffjnXXHMNAJ/97Ge57777OOecc5g9ezbz58/nvPPOY/v27bz11lts2LCB1atX88QTT3ReSnnrrbcydOhQXnvtNSZOnMj555/PsGHDeOWVVzj77LO54YYbOO+88/jqV7/K0qVL+f3vf8+cOXM499xzueWWWzj88MNZuXIlO3bs4KyzzmLq1KkAPPbYY6xdu5aRI0dy1lln8dvf/pYrr7ySb33rWyxfvpzhw4fzwgsvcNVVV7Fq1SqGDBnC1KlTuffee5k1a9Yuvxf3339/5/GNGzfS1NTUeaypqakzJOphEEja7xx66KGsWrWK3/zmNyxfvpwLL7yQhQsXcskll7B8+XKuv/56Xn31VbZs2cK4ceNoaWlh48aNnHfeeUDHH1S9bdKkSe+4nv7mm2/mnnvuAWDDhg20tbUxbNgwDjzwQKZPnw7AhAkTGDx4MIMGDWLChAmsX78egF/84hc8/vjj3H333QBs3bqVtrY2DjzwQCZNmtT5Q/rUU09l/fr1fPSjH33HvFauXElLSwsjRnT8A9DZs2fz61//umYQzJ49m9dff51t27a9Y42gNxgEkt7Te/3m3psGDBhAS0sLLS0tTJgwgcWLF3PRRRdx2WWX0drayjHHHMO111672+vl3/e+93Vur1ixgmXLlvHQQw9xyCGH0NLS0nn/QYMGdV52ecABB3SeljrggAM61xcyk29/+9tMmzbtHc+xYsWKzvq3e693TeL222/n9NNPZ968eVxxxRX87Gc/Y9SoUbS3t3fWtLe3M2rUqLqeB1wjkLQfevrpp2lra+vcX7NmDR/84Ac7f2gPHz6cbdu2df5mfthhh9HU1NR5vnzHjh01F2i3bt3KkCFDOOSQQ3jqqad4+OGHe9TXtGnT+N73vscbb7wBwDPPPMMrr7zynvc57LDD+Otf/wp0vDv51a9+xUsvvcSbb77JHXfc0XnKq5aI4LrrruPhhx/mqaee4uijj+b9738/Dz/8MJnJj3/8Y2bOnNmjOdTiOwJJ+51t27ZxxRVX8Oc//5mBAwcyZswYFi1axBFHHMHnP/95xo8fz1FHHcXEiRM773PbbbfxhS98gWuuuYZBgwbx05/+9F2PO336dL7//e9z0kknceKJJ3LGGWf0qK9LL72U9evXc9ppp5GZjBgxYreLtXPnzmX69OmMHDmS5cuXs3DhQiZPnkxm8qlPfWq3P8gPPvhgvvzlL3PDDTdwyy238N3vfpdLLrmE1157jRkzZjBjxowezaGWaMQ1qPtac3Nz+sE0Uu958sknOemkk/q6DdWh1msYEasys7l7raeGJKlwBoEkFc4gkFRTfzxtrA49fe0MAknvctBBB7F582bDoB96+/MIuv4txe541ZCkd2lqaqK9vZ1Nmzb1dSvaC29/QtmeMggkvcugQYP2+NOt1P95akiSCmcQSFLhGhIEETE9Ip6OiHURMb/G8cERcVd1/JGIGN3t+LERsS0ivtKIfiRJe67uIIiIAcB3gBnAWOAzETG2W9nngJczcwxwI/DNbse/Bfxnvb1IknquEe8IJgHrMvO5zHwduBPo/s8zZgKLq+27gU9E9W/+ImIW8DywtgG9SJJ6qBFBMArY0GW/vRqrWZOZO4GtwLCIOBS4Cvjn3T1JRMyNiNaIaPWSNklqnL5eLL4WuDEzt+2uMDMXZWZzZja//aEOkqT6NeLvCDYCXT9Vuqkaq1XTHhEDgcOBzcBHgAsi4nrgCOCtiNiemf/WgL4kSXugEUGwEjghIo6j4wf+RcD/7FazBJgDPARcAPwyO/52/WNvF0TEtcA2Q0CS9q26gyAzd0bE5cADwADg1sxcGxELgNbMXALcAtwWEeuALXSEhSRpP+AH00hSIfxgGklSTQaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhGhIEETE9Ip6OiHURMb/G8cERcVd1/JGIGF2NfzIiVkXEf1Vfz25EP5KkPVd3EETEAOA7wAxgLPCZiBjbrexzwMuZOQa4EfhmNf4ScE5mTgDmALfV248kqWca8Y5gErAuM5/LzNeBO4GZ3WpmAour7buBT0REZOZjmflCNb4WODgiBjegJ0nSHmpEEIwCNnTZb6/GatZk5k5gKzCsW835wOrM3NGAniRJe2hgXzcAEBHj6DhdNPU9auYCcwGOPfbYfdSZJP3ta8Q7go3AMV32m6qxmjURMRA4HNhc7TcB9wAXZ+azu3qSzFyUmc2Z2TxixIgGtC1JgsYEwUrghIg4LiIOBC4ClnSrWULHYjDABcAvMzMj4gjg58D8zPxtA3qRJPVQ3UFQnfO/HHgAeBL4SWaujYgFEXFuVXYLMCwi1gFfAt6+xPRyYAxwTUSsqW4fqLcnSdKei8zs6x56rLm5OVtbW/u6DUnqVyJiVWY2dx/3L4slqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSpcQ4IgIqZHxNMRsS4i5tc4Pjgi7qqOPxIRo7sc+6dq/OmImNaIfiRJe67uIIiIAcB3gBnAWOAzETG2W9nngJczcwxwI/DN6r5jgYuAccB04LvV40mS9pFGvCOYBKzLzOcy83XgTmBmt5qZwOJq+27gExER1fidmbkjM58H1lWPJ0naRxoRBKOADV3226uxmjWZuRPYCgzbw/sCEBFzI6I1Ilo3bdrUgLYlSdCPFoszc1FmNmdm84gRI/q6HUn6m9GIINgIHNNlv6kaq1kTEQOBw4HNe3hfSVIvakQQrAROiIjjIuJAOhZ/l3SrWQLMqbYvAH6ZmVmNX1RdVXQccALwaAN6kiTtoYH1PkBm7oyIy4EHgAHArZm5NiIWAK2ZuQS4BbgtItYBW+gIC6q6nwC/B3YC/5CZb9bbkyRpz0XHL+b9S3Nzc7a2tvZ1G5LUr0TEqsxs7j7ebxaLJUm9wyCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSpcXUEQEUMjYmlEtFVfh+yibk5V0xYRc6qxQyLi5xHxVESsjYiF9fQiSdo79b4jmA88mJknAA9W++8QEUOBrwEfASYBX+sSGP+SmR8G/h44KyJm1NmPJKmH6g2CmcDiansxMKtGzTRgaWZuycyXgaXA9Mx8NTOXA2Tm68BqoKnOfiRJPVRvEByZmS9W238AjqxRMwrY0GW/vRrrFBFHAOfQ8a5CkrQPDdxdQUQsA46qcejqrjuZmRGRPW0gIgYCdwA3Z+Zz71E3F5gLcOyxx/b0aSRJu7DbIMjMKbs6FhF/jIijM/PFiDga+FONso1AS5f9JmBFl/1FQFtm3rSbPhZVtTQ3N/c4cCRJtdV7amgJMKfangP8R42aB4CpETGkWiSeWo0REV8HDgf+T519SJL2Ur1BsBD4ZES0AVOqfSKiOSJ+BJCZW4DrgJXVbUFmbomIJjpOL40FVkfEmoi4tM5+JEk9FJn97yxLc3Nztra29nUbktSvRMSqzGzuPu5fFktS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVLi6giAihkbE0ohoq74O2UXdnKqmLSLm1Di+JCKeqKcXSdLeqfcdwXzgwcw8AXiw2n+HiBgKfA34CDAJ+FrXwIiITwPb6uxDkrSX6g2CmcDiansxMKtGzTRgaWZuycyXgaXAdICIOBT4EvD1OvuQJO2leoPgyMx8sdr+A3BkjZpRwIYu++3VGMB1wL8Cr+7uiSJibkS0RkTrpk2b6mhZktTVwN0VRMQy4Kgah67uupOZGRG5p08cEacCf5eZ/xgRo3dXn5mLgEUAzc3Ne/w8kqT3ttsgyMwpuzoWEX+MiKMz88WIOBr4U42yjUBLl/0mYAVwJtAcEeurPj4QESsyswVJ0j5T76mhJcDbVwHNAf6jRs0DwNSIGFItEk8FHsjM72XmyMwcDXwUeMYQkKR9r94gWAh8MiLagCnVPhHRHBE/AsjMLXSsBaysbguqMUnSfiAy+9/p9ubm5mxtbe3rNiSpX4mIVZnZ3H3cvyyWpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVLjKzr3vosYjYBPx3X/fRQ8OBl/q6iX3MOZfBOfcfH8zMEd0H+2UQ9EcR0ZqZzX3dx77knMvgnPs/Tw1JUuEMAkkqnEGw7yzq6wb6gHMug3Pu51wjkKTC+Y5AkgpnEEhS4QyCBoqIoRGxNCLaqq9DdlE3p6ppi4g5NY4viYgner/j+tUz54g4JCJ+HhFPRcTaiFi4b7vvmYiYHhFPR8S6iJhf4/jgiLirOv5IRIzucuyfqvGnI2Lavuy7Hns754j4ZESsioj/qr6eva973xv1vMbV8WMjYltEfGVf9dwQmemtQTfgemB+tT0f+GaNmqHAc9XXIdX2kC7HPw38X+CJvp5Pb88ZOASYXNUcCPwGmNHXc9rFPAcAzwLHV73+DhjbreYy4PvV9kXAXdX22Kp+MHBc9TgD+npOvTznvwdGVtvjgY19PZ/enG+X43cDPwW+0tfz6cnNdwSNNRNYXG0vBmbVqJkGLM3MLZn5MrAUmA4QEYcCXwK+vg96bZS9nnNmvpqZywEy83VgNdC0D3reG5OAdZn5XNXrnXTMvauu34u7gU9ERFTjd2bmjsx8HlhXPd7+bq/nnJmPZeYL1fha4OCIGLxPut579bzGRMQs4Hk65tuvGASNdWRmvlht/wE4skbNKGBDl/32agzgOuBfgVd7rcPGq3fOAETEEcA5wIO90WQD7HYOXWsycyewFRi2h/fdH9Uz567OB1Zn5o5e6rNR9nq+1S9xVwH/vA/6bLiBfd1AfxMRy4Cjahy6uutOZmZE7PG1uRFxKvB3mfmP3c879rXemnOXxx8I3AHcnJnP7V2X2h9FxDjgm8DUvu6ll10L3JiZ26o3CP2KQdBDmTllV8ci4o8RcXRmvhgRRwN/qlG2EWjpst8ErADOBJojYj0dr8sHImJFZrbQx3pxzm9bBLRl5k0NaLe3bASO6bLfVI3Vqmmvwu1wYPMe3nd/VM+ciYgm4B7g4sx8tvfbrVs98/0IcEFEXA8cAbwVEdsz8996v+0G6OtFir+lG3AD71w4vb5GzVA6ziMOqW7PA0O71Yym/ywW1zVnOtZD/h04oK/nspt5DqRjkfs4/v9C4rhuNf/AOxcSf1Jtj+Odi8XP0T8Wi+uZ8xFV/af7eh77Yr7daq6lny0W93kDf0s3Os6NPgi0Acu6/LBrBn7Upe5/07FguA74XzUepz8FwV7PmY7fuBJ4ElhT3S7t6zm9x1z/B/AMHVeWXF2NLQDOrbYPouOKkXXAo8DxXe57dXW/p9lPr4xq5JyBrwKvdHld1wAf6Ov59OZr3OUx+l0Q+C8mJKlwXjUkSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLh/h+XiicUqSJfdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(len(R0_Sacramento))\n",
    "y1 = R0_Sacramento\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Sacramento R0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-66a84fa2b4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_past_cases_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m202\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pred_vals = []\n",
    "for i in range(len(train_past_cases_1d)):\n",
    "    pred_vals.append(train_vals[i][202].cpu().numpy())\n",
    "\n",
    "x = range(len(pred_vals))\n",
    "y1 = train_labels_Sacramento\n",
    "y2 = pred_vals\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Real\")\n",
    "plt.plot(x, y2, ls=\"-\", lw=2, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(R0_NYC))\n",
    "y_NYC = R0_NYC\n",
    "plt.plot(x, y_NYC, ls=\"-\", lw=2, label=\"NYC R0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_vals_NYC = []\n",
    "for i in range(79-19):\n",
    "    pred_vals_NYC.append(train_vals[i][4].cpu().numpy())\n",
    "\n",
    "x = range(60)\n",
    "y1 = train_labels_NYC\n",
    "y2 = pred_vals_NYC\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Real\")\n",
    "plt.plot(x, y2, ls=\"-\", lw=2, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-day Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrs: torch.Size([3142, 78])\n",
      "cases: (3142, 84)\n",
      "deaths: (3142, 84)\n",
      "tensor([ 4.0641e+01, -7.3955e+01,  4.0651e+01, -7.3955e+01,  1.0000e+00,\n",
      "         2.5828e+06,  1.2550e+06,  1.3938e+06,  4.7379e-01,  3.5671e+05,\n",
      "         3.5369e+04,  2.5047e+06,  3.4100e+01,  3.8667e+05,  3.0966e+05,\n",
      "         6.3500e+02,  9.7000e+00,  1.9580e+02,  1.9500e+01,  1.3841e+01,\n",
      "         2.3050e+01,  3.5442e+04,  9.3070e+03,  6.0000e+00,  1.2000e+01,\n",
      "         3.1800e+02,  4.5415e+00,  9.0415e+04,  8.6783e+04,  8.1356e+04,\n",
      "         7.8035e+04,  7.9604e+04,  7.6959e+04,  8.6716e+04,  8.3968e+04,\n",
      "         9.6663e+04,  9.9134e+04,  1.0605e+05,  1.1679e+05,  9.7154e+04,\n",
      "         1.0570e+05,  1.6196e+05,  1.7958e+05,  1.4949e+05,  1.7469e+05,\n",
      "         6.3789e+04,  7.8116e+04,  5.5241e+04,  6.8866e+04,  6.4628e+04,\n",
      "         8.8066e+04,  3.5780e+04,  5.8209e+04,  1.2524e+04,  2.8426e+04,\n",
      "         1.5400e+02,  2.4000e+01,  3.3000e+01,  1.5100e+02,  3.4100e+02,\n",
      "         4.9300e+02,  1.1160e+03,  2.1390e+03,  2.8520e+03,  3.5520e+03,\n",
      "         5.1020e+03,  9.2622e+02,  7.3751e+05,  7.3750e+05,  7.3750e+05,\n",
      "         7.3750e+05,  7.3750e+05,  7.3750e+05,  7.3750e+05,  7.3750e+05,\n",
      "         8.1530e-01,         nan,         nan])\n",
      "[    3     3     4    10    14    24    24    34    53    62   157   505\n",
      "  1195  1518  2484  2857  3494  4237  5232  6095  6750  8129  8887 10171\n",
      " 11160 12274 13290 15700 17504 18558 19702 20879 22082 23394 24715 26243\n",
      " 27471 28404 29306 31969 33521 34705 35763 36482 37030 37694 38481 39354\n",
      " 40648 41660 42487 43014 43587 44236 44872 45519 46275 46839 47183 47579\n",
      " 47974 48550 48998 49461 49817 50072 50331 50667 51095 51581 51991 52298\n",
      " 52485 52681 52889 53385 53639 53902 54175 54360 54560 54779 55147 55446]\n",
      "[   0    0    0    0    0    0    0    1    1    1    1    1    1    1\n",
      "    1   14   27   45   64   81  102  167  185  215  261  328  385  485\n",
      "  610  896 1022 1153 1313 1473 1640 1843 2028 2132 2839 3007 3164 3317\n",
      " 3451 3749 3900 4071 4247 4413 4568 4738 4878 4970 5064 5155 5228 5320\n",
      " 5410 5508 5569 5638 5677 5783 5853 5924 5976 6017 6077 6127 6194 6246\n",
      " 6278 6304 6330 6353 6401 6435 6459 6479 6504 6517 6533 6544 6561 6582]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "attr_cols = []\n",
    "\n",
    "# Set the variable to True if we want to specify features ourselves.\n",
    "use_specified_fields = False\n",
    "\n",
    "if use_specified_fields:\n",
    "    f = open(\"fields.txt\", \"r\")\n",
    "    fields = f.readlines()\n",
    "    for field in fields:\n",
    "        field = field.rstrip()\n",
    "        arr = np.array(df[field])\n",
    "        if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
    "            attr_cols.append(np.array(arr, dtype=np.float32))\n",
    "else:\n",
    "    for i in range(6, 86):\n",
    "        arr = np.array(df[keys[i]])\n",
    "        if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
    "            attr_cols.append(np.array(arr, dtype=np.float32))\n",
    "\n",
    "attrs = th.tensor(np.stack(attr_cols, 1), dtype=th.float32)\n",
    "cases = []\n",
    "# for i in range(87, 216):\n",
    "for i in range(132, 216):\n",
    "    cases.append(np.array(df[keys[i]]))\n",
    "cases = np.stack(cases, 1)\n",
    "deaths = []\n",
    "# for i in range(218, 347):\n",
    "for i in range(263, 347):\n",
    "    deaths.append(np.array(df[keys[i]]))\n",
    "deaths = np.stack(deaths, 1)\n",
    "\n",
    "pop = attrs[:,5]\n",
    "pop = pop.view(3142, 1)\n",
    "pop[1834] = 1 \n",
    "\n",
    "print('attrs:', attrs.shape)\n",
    "print('cases:', cases.shape)\n",
    "print('deaths:', deaths.shape)\n",
    "print(attrs[0])\n",
    "print(cases[0])\n",
    "print(deaths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "num_days = cases.shape[1]\n",
    "num_valid_days = 15\n",
    "num_test_days = 15\n",
    "train_valid_split = num_days - num_valid_days - num_test_days\n",
    "valid_test_split = num_days - num_test_days\n",
    "in_len = 20\n",
    "out_len = 7\n",
    "out_size = 7\n",
    "\n",
    "train_past_cases = []\n",
    "train_past_deaths = []\n",
    "train_labels_cases = []\n",
    "train_labels_deaths = []\n",
    "for start in range(14):\n",
    "    end = start + in_len + out_len - 1\n",
    "    end_begin = end - out_len\n",
    "    train_past_cases.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "    #train_past_deaths.append(th.mul(th.tensor(deaths[:,start:end_begin], dtype=th.float32),1))\n",
    "    train_past_deaths.append(th.mul(th.tensor(deaths[:,start:end_begin], dtype=th.float32),1))\n",
    "    train_labels_cases.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "    #train_labels_deaths.append(th.mul(th.tensor(deaths[:,end_begin:end], dtype=th.float32),1))\n",
    "    train_labels_deaths.append(th.mul(th.tensor(deaths[:,end_begin:end], dtype=th.float32),1))\n",
    "\n",
    "for start in range(14, train_valid_split - in_len - out_len + 1):\n",
    "    end = start + in_len + out_len - 1\n",
    "    end_begin = end - out_len\n",
    "    train_past_cases.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "    #train_past_deaths.append(th.mul(th.tensor(deaths[:,start:end_begin], dtype=th.float32),1))\n",
    "    train_past_deaths.append(th.mul(th.tensor(cases[:,start-14:end_begin-14], dtype=th.float32),1))\n",
    "    train_labels_cases.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "    #train_labels_deaths.append(th.mul(th.tensor(deaths[:,end_begin:end], dtype=th.float32),1))\n",
    "    train_labels_deaths.append(th.mul(th.tensor(cases[:,end_begin-14:end-14], dtype=th.float32),1))\n",
    "\n",
    "valid_past_cases = []\n",
    "valid_past_deaths = []\n",
    "valid_labels_cases = []\n",
    "valid_labels_deaths = []\n",
    "for start in range(train_valid_split - in_len - out_len + 1, valid_test_split - in_len - out_len):\n",
    "    end = start + in_len + out_len - 1\n",
    "    end_begin = end - out_len\n",
    "    valid_past_cases.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "    #valid_past_deaths.append(th.mul(th.tensor(deaths[:,start:end_begin], dtype=th.float32),50))\n",
    "    valid_past_deaths.append(th.mul(th.tensor(cases[:,start-14:end_begin-14], dtype=th.float32),1))\n",
    "    valid_labels_cases.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "    #valid_labels_deaths.append(th.mul(th.tensor(deaths[:,end_begin:end], dtype=th.float32),50))\n",
    "    valid_labels_deaths.append(th.mul(th.tensor(cases[:,end_begin-14:end-14], dtype=th.float32),1))\n",
    "    \n",
    "test_past_cases = []\n",
    "test_past_deaths = []\n",
    "test_labels_cases = []\n",
    "test_labels_deaths = []\n",
    "for start in range(valid_test_split - in_len - out_len + 1, num_days - in_len - out_len):\n",
    "    end = start + in_len + out_len - 1\n",
    "    end_begin = end - out_len\n",
    "    test_past_cases.append(th.tensor(cases[:,start:end_begin], dtype=th.float32))\n",
    "    # test_past_deaths.append(th.mul(th.tensor(deaths[:,start:end_begin], dtype=th.float32),50))\n",
    "    test_past_deaths.append(th.mul(th.tensor(cases[:,start-14:end_begin-14], dtype=th.float32),1))\n",
    "    test_labels_cases.append(th.tensor(cases[:,end_begin:end], dtype=th.float32))\n",
    "    #test_labels_deaths.append(th.mul(th.tensor(deaths[:,end_begin:end], dtype=th.float32),50))\n",
    "    test_labels_deaths.append(th.mul(th.tensor(cases[:,end_begin-1:end-1], dtype=th.float32),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sir_output(params, I, D):\n",
    "    gamma = params[:,0]\n",
    "    beta = params[:,1]\n",
    "    I[I != I] = 0.0\n",
    "    D[D != D] = 0.0\n",
    "    err = th.tensor([0],dtype=th.float)\n",
    "    err = err.to(device)\n",
    "    S = pop - I - D\n",
    "    I_lst = []\n",
    "    D_lst = []\n",
    "    for i in range(7):\n",
    "        S_new = th.add(S, - th.div(th.mul(beta.view(3142,1), th.mul(S, I)), pop))\n",
    "        I_new = th.add(th.add(I, th.mul(beta.view(3142,1), th.div(th.mul(S,I), pop))), - th.mul(gamma.view(3142,1), I))\n",
    "        D_new = th.add(D, th.mul(gamma.view(3142,1), I))\n",
    "        I_lst.append(I_new)\n",
    "        D_lst.append(D_new)\n",
    "        S = S_new\n",
    "        I = I_new\n",
    "        D = D_new\n",
    "    return th.cat(I_lst, dim = 1), th.cat(D_lst, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP - SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 97\n",
      "epoch=0, loss=3.338, validation loss = 4.170, test loss=4.432, test mse = 7348628.000, test mae = 413.594\n",
      "epoch=1, loss=3.301, validation loss = 4.113, test loss=4.329, test mse = 7355843.500, test mae = 413.069\n",
      "epoch=2, loss=3.259, validation loss = 4.048, test loss=4.204, test mse = 7364558.000, test mae = 412.442\n",
      "epoch=3, loss=3.213, validation loss = 3.973, test loss=4.059, test mse = 7374425.500, test mae = 411.674\n",
      "epoch=4, loss=3.163, validation loss = 3.890, test loss=3.890, test mse = 7385044.000, test mae = 410.764\n",
      "epoch=5, loss=3.109, validation loss = 3.796, test loss=3.691, test mse = 7395536.000, test mae = 409.567\n",
      "epoch=6, loss=3.051, validation loss = 3.691, test loss=3.452, test mse = 7403334.500, test mae = 407.851\n",
      "epoch=7, loss=2.990, validation loss = 3.571, test loss=3.162, test mse = 7397291.500, test mae = 405.106\n",
      "epoch=8, loss=2.922, validation loss = 3.432, test loss=2.789, test mse = 7233640.500, test mae = 397.638\n",
      "epoch=9, loss=2.848, validation loss = 3.260, test loss=2.289, test mse = 6224608.000, test mae = 369.143\n",
      "epoch=10, loss=2.766, validation loss = 3.036, test loss=1.774, test mse = 4217693.500, test mae = 308.819\n",
      "epoch=11, loss=2.676, validation loss = 2.755, test loss=1.399, test mse = 2379781.500, test mae = 244.911\n",
      "epoch=12, loss=2.570, validation loss = 2.437, test loss=1.155, test mse = 1322131.875, test mae = 196.825\n",
      "epoch=13, loss=2.448, validation loss = 2.203, test loss=0.989, test mse = 1052746.375, test mae = 167.493\n",
      "epoch=14, loss=2.317, validation loss = 2.017, test loss=0.887, test mse = 1081467.000, test mae = 146.524\n",
      "epoch=15, loss=2.182, validation loss = 1.857, test loss=0.815, test mse = 1309713.375, test mae = 133.220\n",
      "epoch=16, loss=2.039, validation loss = 1.715, test loss=0.761, test mse = 1638617.875, test mae = 124.394\n",
      "epoch=17, loss=1.899, validation loss = 1.606, test loss=0.719, test mse = 2036272.375, test mae = 118.582\n",
      "epoch=18, loss=1.804, validation loss = 1.534, test loss=0.686, test mse = 2480230.250, test mae = 114.659\n",
      "epoch=19, loss=1.749, validation loss = 1.475, test loss=0.661, test mse = 2950479.250, test mae = 112.135\n",
      "epoch=20, loss=1.720, validation loss = 1.434, test loss=0.642, test mse = 3429638.000, test mae = 110.423\n",
      "epoch=21, loss=1.701, validation loss = 1.406, test loss=0.628, test mse = 3909590.000, test mae = 109.349\n",
      "epoch=22, loss=1.688, validation loss = 1.387, test loss=0.617, test mse = 4385405.500, test mae = 108.637\n",
      "epoch=23, loss=1.677, validation loss = 1.372, test loss=0.608, test mse = 4851001.000, test mae = 108.146\n",
      "epoch=24, loss=1.669, validation loss = 1.360, test loss=0.600, test mse = 5296798.500, test mae = 107.770\n",
      "epoch=25, loss=1.661, validation loss = 1.351, test loss=0.595, test mse = 5711093.500, test mae = 107.496\n",
      "epoch=26, loss=1.655, validation loss = 1.342, test loss=0.590, test mse = 6084762.000, test mae = 107.359\n",
      "epoch=27, loss=1.650, validation loss = 1.336, test loss=0.587, test mse = 6411619.500, test mae = 107.421\n",
      "epoch=28, loss=1.645, validation loss = 1.330, test loss=0.584, test mse = 6689924.500, test mae = 107.722\n",
      "epoch=29, loss=1.641, validation loss = 1.324, test loss=0.582, test mse = 6921282.000, test mae = 108.288\n",
      "epoch=30, loss=1.637, validation loss = 1.320, test loss=0.580, test mse = 7109427.500, test mae = 109.154\n",
      "epoch=31, loss=1.633, validation loss = 1.315, test loss=0.579, test mse = 7259117.500, test mae = 110.286\n",
      "epoch=32, loss=1.630, validation loss = 1.312, test loss=0.578, test mse = 7375340.000, test mae = 111.589\n",
      "epoch=33, loss=1.627, validation loss = 1.308, test loss=0.577, test mse = 7462675.500, test mae = 113.036\n",
      "epoch=34, loss=1.624, validation loss = 1.305, test loss=0.577, test mse = 7523100.500, test mae = 114.590\n",
      "epoch=35, loss=1.621, validation loss = 1.302, test loss=0.577, test mse = 7555193.500, test mae = 116.194\n",
      "epoch=36, loss=1.619, validation loss = 1.300, test loss=0.577, test mse = 7568199.500, test mae = 117.806\n",
      "epoch=37, loss=1.616, validation loss = 1.297, test loss=0.577, test mse = 7565864.500, test mae = 119.393\n",
      "epoch=38, loss=1.614, validation loss = 1.295, test loss=0.577, test mse = 7550348.000, test mae = 120.927\n",
      "epoch=39, loss=1.611, validation loss = 1.292, test loss=0.578, test mse = 7522704.500, test mae = 122.388\n",
      "epoch=40, loss=1.609, validation loss = 1.290, test loss=0.578, test mse = 7482422.500, test mae = 123.762\n",
      "epoch=41, loss=1.607, validation loss = 1.288, test loss=0.579, test mse = 7430220.000, test mae = 125.039\n",
      "epoch=42, loss=1.604, validation loss = 1.286, test loss=0.579, test mse = 7366652.500, test mae = 126.214\n",
      "epoch=43, loss=1.602, validation loss = 1.284, test loss=0.580, test mse = 7288804.000, test mae = 127.274\n",
      "epoch=44, loss=1.600, validation loss = 1.282, test loss=0.581, test mse = 7201022.500, test mae = 128.226\n",
      "epoch=45, loss=1.598, validation loss = 1.280, test loss=0.581, test mse = 7103653.500, test mae = 129.069\n",
      "epoch=46, loss=1.595, validation loss = 1.278, test loss=0.582, test mse = 6997136.000, test mae = 129.794\n",
      "epoch=47, loss=1.593, validation loss = 1.277, test loss=0.583, test mse = 6882173.500, test mae = 130.405\n",
      "epoch=48, loss=1.590, validation loss = 1.275, test loss=0.583, test mse = 6759194.000, test mae = 130.906\n",
      "epoch=49, loss=1.588, validation loss = 1.273, test loss=0.584, test mse = 6628462.500, test mae = 131.294\n",
      "epoch=50, loss=1.586, validation loss = 1.271, test loss=0.585, test mse = 6490450.000, test mae = 131.568\n",
      "epoch=51, loss=1.583, validation loss = 1.269, test loss=0.585, test mse = 6346038.000, test mae = 131.739\n",
      "epoch=52, loss=1.581, validation loss = 1.268, test loss=0.586, test mse = 6196943.500, test mae = 131.814\n",
      "epoch=53, loss=1.578, validation loss = 1.266, test loss=0.586, test mse = 6042792.000, test mae = 131.787\n",
      "epoch=54, loss=1.575, validation loss = 1.264, test loss=0.587, test mse = 5884568.000, test mae = 131.662\n",
      "epoch=55, loss=1.573, validation loss = 1.262, test loss=0.587, test mse = 5722913.500, test mae = 131.442\n",
      "epoch=56, loss=1.570, validation loss = 1.260, test loss=0.588, test mse = 5558544.000, test mae = 131.130\n",
      "epoch=57, loss=1.567, validation loss = 1.258, test loss=0.588, test mse = 5394707.000, test mae = 130.739\n",
      "epoch=58, loss=1.564, validation loss = 1.257, test loss=0.589, test mse = 5230731.500, test mae = 130.270\n",
      "epoch=59, loss=1.562, validation loss = 1.255, test loss=0.589, test mse = 5066230.500, test mae = 129.719\n",
      "epoch=60, loss=1.559, validation loss = 1.253, test loss=0.589, test mse = 4902011.500, test mae = 129.090\n",
      "epoch=61, loss=1.556, validation loss = 1.251, test loss=0.590, test mse = 4738990.500, test mae = 128.389\n",
      "epoch=62, loss=1.553, validation loss = 1.249, test loss=0.590, test mse = 4578083.500, test mae = 127.625\n",
      "epoch=63, loss=1.550, validation loss = 1.247, test loss=0.590, test mse = 4419704.500, test mae = 126.796\n",
      "epoch=64, loss=1.547, validation loss = 1.245, test loss=0.590, test mse = 4264887.500, test mae = 125.906\n",
      "epoch=65, loss=1.544, validation loss = 1.243, test loss=0.590, test mse = 4114544.250, test mae = 124.963\n",
      "epoch=66, loss=1.540, validation loss = 1.241, test loss=0.590, test mse = 3968834.750, test mae = 123.966\n",
      "epoch=67, loss=1.537, validation loss = 1.239, test loss=0.590, test mse = 3829002.750, test mae = 122.926\n",
      "epoch=68, loss=1.534, validation loss = 1.237, test loss=0.590, test mse = 3695284.250, test mae = 121.847\n",
      "epoch=69, loss=1.531, validation loss = 1.235, test loss=0.590, test mse = 3567706.750, test mae = 120.732\n",
      "epoch=70, loss=1.527, validation loss = 1.233, test loss=0.590, test mse = 3446492.000, test mae = 119.584\n",
      "epoch=71, loss=1.524, validation loss = 1.231, test loss=0.590, test mse = 3331455.250, test mae = 118.408\n",
      "epoch=72, loss=1.520, validation loss = 1.229, test loss=0.590, test mse = 3222674.750, test mae = 117.215\n",
      "epoch=73, loss=1.517, validation loss = 1.227, test loss=0.589, test mse = 3120608.250, test mae = 116.013\n",
      "epoch=74, loss=1.513, validation loss = 1.225, test loss=0.589, test mse = 3023905.750, test mae = 114.800\n",
      "epoch=75, loss=1.510, validation loss = 1.222, test loss=0.589, test mse = 2932007.250, test mae = 113.577\n",
      "epoch=76, loss=1.506, validation loss = 1.220, test loss=0.588, test mse = 2843298.000, test mae = 112.341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=77, loss=1.503, validation loss = 1.218, test loss=0.588, test mse = 2758240.750, test mae = 111.109\n",
      "epoch=78, loss=1.499, validation loss = 1.216, test loss=0.588, test mse = 2675845.750, test mae = 109.878\n",
      "epoch=79, loss=1.496, validation loss = 1.213, test loss=0.587, test mse = 2595299.250, test mae = 108.647\n",
      "epoch=80, loss=1.492, validation loss = 1.211, test loss=0.587, test mse = 2515777.000, test mae = 107.419\n",
      "epoch=81, loss=1.488, validation loss = 1.209, test loss=0.586, test mse = 2436730.250, test mae = 106.193\n",
      "epoch=82, loss=1.485, validation loss = 1.206, test loss=0.586, test mse = 2357792.250, test mae = 104.969\n",
      "epoch=83, loss=1.481, validation loss = 1.204, test loss=0.585, test mse = 2278160.250, test mae = 103.740\n",
      "epoch=84, loss=1.477, validation loss = 1.202, test loss=0.584, test mse = 2197606.500, test mae = 102.513\n",
      "epoch=85, loss=1.474, validation loss = 1.199, test loss=0.584, test mse = 2115377.250, test mae = 101.282\n",
      "epoch=86, loss=1.470, validation loss = 1.197, test loss=0.583, test mse = 2030591.125, test mae = 100.050\n",
      "epoch=87, loss=1.466, validation loss = 1.194, test loss=0.582, test mse = 1944098.625, test mae = 98.814\n",
      "epoch=88, loss=1.462, validation loss = 1.192, test loss=0.582, test mse = 1855734.625, test mae = 97.572\n",
      "epoch=89, loss=1.459, validation loss = 1.189, test loss=0.581, test mse = 1765465.375, test mae = 96.324\n",
      "epoch=90, loss=1.455, validation loss = 1.187, test loss=0.580, test mse = 1673086.875, test mae = 95.067\n",
      "epoch=91, loss=1.451, validation loss = 1.185, test loss=0.579, test mse = 1577973.000, test mae = 93.798\n",
      "epoch=92, loss=1.448, validation loss = 1.182, test loss=0.579, test mse = 1481561.625, test mae = 92.530\n",
      "epoch=93, loss=1.444, validation loss = 1.180, test loss=0.578, test mse = 1384066.875, test mae = 91.258\n",
      "epoch=94, loss=1.440, validation loss = 1.177, test loss=0.577, test mse = 1286305.375, test mae = 89.982\n",
      "epoch=95, loss=1.437, validation loss = 1.175, test loss=0.576, test mse = 1189184.500, test mae = 88.709\n",
      "epoch=96, loss=1.433, validation loss = 1.172, test loss=0.575, test mse = 1093608.250, test mae = 87.429\n",
      "epoch=97, loss=1.429, validation loss = 1.170, test loss=0.574, test mse = 1000694.688, test mae = 86.145\n",
      "epoch=98, loss=1.425, validation loss = 1.167, test loss=0.573, test mse = 911641.188, test mae = 84.861\n",
      "epoch=99, loss=1.422, validation loss = 1.165, test loss=0.572, test mse = 827654.062, test mae = 83.584\n",
      "epoch=100, loss=1.418, validation loss = 1.162, test loss=0.571, test mse = 749690.938, test mae = 82.319\n",
      "epoch=101, loss=1.414, validation loss = 1.160, test loss=0.570, test mse = 678564.812, test mae = 81.074\n",
      "epoch=102, loss=1.411, validation loss = 1.158, test loss=0.569, test mse = 614610.875, test mae = 79.847\n",
      "epoch=103, loss=1.407, validation loss = 1.155, test loss=0.568, test mse = 557688.062, test mae = 78.640\n",
      "epoch=104, loss=1.403, validation loss = 1.153, test loss=0.567, test mse = 507618.594, test mae = 77.459\n",
      "epoch=105, loss=1.400, validation loss = 1.150, test loss=0.566, test mse = 463907.500, test mae = 76.309\n",
      "epoch=106, loss=1.396, validation loss = 1.148, test loss=0.565, test mse = 425771.750, test mae = 75.191\n",
      "epoch=107, loss=1.392, validation loss = 1.145, test loss=0.564, test mse = 392171.625, test mae = 74.103\n",
      "epoch=108, loss=1.389, validation loss = 1.143, test loss=0.563, test mse = 362437.094, test mae = 73.049\n",
      "epoch=109, loss=1.385, validation loss = 1.140, test loss=0.562, test mse = 335812.125, test mae = 72.033\n",
      "epoch=110, loss=1.382, validation loss = 1.138, test loss=0.561, test mse = 311592.500, test mae = 71.051\n",
      "epoch=111, loss=1.378, validation loss = 1.136, test loss=0.560, test mse = 289289.156, test mae = 70.099\n",
      "epoch=112, loss=1.375, validation loss = 1.133, test loss=0.559, test mse = 268532.250, test mae = 69.176\n",
      "epoch=113, loss=1.371, validation loss = 1.131, test loss=0.558, test mse = 249096.391, test mae = 68.282\n",
      "epoch=114, loss=1.368, validation loss = 1.128, test loss=0.557, test mse = 230785.875, test mae = 67.412\n",
      "epoch=115, loss=1.364, validation loss = 1.126, test loss=0.556, test mse = 213560.375, test mae = 66.566\n",
      "epoch=116, loss=1.361, validation loss = 1.124, test loss=0.555, test mse = 197396.750, test mae = 65.742\n",
      "epoch=117, loss=1.358, validation loss = 1.121, test loss=0.554, test mse = 182282.125, test mae = 64.941\n",
      "epoch=118, loss=1.354, validation loss = 1.119, test loss=0.553, test mse = 168177.156, test mae = 64.160\n",
      "epoch=119, loss=1.351, validation loss = 1.117, test loss=0.552, test mse = 155080.203, test mae = 63.400\n",
      "epoch=120, loss=1.348, validation loss = 1.114, test loss=0.551, test mse = 142981.125, test mae = 62.659\n",
      "epoch=121, loss=1.345, validation loss = 1.112, test loss=0.550, test mse = 131855.094, test mae = 61.938\n",
      "epoch=122, loss=1.342, validation loss = 1.110, test loss=0.549, test mse = 121670.711, test mae = 61.239\n",
      "epoch=123, loss=1.339, validation loss = 1.107, test loss=0.547, test mse = 112406.062, test mae = 60.564\n",
      "epoch=124, loss=1.336, validation loss = 1.105, test loss=0.546, test mse = 104012.523, test mae = 59.920\n",
      "epoch=125, loss=1.333, validation loss = 1.103, test loss=0.545, test mse = 96446.148, test mae = 59.301\n",
      "epoch=126, loss=1.330, validation loss = 1.101, test loss=0.544, test mse = 89658.633, test mae = 58.701\n",
      "epoch=127, loss=1.327, validation loss = 1.098, test loss=0.543, test mse = 83597.180, test mae = 58.119\n",
      "epoch=128, loss=1.324, validation loss = 1.096, test loss=0.542, test mse = 78206.211, test mae = 57.553\n",
      "epoch=129, loss=1.322, validation loss = 1.094, test loss=0.541, test mse = 73401.242, test mae = 57.004\n",
      "epoch=130, loss=1.319, validation loss = 1.092, test loss=0.540, test mse = 69148.320, test mae = 56.471\n",
      "epoch=131, loss=1.317, validation loss = 1.089, test loss=0.539, test mse = 65409.754, test mae = 55.958\n",
      "epoch=132, loss=1.314, validation loss = 1.087, test loss=0.539, test mse = 62129.770, test mae = 55.465\n",
      "epoch=133, loss=1.311, validation loss = 1.085, test loss=0.538, test mse = 59255.109, test mae = 54.991\n",
      "epoch=134, loss=1.309, validation loss = 1.083, test loss=0.537, test mse = 56732.484, test mae = 54.533\n",
      "epoch=135, loss=1.307, validation loss = 1.081, test loss=0.536, test mse = 54518.766, test mae = 54.092\n",
      "epoch=136, loss=1.304, validation loss = 1.079, test loss=0.535, test mse = 52575.762, test mae = 53.666\n",
      "epoch=137, loss=1.302, validation loss = 1.077, test loss=0.534, test mse = 50867.895, test mae = 53.253\n",
      "epoch=138, loss=1.299, validation loss = 1.075, test loss=0.533, test mse = 49365.750, test mae = 52.854\n",
      "epoch=139, loss=1.297, validation loss = 1.073, test loss=0.532, test mse = 48040.980, test mae = 52.469\n",
      "epoch=140, loss=1.295, validation loss = 1.071, test loss=0.531, test mse = 46868.559, test mae = 52.096\n",
      "epoch=141, loss=1.293, validation loss = 1.069, test loss=0.530, test mse = 45827.512, test mae = 51.735\n",
      "epoch=142, loss=1.290, validation loss = 1.067, test loss=0.529, test mse = 44898.766, test mae = 51.384\n",
      "epoch=143, loss=1.288, validation loss = 1.065, test loss=0.528, test mse = 44067.957, test mae = 51.045\n",
      "epoch=144, loss=1.286, validation loss = 1.063, test loss=0.528, test mse = 43323.137, test mae = 50.715\n",
      "epoch=145, loss=1.284, validation loss = 1.061, test loss=0.527, test mse = 42653.465, test mae = 50.395\n",
      "epoch=146, loss=1.282, validation loss = 1.059, test loss=0.526, test mse = 42048.895, test mae = 50.084\n",
      "epoch=147, loss=1.280, validation loss = 1.057, test loss=0.525, test mse = 41501.227, test mae = 49.782\n",
      "epoch=148, loss=1.278, validation loss = 1.055, test loss=0.524, test mse = 41003.453, test mae = 49.488\n",
      "epoch=149, loss=1.276, validation loss = 1.053, test loss=0.523, test mse = 40548.723, test mae = 49.202\n",
      "epoch=150, loss=1.274, validation loss = 1.051, test loss=0.523, test mse = 40131.301, test mae = 48.923\n",
      "epoch=151, loss=1.272, validation loss = 1.049, test loss=0.522, test mse = 39746.469, test mae = 48.652\n",
      "epoch=152, loss=1.270, validation loss = 1.047, test loss=0.521, test mse = 39389.547, test mae = 48.387\n",
      "epoch=153, loss=1.268, validation loss = 1.045, test loss=0.520, test mse = 39057.625, test mae = 48.128\n",
      "epoch=154, loss=1.266, validation loss = 1.044, test loss=0.519, test mse = 38748.230, test mae = 47.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=155, loss=1.264, validation loss = 1.042, test loss=0.519, test mse = 38458.137, test mae = 47.627\n",
      "epoch=156, loss=1.262, validation loss = 1.040, test loss=0.518, test mse = 38184.855, test mae = 47.384\n",
      "epoch=157, loss=1.260, validation loss = 1.038, test loss=0.517, test mse = 37926.285, test mae = 47.145\n",
      "epoch=158, loss=1.258, validation loss = 1.036, test loss=0.516, test mse = 37680.457, test mae = 46.911\n",
      "epoch=159, loss=1.256, validation loss = 1.035, test loss=0.515, test mse = 37445.691, test mae = 46.681\n",
      "epoch=160, loss=1.254, validation loss = 1.033, test loss=0.515, test mse = 37220.363, test mae = 46.456\n",
      "epoch=161, loss=1.252, validation loss = 1.031, test loss=0.514, test mse = 37003.148, test mae = 46.237\n",
      "epoch=162, loss=1.251, validation loss = 1.029, test loss=0.513, test mse = 36792.848, test mae = 46.022\n",
      "epoch=163, loss=1.249, validation loss = 1.028, test loss=0.512, test mse = 36588.324, test mae = 45.812\n",
      "epoch=164, loss=1.247, validation loss = 1.026, test loss=0.512, test mse = 36388.434, test mae = 45.606\n",
      "epoch=165, loss=1.245, validation loss = 1.024, test loss=0.511, test mse = 36192.273, test mae = 45.404\n",
      "epoch=166, loss=1.243, validation loss = 1.022, test loss=0.510, test mse = 35998.902, test mae = 45.204\n",
      "epoch=167, loss=1.242, validation loss = 1.021, test loss=0.509, test mse = 35807.715, test mae = 45.008\n",
      "epoch=168, loss=1.240, validation loss = 1.019, test loss=0.509, test mse = 35618.203, test mae = 44.815\n",
      "epoch=169, loss=1.238, validation loss = 1.017, test loss=0.508, test mse = 35430.012, test mae = 44.624\n",
      "epoch=170, loss=1.236, validation loss = 1.016, test loss=0.507, test mse = 35242.387, test mae = 44.435\n",
      "epoch=171, loss=1.235, validation loss = 1.014, test loss=0.506, test mse = 35055.004, test mae = 44.249\n",
      "epoch=172, loss=1.233, validation loss = 1.012, test loss=0.506, test mse = 34863.359, test mae = 44.065\n",
      "epoch=173, loss=1.231, validation loss = 1.010, test loss=0.505, test mse = 34670.695, test mae = 43.884\n",
      "epoch=174, loss=1.229, validation loss = 1.009, test loss=0.504, test mse = 34478.363, test mae = 43.705\n",
      "epoch=175, loss=1.228, validation loss = 1.007, test loss=0.504, test mse = 34287.020, test mae = 43.527\n",
      "epoch=176, loss=1.226, validation loss = 1.006, test loss=0.503, test mse = 34097.500, test mae = 43.352\n",
      "epoch=177, loss=1.224, validation loss = 1.004, test loss=0.502, test mse = 33910.809, test mae = 43.178\n",
      "epoch=178, loss=1.223, validation loss = 1.002, test loss=0.501, test mse = 33728.207, test mae = 43.006\n",
      "epoch=179, loss=1.221, validation loss = 1.001, test loss=0.501, test mse = 33550.875, test mae = 42.836\n",
      "epoch=180, loss=1.219, validation loss = 0.999, test loss=0.500, test mse = 33379.926, test mae = 42.668\n",
      "epoch=181, loss=1.218, validation loss = 0.997, test loss=0.499, test mse = 33216.422, test mae = 42.502\n",
      "epoch=182, loss=1.216, validation loss = 0.996, test loss=0.499, test mse = 33061.277, test mae = 42.339\n",
      "epoch=183, loss=1.215, validation loss = 0.994, test loss=0.498, test mse = 32915.227, test mae = 42.178\n",
      "epoch=184, loss=1.213, validation loss = 0.993, test loss=0.497, test mse = 32778.566, test mae = 42.020\n",
      "epoch=185, loss=1.211, validation loss = 0.991, test loss=0.496, test mse = 32651.514, test mae = 41.864\n",
      "epoch=186, loss=1.210, validation loss = 0.990, test loss=0.496, test mse = 32534.010, test mae = 41.711\n",
      "epoch=187, loss=1.208, validation loss = 0.988, test loss=0.495, test mse = 32425.727, test mae = 41.560\n",
      "epoch=188, loss=1.207, validation loss = 0.986, test loss=0.494, test mse = 32326.197, test mae = 41.411\n",
      "epoch=189, loss=1.205, validation loss = 0.985, test loss=0.494, test mse = 32234.924, test mae = 41.265\n",
      "epoch=190, loss=1.204, validation loss = 0.983, test loss=0.493, test mse = 32151.314, test mae = 41.122\n",
      "epoch=191, loss=1.202, validation loss = 0.982, test loss=0.492, test mse = 32074.635, test mae = 40.980\n",
      "epoch=192, loss=1.201, validation loss = 0.980, test loss=0.492, test mse = 32003.891, test mae = 40.841\n",
      "epoch=193, loss=1.199, validation loss = 0.979, test loss=0.491, test mse = 31938.869, test mae = 40.705\n",
      "epoch=194, loss=1.197, validation loss = 0.977, test loss=0.491, test mse = 31878.955, test mae = 40.570\n",
      "epoch=195, loss=1.196, validation loss = 0.976, test loss=0.490, test mse = 31823.529, test mae = 40.438\n",
      "epoch=196, loss=1.194, validation loss = 0.974, test loss=0.489, test mse = 31772.047, test mae = 40.308\n",
      "epoch=197, loss=1.193, validation loss = 0.973, test loss=0.489, test mse = 31724.000, test mae = 40.179\n",
      "epoch=198, loss=1.191, validation loss = 0.971, test loss=0.488, test mse = 31678.842, test mae = 40.053\n",
      "epoch=199, loss=1.190, validation loss = 0.970, test loss=0.487, test mse = 31636.404, test mae = 39.928\n",
      "epoch=200, loss=1.189, validation loss = 0.968, test loss=0.487, test mse = 31596.404, test mae = 39.806\n",
      "epoch=201, loss=1.187, validation loss = 0.967, test loss=0.486, test mse = 31558.584, test mae = 39.686\n",
      "epoch=202, loss=1.186, validation loss = 0.965, test loss=0.486, test mse = 31522.697, test mae = 39.568\n",
      "epoch=203, loss=1.184, validation loss = 0.964, test loss=0.485, test mse = 31488.633, test mae = 39.452\n",
      "epoch=204, loss=1.183, validation loss = 0.962, test loss=0.484, test mse = 31456.092, test mae = 39.338\n",
      "epoch=205, loss=1.181, validation loss = 0.961, test loss=0.484, test mse = 31425.025, test mae = 39.225\n",
      "epoch=206, loss=1.180, validation loss = 0.960, test loss=0.483, test mse = 31395.275, test mae = 39.115\n",
      "epoch=207, loss=1.178, validation loss = 0.958, test loss=0.483, test mse = 31366.697, test mae = 39.006\n",
      "epoch=208, loss=1.177, validation loss = 0.957, test loss=0.482, test mse = 31339.195, test mae = 38.898\n",
      "epoch=209, loss=1.176, validation loss = 0.955, test loss=0.481, test mse = 31312.686, test mae = 38.793\n",
      "epoch=210, loss=1.174, validation loss = 0.954, test loss=0.481, test mse = 31287.109, test mae = 38.688\n",
      "epoch=211, loss=1.173, validation loss = 0.952, test loss=0.480, test mse = 31262.412, test mae = 38.586\n",
      "epoch=212, loss=1.171, validation loss = 0.951, test loss=0.480, test mse = 31238.500, test mae = 38.485\n",
      "epoch=213, loss=1.170, validation loss = 0.950, test loss=0.479, test mse = 31215.357, test mae = 38.385\n",
      "epoch=214, loss=1.169, validation loss = 0.948, test loss=0.479, test mse = 31192.953, test mae = 38.287\n",
      "epoch=215, loss=1.167, validation loss = 0.947, test loss=0.478, test mse = 31171.258, test mae = 38.190\n",
      "epoch=216, loss=1.166, validation loss = 0.946, test loss=0.478, test mse = 31150.232, test mae = 38.094\n",
      "epoch=217, loss=1.165, validation loss = 0.944, test loss=0.477, test mse = 31129.850, test mae = 38.000\n",
      "epoch=218, loss=1.163, validation loss = 0.943, test loss=0.476, test mse = 31110.068, test mae = 37.907\n",
      "epoch=219, loss=1.162, validation loss = 0.941, test loss=0.476, test mse = 31090.877, test mae = 37.815\n",
      "epoch=220, loss=1.161, validation loss = 0.940, test loss=0.475, test mse = 31072.236, test mae = 37.725\n",
      "epoch=221, loss=1.159, validation loss = 0.939, test loss=0.475, test mse = 31054.127, test mae = 37.636\n",
      "epoch=222, loss=1.158, validation loss = 0.937, test loss=0.474, test mse = 31036.516, test mae = 37.548\n",
      "epoch=223, loss=1.157, validation loss = 0.936, test loss=0.474, test mse = 31019.381, test mae = 37.462\n",
      "epoch=224, loss=1.155, validation loss = 0.935, test loss=0.473, test mse = 31002.717, test mae = 37.376\n",
      "epoch=225, loss=1.154, validation loss = 0.933, test loss=0.473, test mse = 30986.510, test mae = 37.292\n",
      "epoch=226, loss=1.153, validation loss = 0.932, test loss=0.472, test mse = 30970.734, test mae = 37.208\n",
      "epoch=227, loss=1.151, validation loss = 0.931, test loss=0.472, test mse = 30955.373, test mae = 37.126\n",
      "epoch=228, loss=1.150, validation loss = 0.929, test loss=0.471, test mse = 30940.412, test mae = 37.045\n",
      "epoch=229, loss=1.149, validation loss = 0.928, test loss=0.471, test mse = 30925.842, test mae = 36.965\n",
      "epoch=230, loss=1.147, validation loss = 0.927, test loss=0.470, test mse = 30911.656, test mae = 36.886\n",
      "epoch=231, loss=1.146, validation loss = 0.926, test loss=0.470, test mse = 30897.834, test mae = 36.807\n",
      "epoch=232, loss=1.145, validation loss = 0.924, test loss=0.469, test mse = 30884.365, test mae = 36.730\n",
      "epoch=233, loss=1.144, validation loss = 0.923, test loss=0.469, test mse = 30871.240, test mae = 36.653\n",
      "epoch=234, loss=1.142, validation loss = 0.922, test loss=0.468, test mse = 30858.445, test mae = 36.578\n",
      "epoch=235, loss=1.141, validation loss = 0.920, test loss=0.468, test mse = 30845.982, test mae = 36.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=236, loss=1.140, validation loss = 0.919, test loss=0.467, test mse = 30833.828, test mae = 36.429\n",
      "epoch=237, loss=1.139, validation loss = 0.918, test loss=0.467, test mse = 30821.967, test mae = 36.356\n",
      "epoch=238, loss=1.137, validation loss = 0.917, test loss=0.466, test mse = 30810.398, test mae = 36.284\n",
      "epoch=239, loss=1.136, validation loss = 0.915, test loss=0.466, test mse = 30799.096, test mae = 36.213\n",
      "epoch=240, loss=1.135, validation loss = 0.914, test loss=0.465, test mse = 30788.057, test mae = 36.143\n",
      "epoch=241, loss=1.134, validation loss = 0.913, test loss=0.465, test mse = 30777.283, test mae = 36.073\n",
      "epoch=242, loss=1.132, validation loss = 0.912, test loss=0.465, test mse = 30766.764, test mae = 36.004\n",
      "epoch=243, loss=1.131, validation loss = 0.910, test loss=0.464, test mse = 30756.490, test mae = 35.936\n",
      "epoch=244, loss=1.130, validation loss = 0.909, test loss=0.464, test mse = 30746.447, test mae = 35.869\n",
      "epoch=245, loss=1.129, validation loss = 0.908, test loss=0.463, test mse = 30736.631, test mae = 35.803\n",
      "epoch=246, loss=1.128, validation loss = 0.907, test loss=0.463, test mse = 30727.041, test mae = 35.737\n",
      "epoch=247, loss=1.126, validation loss = 0.905, test loss=0.462, test mse = 30717.662, test mae = 35.673\n",
      "epoch=248, loss=1.125, validation loss = 0.904, test loss=0.462, test mse = 30708.490, test mae = 35.609\n",
      "epoch=249, loss=1.124, validation loss = 0.903, test loss=0.461, test mse = 30699.523, test mae = 35.545\n",
      "epoch=250, loss=1.123, validation loss = 0.902, test loss=0.461, test mse = 30690.752, test mae = 35.483\n",
      "epoch=251, loss=1.122, validation loss = 0.901, test loss=0.461, test mse = 30682.178, test mae = 35.421\n",
      "epoch=252, loss=1.120, validation loss = 0.899, test loss=0.460, test mse = 30673.787, test mae = 35.360\n",
      "epoch=253, loss=1.119, validation loss = 0.898, test loss=0.460, test mse = 30665.572, test mae = 35.300\n",
      "epoch=254, loss=1.118, validation loss = 0.897, test loss=0.459, test mse = 30657.537, test mae = 35.241\n",
      "epoch=255, loss=1.117, validation loss = 0.896, test loss=0.459, test mse = 30649.672, test mae = 35.182\n",
      "epoch=256, loss=1.116, validation loss = 0.895, test loss=0.458, test mse = 30641.982, test mae = 35.124\n",
      "epoch=257, loss=1.115, validation loss = 0.894, test loss=0.458, test mse = 30634.453, test mae = 35.066\n",
      "epoch=258, loss=1.113, validation loss = 0.892, test loss=0.458, test mse = 30627.084, test mae = 35.010\n",
      "epoch=259, loss=1.112, validation loss = 0.891, test loss=0.457, test mse = 30619.865, test mae = 34.954\n",
      "epoch=260, loss=1.111, validation loss = 0.890, test loss=0.457, test mse = 30612.795, test mae = 34.899\n",
      "epoch=261, loss=1.110, validation loss = 0.889, test loss=0.456, test mse = 30605.865, test mae = 34.844\n",
      "epoch=262, loss=1.109, validation loss = 0.888, test loss=0.456, test mse = 30599.076, test mae = 34.790\n",
      "epoch=263, loss=1.108, validation loss = 0.887, test loss=0.455, test mse = 30592.428, test mae = 34.737\n",
      "epoch=264, loss=1.107, validation loss = 0.885, test loss=0.455, test mse = 30585.916, test mae = 34.684\n",
      "epoch=265, loss=1.105, validation loss = 0.884, test loss=0.455, test mse = 30579.525, test mae = 34.632\n",
      "epoch=266, loss=1.104, validation loss = 0.883, test loss=0.454, test mse = 30573.266, test mae = 34.581\n",
      "epoch=267, loss=1.103, validation loss = 0.882, test loss=0.454, test mse = 30567.135, test mae = 34.530\n",
      "epoch=268, loss=1.102, validation loss = 0.881, test loss=0.453, test mse = 30561.127, test mae = 34.480\n",
      "epoch=269, loss=1.101, validation loss = 0.880, test loss=0.453, test mse = 30555.242, test mae = 34.431\n",
      "epoch=270, loss=1.100, validation loss = 0.879, test loss=0.453, test mse = 30549.482, test mae = 34.382\n",
      "epoch=271, loss=1.099, validation loss = 0.878, test loss=0.452, test mse = 30543.838, test mae = 34.334\n",
      "epoch=272, loss=1.098, validation loss = 0.876, test loss=0.452, test mse = 30538.307, test mae = 34.286\n",
      "epoch=273, loss=1.097, validation loss = 0.875, test loss=0.451, test mse = 30532.891, test mae = 34.239\n",
      "epoch=274, loss=1.096, validation loss = 0.874, test loss=0.451, test mse = 30527.578, test mae = 34.193\n",
      "epoch=275, loss=1.094, validation loss = 0.873, test loss=0.451, test mse = 30522.375, test mae = 34.147\n",
      "epoch=276, loss=1.093, validation loss = 0.872, test loss=0.450, test mse = 30517.273, test mae = 34.101\n",
      "epoch=277, loss=1.092, validation loss = 0.871, test loss=0.450, test mse = 30512.273, test mae = 34.056\n",
      "epoch=278, loss=1.091, validation loss = 0.870, test loss=0.450, test mse = 30507.369, test mae = 34.011\n",
      "epoch=279, loss=1.090, validation loss = 0.869, test loss=0.449, test mse = 30502.561, test mae = 33.967\n",
      "epoch=280, loss=1.089, validation loss = 0.868, test loss=0.449, test mse = 30497.842, test mae = 33.924\n",
      "epoch=281, loss=1.088, validation loss = 0.867, test loss=0.448, test mse = 30493.217, test mae = 33.881\n",
      "epoch=282, loss=1.087, validation loss = 0.865, test loss=0.448, test mse = 30488.682, test mae = 33.838\n",
      "epoch=283, loss=1.086, validation loss = 0.864, test loss=0.448, test mse = 30484.232, test mae = 33.796\n",
      "epoch=284, loss=1.085, validation loss = 0.863, test loss=0.447, test mse = 30479.867, test mae = 33.754\n",
      "epoch=285, loss=1.084, validation loss = 0.862, test loss=0.447, test mse = 30475.588, test mae = 33.713\n",
      "epoch=286, loss=1.083, validation loss = 0.861, test loss=0.447, test mse = 30471.391, test mae = 33.673\n",
      "epoch=287, loss=1.082, validation loss = 0.860, test loss=0.446, test mse = 30467.271, test mae = 33.632\n",
      "epoch=288, loss=1.081, validation loss = 0.859, test loss=0.446, test mse = 30463.227, test mae = 33.593\n",
      "epoch=289, loss=1.079, validation loss = 0.858, test loss=0.446, test mse = 30459.252, test mae = 33.554\n",
      "epoch=290, loss=1.078, validation loss = 0.857, test loss=0.445, test mse = 30455.352, test mae = 33.515\n",
      "epoch=291, loss=1.077, validation loss = 0.856, test loss=0.445, test mse = 30451.521, test mae = 33.476\n",
      "epoch=292, loss=1.076, validation loss = 0.855, test loss=0.445, test mse = 30447.758, test mae = 33.438\n",
      "epoch=293, loss=1.075, validation loss = 0.854, test loss=0.444, test mse = 30444.057, test mae = 33.401\n",
      "epoch=294, loss=1.074, validation loss = 0.853, test loss=0.444, test mse = 30440.422, test mae = 33.364\n",
      "epoch=295, loss=1.073, validation loss = 0.852, test loss=0.443, test mse = 30436.857, test mae = 33.327\n",
      "epoch=296, loss=1.072, validation loss = 0.851, test loss=0.443, test mse = 30433.354, test mae = 33.291\n",
      "epoch=297, loss=1.071, validation loss = 0.850, test loss=0.443, test mse = 30429.908, test mae = 33.255\n",
      "epoch=298, loss=1.070, validation loss = 0.849, test loss=0.442, test mse = 30426.529, test mae = 33.219\n",
      "epoch=299, loss=1.069, validation loss = 0.848, test loss=0.442, test mse = 30423.197, test mae = 33.184\n",
      "epoch=300, loss=1.068, validation loss = 0.847, test loss=0.442, test mse = 30419.924, test mae = 33.150\n",
      "epoch=301, loss=1.067, validation loss = 0.846, test loss=0.441, test mse = 30416.709, test mae = 33.115\n",
      "epoch=302, loss=1.066, validation loss = 0.845, test loss=0.441, test mse = 30413.545, test mae = 33.081\n",
      "epoch=303, loss=1.065, validation loss = 0.844, test loss=0.441, test mse = 30410.430, test mae = 33.047\n",
      "epoch=304, loss=1.064, validation loss = 0.843, test loss=0.440, test mse = 30407.367, test mae = 33.014\n",
      "epoch=305, loss=1.063, validation loss = 0.842, test loss=0.440, test mse = 30404.354, test mae = 32.980\n",
      "epoch=306, loss=1.062, validation loss = 0.841, test loss=0.440, test mse = 30401.391, test mae = 32.947\n",
      "epoch=307, loss=1.061, validation loss = 0.840, test loss=0.439, test mse = 30398.467, test mae = 32.914\n",
      "epoch=308, loss=1.060, validation loss = 0.839, test loss=0.439, test mse = 30395.594, test mae = 32.882\n",
      "epoch=309, loss=1.059, validation loss = 0.838, test loss=0.439, test mse = 30392.766, test mae = 32.850\n",
      "epoch=310, loss=1.058, validation loss = 0.837, test loss=0.439, test mse = 30389.982, test mae = 32.818\n",
      "epoch=311, loss=1.057, validation loss = 0.836, test loss=0.438, test mse = 30387.242, test mae = 32.786\n",
      "epoch=312, loss=1.056, validation loss = 0.835, test loss=0.438, test mse = 30384.541, test mae = 32.755\n",
      "epoch=313, loss=1.055, validation loss = 0.834, test loss=0.438, test mse = 30381.885, test mae = 32.723\n",
      "epoch=314, loss=1.054, validation loss = 0.833, test loss=0.437, test mse = 30379.275, test mae = 32.693\n",
      "epoch=315, loss=1.053, validation loss = 0.832, test loss=0.437, test mse = 30376.701, test mae = 32.662\n",
      "epoch=316, loss=1.052, validation loss = 0.831, test loss=0.437, test mse = 30374.170, test mae = 32.631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=317, loss=1.051, validation loss = 0.830, test loss=0.436, test mse = 30371.674, test mae = 32.601\n",
      "epoch=318, loss=1.050, validation loss = 0.829, test loss=0.436, test mse = 30369.219, test mae = 32.571\n",
      "epoch=319, loss=1.049, validation loss = 0.828, test loss=0.436, test mse = 30366.803, test mae = 32.542\n",
      "epoch=320, loss=1.048, validation loss = 0.827, test loss=0.435, test mse = 30364.420, test mae = 32.513\n",
      "epoch=321, loss=1.047, validation loss = 0.826, test loss=0.435, test mse = 30362.078, test mae = 32.483\n",
      "epoch=322, loss=1.047, validation loss = 0.825, test loss=0.435, test mse = 30359.768, test mae = 32.455\n",
      "epoch=323, loss=1.046, validation loss = 0.824, test loss=0.434, test mse = 30357.494, test mae = 32.426\n",
      "epoch=324, loss=1.045, validation loss = 0.823, test loss=0.434, test mse = 30355.256, test mae = 32.398\n",
      "epoch=325, loss=1.044, validation loss = 0.822, test loss=0.434, test mse = 30353.053, test mae = 32.369\n",
      "epoch=326, loss=1.043, validation loss = 0.821, test loss=0.434, test mse = 30350.881, test mae = 32.342\n",
      "epoch=327, loss=1.042, validation loss = 0.820, test loss=0.433, test mse = 30348.740, test mae = 32.314\n",
      "epoch=328, loss=1.041, validation loss = 0.819, test loss=0.433, test mse = 30346.635, test mae = 32.286\n",
      "epoch=329, loss=1.040, validation loss = 0.818, test loss=0.433, test mse = 30344.562, test mae = 32.259\n",
      "epoch=330, loss=1.039, validation loss = 0.817, test loss=0.432, test mse = 30342.516, test mae = 32.232\n",
      "epoch=331, loss=1.038, validation loss = 0.816, test loss=0.432, test mse = 30340.502, test mae = 32.205\n",
      "epoch=332, loss=1.037, validation loss = 0.815, test loss=0.432, test mse = 30338.521, test mae = 32.178\n",
      "epoch=333, loss=1.036, validation loss = 0.814, test loss=0.431, test mse = 30336.562, test mae = 32.152\n",
      "epoch=334, loss=1.035, validation loss = 0.813, test loss=0.431, test mse = 30334.639, test mae = 32.125\n",
      "epoch=335, loss=1.034, validation loss = 0.813, test loss=0.431, test mse = 30332.740, test mae = 32.099\n",
      "epoch=336, loss=1.033, validation loss = 0.812, test loss=0.431, test mse = 30330.869, test mae = 32.073\n",
      "epoch=337, loss=1.032, validation loss = 0.811, test loss=0.430, test mse = 30329.029, test mae = 32.048\n",
      "epoch=338, loss=1.032, validation loss = 0.810, test loss=0.430, test mse = 30327.209, test mae = 32.022\n",
      "epoch=339, loss=1.031, validation loss = 0.809, test loss=0.430, test mse = 30325.416, test mae = 31.997\n",
      "epoch=340, loss=1.030, validation loss = 0.808, test loss=0.429, test mse = 30323.654, test mae = 31.971\n",
      "epoch=341, loss=1.029, validation loss = 0.807, test loss=0.429, test mse = 30321.914, test mae = 31.946\n",
      "epoch=342, loss=1.028, validation loss = 0.806, test loss=0.429, test mse = 30320.201, test mae = 31.922\n",
      "epoch=343, loss=1.027, validation loss = 0.805, test loss=0.429, test mse = 30318.518, test mae = 31.897\n",
      "epoch=344, loss=1.026, validation loss = 0.804, test loss=0.428, test mse = 30316.857, test mae = 31.873\n",
      "epoch=345, loss=1.025, validation loss = 0.803, test loss=0.428, test mse = 30315.219, test mae = 31.849\n",
      "epoch=346, loss=1.024, validation loss = 0.803, test loss=0.428, test mse = 30313.604, test mae = 31.825\n",
      "epoch=347, loss=1.023, validation loss = 0.802, test loss=0.427, test mse = 30312.018, test mae = 31.801\n",
      "epoch=348, loss=1.023, validation loss = 0.801, test loss=0.427, test mse = 30310.453, test mae = 31.777\n",
      "epoch=349, loss=1.022, validation loss = 0.800, test loss=0.427, test mse = 30308.912, test mae = 31.754\n",
      "epoch=350, loss=1.021, validation loss = 0.799, test loss=0.427, test mse = 30307.391, test mae = 31.730\n",
      "epoch=351, loss=1.020, validation loss = 0.798, test loss=0.426, test mse = 30305.893, test mae = 31.707\n",
      "epoch=352, loss=1.019, validation loss = 0.797, test loss=0.426, test mse = 30304.420, test mae = 31.684\n",
      "epoch=353, loss=1.018, validation loss = 0.796, test loss=0.426, test mse = 30302.969, test mae = 31.661\n",
      "epoch=354, loss=1.017, validation loss = 0.795, test loss=0.426, test mse = 30301.539, test mae = 31.639\n",
      "epoch=355, loss=1.016, validation loss = 0.795, test loss=0.425, test mse = 30300.131, test mae = 31.616\n",
      "epoch=356, loss=1.015, validation loss = 0.794, test loss=0.425, test mse = 30298.744, test mae = 31.594\n",
      "epoch=357, loss=1.015, validation loss = 0.793, test loss=0.425, test mse = 30297.381, test mae = 31.572\n",
      "epoch=358, loss=1.014, validation loss = 0.792, test loss=0.424, test mse = 30296.031, test mae = 31.550\n",
      "epoch=359, loss=1.013, validation loss = 0.791, test loss=0.424, test mse = 30294.711, test mae = 31.528\n",
      "epoch=360, loss=1.012, validation loss = 0.790, test loss=0.424, test mse = 30293.406, test mae = 31.507\n",
      "epoch=361, loss=1.011, validation loss = 0.789, test loss=0.424, test mse = 30292.123, test mae = 31.486\n",
      "epoch=362, loss=1.010, validation loss = 0.788, test loss=0.423, test mse = 30290.859, test mae = 31.465\n",
      "epoch=363, loss=1.009, validation loss = 0.788, test loss=0.423, test mse = 30289.611, test mae = 31.444\n",
      "epoch=364, loss=1.008, validation loss = 0.787, test loss=0.423, test mse = 30288.389, test mae = 31.423\n",
      "epoch=365, loss=1.008, validation loss = 0.786, test loss=0.423, test mse = 30287.180, test mae = 31.403\n",
      "epoch=366, loss=1.007, validation loss = 0.785, test loss=0.422, test mse = 30285.990, test mae = 31.382\n",
      "epoch=367, loss=1.006, validation loss = 0.784, test loss=0.422, test mse = 30284.818, test mae = 31.362\n",
      "epoch=368, loss=1.005, validation loss = 0.783, test loss=0.422, test mse = 30283.666, test mae = 31.342\n",
      "epoch=369, loss=1.004, validation loss = 0.783, test loss=0.422, test mse = 30282.533, test mae = 31.323\n",
      "epoch=370, loss=1.003, validation loss = 0.782, test loss=0.421, test mse = 30281.420, test mae = 31.303\n",
      "epoch=371, loss=1.003, validation loss = 0.781, test loss=0.421, test mse = 30280.320, test mae = 31.284\n",
      "epoch=372, loss=1.002, validation loss = 0.780, test loss=0.421, test mse = 30279.240, test mae = 31.265\n",
      "epoch=373, loss=1.001, validation loss = 0.779, test loss=0.421, test mse = 30278.178, test mae = 31.246\n",
      "epoch=374, loss=1.000, validation loss = 0.778, test loss=0.420, test mse = 30277.127, test mae = 31.227\n",
      "epoch=375, loss=0.999, validation loss = 0.777, test loss=0.420, test mse = 30276.100, test mae = 31.208\n",
      "epoch=376, loss=0.998, validation loss = 0.777, test loss=0.420, test mse = 30275.084, test mae = 31.190\n",
      "epoch=377, loss=0.997, validation loss = 0.776, test loss=0.420, test mse = 30274.088, test mae = 31.172\n",
      "epoch=378, loss=0.997, validation loss = 0.775, test loss=0.419, test mse = 30273.107, test mae = 31.154\n",
      "epoch=379, loss=0.996, validation loss = 0.774, test loss=0.419, test mse = 30272.143, test mae = 31.136\n",
      "epoch=380, loss=0.995, validation loss = 0.773, test loss=0.419, test mse = 30271.193, test mae = 31.118\n",
      "epoch=381, loss=0.994, validation loss = 0.773, test loss=0.419, test mse = 30270.260, test mae = 31.101\n",
      "epoch=382, loss=0.993, validation loss = 0.772, test loss=0.418, test mse = 30269.342, test mae = 31.083\n",
      "epoch=383, loss=0.992, validation loss = 0.771, test loss=0.418, test mse = 30268.443, test mae = 31.066\n",
      "epoch=384, loss=0.992, validation loss = 0.770, test loss=0.418, test mse = 30267.561, test mae = 31.049\n",
      "epoch=385, loss=0.991, validation loss = 0.769, test loss=0.418, test mse = 30266.688, test mae = 31.033\n",
      "epoch=386, loss=0.990, validation loss = 0.769, test loss=0.417, test mse = 30265.834, test mae = 31.016\n",
      "epoch=387, loss=0.989, validation loss = 0.768, test loss=0.417, test mse = 30264.994, test mae = 31.000\n",
      "epoch=388, loss=0.988, validation loss = 0.767, test loss=0.417, test mse = 30264.170, test mae = 30.983\n",
      "epoch=389, loss=0.988, validation loss = 0.766, test loss=0.417, test mse = 30263.361, test mae = 30.967\n",
      "epoch=390, loss=0.987, validation loss = 0.765, test loss=0.417, test mse = 30262.568, test mae = 30.952\n",
      "epoch=391, loss=0.986, validation loss = 0.765, test loss=0.416, test mse = 30261.791, test mae = 30.936\n",
      "epoch=392, loss=0.985, validation loss = 0.764, test loss=0.416, test mse = 30261.029, test mae = 30.920\n",
      "epoch=393, loss=0.984, validation loss = 0.763, test loss=0.416, test mse = 30260.279, test mae = 30.905\n",
      "epoch=394, loss=0.984, validation loss = 0.762, test loss=0.416, test mse = 30259.541, test mae = 30.890\n",
      "epoch=395, loss=0.983, validation loss = 0.761, test loss=0.415, test mse = 30258.820, test mae = 30.875\n",
      "epoch=396, loss=0.982, validation loss = 0.761, test loss=0.415, test mse = 30258.117, test mae = 30.860\n",
      "epoch=397, loss=0.981, validation loss = 0.760, test loss=0.415, test mse = 30257.424, test mae = 30.846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=398, loss=0.980, validation loss = 0.759, test loss=0.415, test mse = 30256.740, test mae = 30.831\n",
      "epoch=399, loss=0.980, validation loss = 0.758, test loss=0.415, test mse = 30256.076, test mae = 30.817\n",
      "epoch=400, loss=0.979, validation loss = 0.757, test loss=0.414, test mse = 30255.420, test mae = 30.803\n",
      "epoch=401, loss=0.978, validation loss = 0.757, test loss=0.414, test mse = 30254.775, test mae = 30.789\n",
      "epoch=402, loss=0.977, validation loss = 0.756, test loss=0.414, test mse = 30254.141, test mae = 30.775\n",
      "epoch=403, loss=0.976, validation loss = 0.755, test loss=0.414, test mse = 30253.523, test mae = 30.762\n",
      "epoch=404, loss=0.976, validation loss = 0.754, test loss=0.414, test mse = 30252.906, test mae = 30.748\n",
      "epoch=405, loss=0.975, validation loss = 0.754, test loss=0.413, test mse = 30252.307, test mae = 30.735\n",
      "epoch=406, loss=0.974, validation loss = 0.753, test loss=0.413, test mse = 30251.713, test mae = 30.722\n",
      "epoch=407, loss=0.973, validation loss = 0.752, test loss=0.413, test mse = 30251.131, test mae = 30.709\n",
      "epoch=408, loss=0.972, validation loss = 0.751, test loss=0.413, test mse = 30250.557, test mae = 30.696\n",
      "epoch=409, loss=0.972, validation loss = 0.751, test loss=0.413, test mse = 30249.992, test mae = 30.683\n",
      "epoch=410, loss=0.971, validation loss = 0.750, test loss=0.412, test mse = 30249.432, test mae = 30.670\n",
      "epoch=411, loss=0.970, validation loss = 0.749, test loss=0.412, test mse = 30248.885, test mae = 30.657\n",
      "epoch=412, loss=0.969, validation loss = 0.748, test loss=0.412, test mse = 30248.338, test mae = 30.645\n",
      "epoch=413, loss=0.969, validation loss = 0.748, test loss=0.412, test mse = 30247.807, test mae = 30.632\n",
      "epoch=414, loss=0.968, validation loss = 0.747, test loss=0.412, test mse = 30247.281, test mae = 30.620\n",
      "epoch=415, loss=0.967, validation loss = 0.746, test loss=0.411, test mse = 30246.760, test mae = 30.608\n",
      "epoch=416, loss=0.966, validation loss = 0.745, test loss=0.411, test mse = 30246.250, test mae = 30.596\n",
      "epoch=417, loss=0.965, validation loss = 0.745, test loss=0.411, test mse = 30245.748, test mae = 30.584\n",
      "epoch=418, loss=0.965, validation loss = 0.744, test loss=0.411, test mse = 30245.250, test mae = 30.572\n",
      "epoch=419, loss=0.964, validation loss = 0.743, test loss=0.411, test mse = 30244.760, test mae = 30.560\n",
      "epoch=420, loss=0.963, validation loss = 0.742, test loss=0.411, test mse = 30244.275, test mae = 30.548\n",
      "epoch=421, loss=0.962, validation loss = 0.742, test loss=0.410, test mse = 30243.803, test mae = 30.536\n",
      "epoch=422, loss=0.962, validation loss = 0.741, test loss=0.410, test mse = 30243.330, test mae = 30.525\n",
      "epoch=423, loss=0.961, validation loss = 0.740, test loss=0.410, test mse = 30242.867, test mae = 30.513\n",
      "epoch=424, loss=0.960, validation loss = 0.740, test loss=0.410, test mse = 30242.408, test mae = 30.502\n",
      "epoch=425, loss=0.959, validation loss = 0.739, test loss=0.410, test mse = 30241.959, test mae = 30.491\n",
      "epoch=426, loss=0.959, validation loss = 0.738, test loss=0.409, test mse = 30241.514, test mae = 30.479\n",
      "epoch=427, loss=0.958, validation loss = 0.737, test loss=0.409, test mse = 30241.072, test mae = 30.468\n",
      "epoch=428, loss=0.957, validation loss = 0.737, test loss=0.409, test mse = 30240.641, test mae = 30.457\n",
      "epoch=429, loss=0.956, validation loss = 0.736, test loss=0.409, test mse = 30240.211, test mae = 30.446\n",
      "epoch=430, loss=0.956, validation loss = 0.735, test loss=0.409, test mse = 30239.791, test mae = 30.435\n",
      "epoch=431, loss=0.955, validation loss = 0.734, test loss=0.409, test mse = 30239.373, test mae = 30.424\n",
      "epoch=432, loss=0.954, validation loss = 0.734, test loss=0.408, test mse = 30238.961, test mae = 30.413\n",
      "epoch=433, loss=0.953, validation loss = 0.733, test loss=0.408, test mse = 30238.555, test mae = 30.403\n",
      "epoch=434, loss=0.953, validation loss = 0.732, test loss=0.408, test mse = 30238.156, test mae = 30.392\n",
      "epoch=435, loss=0.952, validation loss = 0.732, test loss=0.408, test mse = 30237.760, test mae = 30.381\n",
      "epoch=436, loss=0.951, validation loss = 0.731, test loss=0.408, test mse = 30237.367, test mae = 30.371\n",
      "epoch=437, loss=0.950, validation loss = 0.730, test loss=0.408, test mse = 30236.979, test mae = 30.361\n",
      "epoch=438, loss=0.950, validation loss = 0.729, test loss=0.407, test mse = 30236.600, test mae = 30.350\n",
      "epoch=439, loss=0.949, validation loss = 0.729, test loss=0.407, test mse = 30236.227, test mae = 30.340\n",
      "epoch=440, loss=0.948, validation loss = 0.728, test loss=0.407, test mse = 30235.854, test mae = 30.330\n",
      "epoch=441, loss=0.947, validation loss = 0.727, test loss=0.407, test mse = 30235.486, test mae = 30.320\n",
      "epoch=442, loss=0.947, validation loss = 0.727, test loss=0.407, test mse = 30235.125, test mae = 30.309\n",
      "epoch=443, loss=0.946, validation loss = 0.726, test loss=0.407, test mse = 30234.771, test mae = 30.300\n",
      "epoch=444, loss=0.945, validation loss = 0.725, test loss=0.406, test mse = 30234.422, test mae = 30.290\n",
      "epoch=445, loss=0.944, validation loss = 0.725, test loss=0.406, test mse = 30234.072, test mae = 30.280\n",
      "epoch=446, loss=0.944, validation loss = 0.724, test loss=0.406, test mse = 30233.729, test mae = 30.270\n",
      "epoch=447, loss=0.943, validation loss = 0.723, test loss=0.406, test mse = 30233.389, test mae = 30.260\n",
      "epoch=448, loss=0.942, validation loss = 0.722, test loss=0.406, test mse = 30233.053, test mae = 30.251\n",
      "epoch=449, loss=0.941, validation loss = 0.722, test loss=0.406, test mse = 30232.721, test mae = 30.241\n",
      "epoch=450, loss=0.941, validation loss = 0.721, test loss=0.405, test mse = 30232.396, test mae = 30.232\n",
      "epoch=451, loss=0.940, validation loss = 0.720, test loss=0.405, test mse = 30232.070, test mae = 30.222\n",
      "epoch=452, loss=0.939, validation loss = 0.720, test loss=0.405, test mse = 30231.752, test mae = 30.213\n",
      "epoch=453, loss=0.939, validation loss = 0.719, test loss=0.405, test mse = 30231.438, test mae = 30.203\n",
      "epoch=454, loss=0.938, validation loss = 0.718, test loss=0.405, test mse = 30231.125, test mae = 30.194\n",
      "epoch=455, loss=0.937, validation loss = 0.718, test loss=0.405, test mse = 30230.814, test mae = 30.185\n",
      "epoch=456, loss=0.936, validation loss = 0.717, test loss=0.405, test mse = 30230.518, test mae = 30.176\n",
      "epoch=457, loss=0.936, validation loss = 0.716, test loss=0.404, test mse = 30230.217, test mae = 30.167\n",
      "epoch=458, loss=0.935, validation loss = 0.716, test loss=0.404, test mse = 30229.920, test mae = 30.158\n",
      "epoch=459, loss=0.934, validation loss = 0.715, test loss=0.404, test mse = 30229.627, test mae = 30.149\n",
      "epoch=460, loss=0.933, validation loss = 0.714, test loss=0.404, test mse = 30229.342, test mae = 30.140\n",
      "epoch=461, loss=0.933, validation loss = 0.714, test loss=0.404, test mse = 30229.057, test mae = 30.131\n",
      "epoch=462, loss=0.932, validation loss = 0.713, test loss=0.404, test mse = 30228.775, test mae = 30.122\n",
      "epoch=463, loss=0.931, validation loss = 0.712, test loss=0.403, test mse = 30228.494, test mae = 30.113\n",
      "epoch=464, loss=0.931, validation loss = 0.712, test loss=0.403, test mse = 30228.225, test mae = 30.104\n",
      "epoch=465, loss=0.930, validation loss = 0.711, test loss=0.403, test mse = 30227.951, test mae = 30.096\n",
      "epoch=466, loss=0.929, validation loss = 0.710, test loss=0.403, test mse = 30227.686, test mae = 30.087\n",
      "epoch=467, loss=0.928, validation loss = 0.710, test loss=0.403, test mse = 30227.420, test mae = 30.079\n",
      "epoch=468, loss=0.928, validation loss = 0.709, test loss=0.403, test mse = 30227.164, test mae = 30.070\n",
      "epoch=469, loss=0.927, validation loss = 0.708, test loss=0.403, test mse = 30226.904, test mae = 30.062\n",
      "epoch=470, loss=0.926, validation loss = 0.708, test loss=0.402, test mse = 30226.648, test mae = 30.053\n",
      "epoch=471, loss=0.926, validation loss = 0.707, test loss=0.402, test mse = 30226.398, test mae = 30.045\n",
      "epoch=472, loss=0.925, validation loss = 0.706, test loss=0.402, test mse = 30226.150, test mae = 30.036\n",
      "epoch=473, loss=0.924, validation loss = 0.706, test loss=0.402, test mse = 30225.906, test mae = 30.028\n",
      "epoch=474, loss=0.924, validation loss = 0.705, test loss=0.402, test mse = 30225.662, test mae = 30.020\n",
      "epoch=475, loss=0.923, validation loss = 0.704, test loss=0.402, test mse = 30225.428, test mae = 30.012\n",
      "epoch=476, loss=0.922, validation loss = 0.704, test loss=0.402, test mse = 30225.188, test mae = 30.004\n",
      "epoch=477, loss=0.921, validation loss = 0.703, test loss=0.401, test mse = 30224.955, test mae = 29.996\n",
      "epoch=478, loss=0.921, validation loss = 0.702, test loss=0.401, test mse = 30224.727, test mae = 29.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=479, loss=0.920, validation loss = 0.702, test loss=0.401, test mse = 30224.498, test mae = 29.980\n",
      "epoch=480, loss=0.919, validation loss = 0.701, test loss=0.401, test mse = 30224.273, test mae = 29.972\n",
      "epoch=481, loss=0.919, validation loss = 0.700, test loss=0.401, test mse = 30224.053, test mae = 29.964\n",
      "epoch=482, loss=0.918, validation loss = 0.700, test loss=0.401, test mse = 30223.834, test mae = 29.956\n",
      "epoch=483, loss=0.917, validation loss = 0.699, test loss=0.401, test mse = 30223.615, test mae = 29.948\n",
      "epoch=484, loss=0.917, validation loss = 0.698, test loss=0.400, test mse = 30223.398, test mae = 29.940\n",
      "epoch=485, loss=0.916, validation loss = 0.698, test loss=0.400, test mse = 30223.188, test mae = 29.932\n",
      "epoch=486, loss=0.915, validation loss = 0.697, test loss=0.400, test mse = 30222.979, test mae = 29.925\n",
      "epoch=487, loss=0.914, validation loss = 0.696, test loss=0.400, test mse = 30222.773, test mae = 29.917\n",
      "epoch=488, loss=0.914, validation loss = 0.696, test loss=0.400, test mse = 30222.568, test mae = 29.909\n",
      "epoch=489, loss=0.913, validation loss = 0.695, test loss=0.400, test mse = 30222.365, test mae = 29.901\n",
      "epoch=490, loss=0.912, validation loss = 0.694, test loss=0.400, test mse = 30222.166, test mae = 29.894\n",
      "epoch=491, loss=0.912, validation loss = 0.694, test loss=0.399, test mse = 30221.969, test mae = 29.886\n",
      "epoch=492, loss=0.911, validation loss = 0.693, test loss=0.399, test mse = 30221.775, test mae = 29.878\n",
      "epoch=493, loss=0.910, validation loss = 0.693, test loss=0.399, test mse = 30221.580, test mae = 29.871\n",
      "epoch=494, loss=0.910, validation loss = 0.692, test loss=0.399, test mse = 30221.393, test mae = 29.863\n",
      "epoch=495, loss=0.909, validation loss = 0.691, test loss=0.399, test mse = 30221.205, test mae = 29.856\n",
      "epoch=496, loss=0.908, validation loss = 0.691, test loss=0.399, test mse = 30221.021, test mae = 29.848\n",
      "epoch=497, loss=0.908, validation loss = 0.690, test loss=0.399, test mse = 30220.838, test mae = 29.841\n",
      "epoch=498, loss=0.907, validation loss = 0.689, test loss=0.398, test mse = 30220.656, test mae = 29.834\n",
      "epoch=499, loss=0.906, validation loss = 0.689, test loss=0.398, test mse = 30220.477, test mae = 29.826\n",
      "epoch=500, loss=0.906, validation loss = 0.688, test loss=0.398, test mse = 30220.303, test mae = 29.819\n",
      "epoch=501, loss=0.905, validation loss = 0.687, test loss=0.398, test mse = 30220.127, test mae = 29.812\n",
      "epoch=502, loss=0.904, validation loss = 0.687, test loss=0.398, test mse = 30219.959, test mae = 29.804\n",
      "epoch=503, loss=0.904, validation loss = 0.686, test loss=0.398, test mse = 30219.789, test mae = 29.797\n",
      "epoch=504, loss=0.903, validation loss = 0.686, test loss=0.398, test mse = 30219.619, test mae = 29.790\n",
      "epoch=505, loss=0.902, validation loss = 0.685, test loss=0.398, test mse = 30219.455, test mae = 29.783\n",
      "epoch=506, loss=0.901, validation loss = 0.684, test loss=0.397, test mse = 30219.291, test mae = 29.776\n",
      "epoch=507, loss=0.901, validation loss = 0.684, test loss=0.397, test mse = 30219.133, test mae = 29.769\n",
      "epoch=508, loss=0.900, validation loss = 0.683, test loss=0.397, test mse = 30218.975, test mae = 29.762\n",
      "epoch=509, loss=0.899, validation loss = 0.682, test loss=0.397, test mse = 30218.812, test mae = 29.754\n",
      "epoch=510, loss=0.899, validation loss = 0.682, test loss=0.397, test mse = 30218.658, test mae = 29.747\n",
      "epoch=511, loss=0.898, validation loss = 0.681, test loss=0.397, test mse = 30218.502, test mae = 29.740\n",
      "epoch=512, loss=0.897, validation loss = 0.681, test loss=0.397, test mse = 30218.352, test mae = 29.733\n",
      "epoch=513, loss=0.897, validation loss = 0.680, test loss=0.396, test mse = 30218.201, test mae = 29.727\n",
      "epoch=514, loss=0.896, validation loss = 0.679, test loss=0.396, test mse = 30218.053, test mae = 29.720\n",
      "epoch=515, loss=0.895, validation loss = 0.679, test loss=0.396, test mse = 30217.906, test mae = 29.713\n",
      "epoch=516, loss=0.895, validation loss = 0.678, test loss=0.396, test mse = 30217.764, test mae = 29.706\n",
      "epoch=517, loss=0.894, validation loss = 0.677, test loss=0.396, test mse = 30217.617, test mae = 29.699\n",
      "epoch=518, loss=0.893, validation loss = 0.677, test loss=0.396, test mse = 30217.477, test mae = 29.692\n",
      "epoch=519, loss=0.893, validation loss = 0.676, test loss=0.396, test mse = 30217.336, test mae = 29.685\n",
      "epoch=520, loss=0.892, validation loss = 0.676, test loss=0.396, test mse = 30217.201, test mae = 29.679\n",
      "epoch=521, loss=0.891, validation loss = 0.675, test loss=0.395, test mse = 30217.064, test mae = 29.672\n",
      "epoch=522, loss=0.891, validation loss = 0.674, test loss=0.395, test mse = 30216.928, test mae = 29.665\n",
      "epoch=523, loss=0.890, validation loss = 0.674, test loss=0.395, test mse = 30216.797, test mae = 29.659\n",
      "epoch=524, loss=0.889, validation loss = 0.673, test loss=0.395, test mse = 30216.664, test mae = 29.652\n",
      "epoch=525, loss=0.889, validation loss = 0.673, test loss=0.395, test mse = 30216.533, test mae = 29.645\n",
      "epoch=526, loss=0.888, validation loss = 0.672, test loss=0.395, test mse = 30216.406, test mae = 29.639\n",
      "epoch=527, loss=0.888, validation loss = 0.671, test loss=0.395, test mse = 30216.281, test mae = 29.632\n",
      "epoch=528, loss=0.887, validation loss = 0.671, test loss=0.395, test mse = 30216.156, test mae = 29.626\n",
      "epoch=529, loss=0.886, validation loss = 0.670, test loss=0.394, test mse = 30216.033, test mae = 29.619\n",
      "epoch=530, loss=0.886, validation loss = 0.669, test loss=0.394, test mse = 30215.912, test mae = 29.613\n",
      "epoch=531, loss=0.885, validation loss = 0.669, test loss=0.394, test mse = 30215.789, test mae = 29.607\n",
      "epoch=532, loss=0.884, validation loss = 0.668, test loss=0.394, test mse = 30215.670, test mae = 29.600\n",
      "epoch=533, loss=0.884, validation loss = 0.668, test loss=0.394, test mse = 30215.555, test mae = 29.594\n",
      "epoch=534, loss=0.883, validation loss = 0.667, test loss=0.394, test mse = 30215.438, test mae = 29.587\n",
      "epoch=535, loss=0.882, validation loss = 0.666, test loss=0.394, test mse = 30215.326, test mae = 29.581\n",
      "epoch=536, loss=0.882, validation loss = 0.666, test loss=0.394, test mse = 30215.209, test mae = 29.575\n",
      "epoch=537, loss=0.881, validation loss = 0.665, test loss=0.394, test mse = 30215.100, test mae = 29.569\n",
      "epoch=538, loss=0.880, validation loss = 0.665, test loss=0.393, test mse = 30214.986, test mae = 29.562\n",
      "epoch=539, loss=0.880, validation loss = 0.664, test loss=0.393, test mse = 30214.877, test mae = 29.556\n",
      "epoch=540, loss=0.879, validation loss = 0.663, test loss=0.393, test mse = 30214.771, test mae = 29.550\n",
      "epoch=541, loss=0.878, validation loss = 0.663, test loss=0.393, test mse = 30214.662, test mae = 29.544\n",
      "epoch=542, loss=0.878, validation loss = 0.662, test loss=0.393, test mse = 30214.557, test mae = 29.538\n",
      "epoch=543, loss=0.877, validation loss = 0.662, test loss=0.393, test mse = 30214.451, test mae = 29.532\n",
      "epoch=544, loss=0.876, validation loss = 0.661, test loss=0.393, test mse = 30214.350, test mae = 29.526\n",
      "epoch=545, loss=0.876, validation loss = 0.660, test loss=0.393, test mse = 30214.248, test mae = 29.519\n",
      "epoch=546, loss=0.875, validation loss = 0.660, test loss=0.392, test mse = 30214.146, test mae = 29.513\n",
      "epoch=547, loss=0.875, validation loss = 0.659, test loss=0.392, test mse = 30214.045, test mae = 29.507\n",
      "epoch=548, loss=0.874, validation loss = 0.659, test loss=0.392, test mse = 30213.945, test mae = 29.501\n",
      "epoch=549, loss=0.873, validation loss = 0.658, test loss=0.392, test mse = 30213.850, test mae = 29.495\n",
      "epoch=550, loss=0.873, validation loss = 0.658, test loss=0.392, test mse = 30213.752, test mae = 29.489\n",
      "epoch=551, loss=0.872, validation loss = 0.657, test loss=0.392, test mse = 30213.658, test mae = 29.484\n",
      "epoch=552, loss=0.871, validation loss = 0.656, test loss=0.392, test mse = 30213.564, test mae = 29.478\n",
      "epoch=553, loss=0.871, validation loss = 0.656, test loss=0.392, test mse = 30213.475, test mae = 29.472\n",
      "epoch=554, loss=0.870, validation loss = 0.655, test loss=0.392, test mse = 30213.381, test mae = 29.466\n",
      "epoch=555, loss=0.869, validation loss = 0.655, test loss=0.391, test mse = 30213.295, test mae = 29.460\n",
      "epoch=556, loss=0.869, validation loss = 0.654, test loss=0.391, test mse = 30213.205, test mae = 29.454\n",
      "epoch=557, loss=0.868, validation loss = 0.653, test loss=0.391, test mse = 30213.115, test mae = 29.448\n",
      "epoch=558, loss=0.867, validation loss = 0.653, test loss=0.391, test mse = 30213.029, test mae = 29.443\n",
      "epoch=559, loss=0.867, validation loss = 0.652, test loss=0.391, test mse = 30212.943, test mae = 29.437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=560, loss=0.866, validation loss = 0.652, test loss=0.391, test mse = 30212.859, test mae = 29.431\n",
      "epoch=561, loss=0.866, validation loss = 0.651, test loss=0.391, test mse = 30212.775, test mae = 29.425\n",
      "epoch=562, loss=0.865, validation loss = 0.651, test loss=0.391, test mse = 30212.693, test mae = 29.420\n",
      "epoch=563, loss=0.864, validation loss = 0.650, test loss=0.391, test mse = 30212.611, test mae = 29.414\n",
      "epoch=564, loss=0.864, validation loss = 0.649, test loss=0.390, test mse = 30212.533, test mae = 29.408\n",
      "epoch=565, loss=0.863, validation loss = 0.649, test loss=0.390, test mse = 30212.453, test mae = 29.403\n",
      "epoch=566, loss=0.862, validation loss = 0.648, test loss=0.390, test mse = 30212.375, test mae = 29.397\n",
      "epoch=567, loss=0.862, validation loss = 0.648, test loss=0.390, test mse = 30212.297, test mae = 29.391\n",
      "epoch=568, loss=0.861, validation loss = 0.647, test loss=0.390, test mse = 30212.217, test mae = 29.386\n",
      "epoch=569, loss=0.861, validation loss = 0.646, test loss=0.390, test mse = 30212.143, test mae = 29.380\n",
      "epoch=570, loss=0.860, validation loss = 0.646, test loss=0.390, test mse = 30212.068, test mae = 29.375\n",
      "epoch=571, loss=0.859, validation loss = 0.645, test loss=0.390, test mse = 30211.992, test mae = 29.369\n",
      "epoch=572, loss=0.859, validation loss = 0.645, test loss=0.389, test mse = 30211.920, test mae = 29.364\n",
      "epoch=573, loss=0.858, validation loss = 0.644, test loss=0.389, test mse = 30211.846, test mae = 29.358\n",
      "epoch=574, loss=0.857, validation loss = 0.644, test loss=0.389, test mse = 30211.775, test mae = 29.353\n",
      "epoch=575, loss=0.857, validation loss = 0.643, test loss=0.389, test mse = 30211.703, test mae = 29.347\n",
      "epoch=576, loss=0.856, validation loss = 0.642, test loss=0.389, test mse = 30211.639, test mae = 29.342\n",
      "epoch=577, loss=0.856, validation loss = 0.642, test loss=0.389, test mse = 30211.568, test mae = 29.337\n",
      "epoch=578, loss=0.855, validation loss = 0.641, test loss=0.389, test mse = 30211.500, test mae = 29.331\n",
      "epoch=579, loss=0.854, validation loss = 0.641, test loss=0.389, test mse = 30211.432, test mae = 29.326\n",
      "epoch=580, loss=0.854, validation loss = 0.640, test loss=0.389, test mse = 30211.365, test mae = 29.321\n",
      "epoch=581, loss=0.853, validation loss = 0.640, test loss=0.389, test mse = 30211.299, test mae = 29.315\n",
      "epoch=582, loss=0.852, validation loss = 0.639, test loss=0.388, test mse = 30211.234, test mae = 29.310\n",
      "epoch=583, loss=0.852, validation loss = 0.638, test loss=0.388, test mse = 30211.170, test mae = 29.305\n",
      "epoch=584, loss=0.851, validation loss = 0.638, test loss=0.388, test mse = 30211.104, test mae = 29.300\n",
      "epoch=585, loss=0.851, validation loss = 0.637, test loss=0.388, test mse = 30211.041, test mae = 29.295\n",
      "epoch=586, loss=0.850, validation loss = 0.637, test loss=0.388, test mse = 30210.979, test mae = 29.289\n",
      "epoch=587, loss=0.849, validation loss = 0.636, test loss=0.388, test mse = 30210.916, test mae = 29.284\n",
      "epoch=588, loss=0.849, validation loss = 0.636, test loss=0.388, test mse = 30210.857, test mae = 29.279\n",
      "epoch=589, loss=0.848, validation loss = 0.635, test loss=0.388, test mse = 30210.797, test mae = 29.274\n",
      "epoch=590, loss=0.847, validation loss = 0.635, test loss=0.388, test mse = 30210.734, test mae = 29.269\n",
      "epoch=591, loss=0.847, validation loss = 0.634, test loss=0.387, test mse = 30210.678, test mae = 29.263\n",
      "epoch=592, loss=0.846, validation loss = 0.633, test loss=0.387, test mse = 30210.619, test mae = 29.258\n",
      "epoch=593, loss=0.846, validation loss = 0.633, test loss=0.387, test mse = 30210.562, test mae = 29.253\n",
      "epoch=594, loss=0.845, validation loss = 0.632, test loss=0.387, test mse = 30210.502, test mae = 29.248\n",
      "epoch=595, loss=0.844, validation loss = 0.632, test loss=0.387, test mse = 30210.447, test mae = 29.243\n",
      "epoch=596, loss=0.844, validation loss = 0.631, test loss=0.387, test mse = 30210.391, test mae = 29.238\n",
      "epoch=597, loss=0.843, validation loss = 0.631, test loss=0.387, test mse = 30210.336, test mae = 29.233\n",
      "epoch=598, loss=0.843, validation loss = 0.630, test loss=0.387, test mse = 30210.281, test mae = 29.228\n",
      "epoch=599, loss=0.842, validation loss = 0.630, test loss=0.387, test mse = 30210.227, test mae = 29.223\n",
      "epoch=600, loss=0.841, validation loss = 0.629, test loss=0.386, test mse = 30210.172, test mae = 29.218\n",
      "epoch=601, loss=0.841, validation loss = 0.628, test loss=0.386, test mse = 30210.119, test mae = 29.213\n",
      "epoch=602, loss=0.840, validation loss = 0.628, test loss=0.386, test mse = 30210.070, test mae = 29.208\n",
      "epoch=603, loss=0.839, validation loss = 0.627, test loss=0.386, test mse = 30210.018, test mae = 29.203\n",
      "epoch=604, loss=0.839, validation loss = 0.627, test loss=0.386, test mse = 30209.967, test mae = 29.199\n",
      "epoch=605, loss=0.838, validation loss = 0.626, test loss=0.386, test mse = 30209.916, test mae = 29.194\n",
      "epoch=606, loss=0.838, validation loss = 0.626, test loss=0.386, test mse = 30209.867, test mae = 29.189\n",
      "epoch=607, loss=0.837, validation loss = 0.625, test loss=0.386, test mse = 30209.818, test mae = 29.184\n",
      "epoch=608, loss=0.836, validation loss = 0.625, test loss=0.386, test mse = 30209.768, test mae = 29.179\n",
      "epoch=609, loss=0.836, validation loss = 0.624, test loss=0.386, test mse = 30209.725, test mae = 29.174\n",
      "epoch=610, loss=0.835, validation loss = 0.623, test loss=0.385, test mse = 30209.674, test mae = 29.170\n",
      "epoch=611, loss=0.835, validation loss = 0.623, test loss=0.385, test mse = 30209.627, test mae = 29.165\n",
      "epoch=612, loss=0.834, validation loss = 0.622, test loss=0.385, test mse = 30209.580, test mae = 29.160\n",
      "epoch=613, loss=0.833, validation loss = 0.622, test loss=0.385, test mse = 30209.537, test mae = 29.155\n",
      "epoch=614, loss=0.833, validation loss = 0.621, test loss=0.385, test mse = 30209.490, test mae = 29.151\n",
      "epoch=615, loss=0.832, validation loss = 0.621, test loss=0.385, test mse = 30209.445, test mae = 29.146\n",
      "epoch=616, loss=0.832, validation loss = 0.620, test loss=0.385, test mse = 30209.400, test mae = 29.141\n",
      "epoch=617, loss=0.831, validation loss = 0.620, test loss=0.385, test mse = 30209.359, test mae = 29.137\n",
      "epoch=618, loss=0.830, validation loss = 0.619, test loss=0.385, test mse = 30209.314, test mae = 29.132\n",
      "epoch=619, loss=0.830, validation loss = 0.619, test loss=0.384, test mse = 30209.271, test mae = 29.127\n",
      "epoch=620, loss=0.829, validation loss = 0.618, test loss=0.384, test mse = 30209.232, test mae = 29.123\n",
      "epoch=621, loss=0.829, validation loss = 0.617, test loss=0.384, test mse = 30209.189, test mae = 29.118\n",
      "epoch=622, loss=0.828, validation loss = 0.617, test loss=0.384, test mse = 30209.150, test mae = 29.114\n",
      "epoch=623, loss=0.827, validation loss = 0.616, test loss=0.384, test mse = 30209.107, test mae = 29.109\n",
      "epoch=624, loss=0.827, validation loss = 0.616, test loss=0.384, test mse = 30209.070, test mae = 29.105\n",
      "epoch=625, loss=0.826, validation loss = 0.615, test loss=0.384, test mse = 30209.025, test mae = 29.100\n",
      "epoch=626, loss=0.826, validation loss = 0.615, test loss=0.384, test mse = 30208.990, test mae = 29.095\n",
      "epoch=627, loss=0.825, validation loss = 0.614, test loss=0.384, test mse = 30208.953, test mae = 29.091\n",
      "epoch=628, loss=0.824, validation loss = 0.614, test loss=0.384, test mse = 30208.916, test mae = 29.086\n",
      "epoch=629, loss=0.824, validation loss = 0.613, test loss=0.383, test mse = 30208.875, test mae = 29.082\n",
      "epoch=630, loss=0.823, validation loss = 0.613, test loss=0.383, test mse = 30208.842, test mae = 29.077\n",
      "epoch=631, loss=0.823, validation loss = 0.612, test loss=0.383, test mse = 30208.803, test mae = 29.073\n",
      "epoch=632, loss=0.822, validation loss = 0.612, test loss=0.383, test mse = 30208.768, test mae = 29.069\n",
      "epoch=633, loss=0.821, validation loss = 0.611, test loss=0.383, test mse = 30208.732, test mae = 29.064\n",
      "epoch=634, loss=0.821, validation loss = 0.610, test loss=0.383, test mse = 30208.697, test mae = 29.060\n",
      "epoch=635, loss=0.820, validation loss = 0.610, test loss=0.383, test mse = 30208.664, test mae = 29.055\n",
      "epoch=636, loss=0.820, validation loss = 0.609, test loss=0.383, test mse = 30208.631, test mae = 29.051\n",
      "epoch=637, loss=0.819, validation loss = 0.609, test loss=0.383, test mse = 30208.596, test mae = 29.046\n",
      "epoch=638, loss=0.818, validation loss = 0.608, test loss=0.383, test mse = 30208.564, test mae = 29.042\n",
      "epoch=639, loss=0.818, validation loss = 0.608, test loss=0.382, test mse = 30208.537, test mae = 29.038\n",
      "epoch=640, loss=0.817, validation loss = 0.607, test loss=0.382, test mse = 30208.506, test mae = 29.033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=641, loss=0.817, validation loss = 0.607, test loss=0.382, test mse = 30208.471, test mae = 29.029\n",
      "epoch=642, loss=0.816, validation loss = 0.606, test loss=0.382, test mse = 30208.439, test mae = 29.025\n",
      "epoch=643, loss=0.816, validation loss = 0.606, test loss=0.382, test mse = 30208.412, test mae = 29.021\n",
      "epoch=644, loss=0.815, validation loss = 0.605, test loss=0.382, test mse = 30208.383, test mae = 29.016\n",
      "epoch=645, loss=0.814, validation loss = 0.605, test loss=0.382, test mse = 30208.352, test mae = 29.012\n",
      "epoch=646, loss=0.814, validation loss = 0.604, test loss=0.382, test mse = 30208.326, test mae = 29.008\n",
      "epoch=647, loss=0.813, validation loss = 0.604, test loss=0.382, test mse = 30208.297, test mae = 29.003\n",
      "epoch=648, loss=0.813, validation loss = 0.603, test loss=0.382, test mse = 30208.271, test mae = 28.999\n",
      "epoch=649, loss=0.812, validation loss = 0.603, test loss=0.382, test mse = 30208.242, test mae = 28.995\n",
      "epoch=650, loss=0.811, validation loss = 0.602, test loss=0.381, test mse = 30208.217, test mae = 28.991\n",
      "epoch=651, loss=0.811, validation loss = 0.601, test loss=0.381, test mse = 30208.193, test mae = 28.987\n",
      "epoch=652, loss=0.810, validation loss = 0.601, test loss=0.381, test mse = 30208.164, test mae = 28.983\n",
      "epoch=653, loss=0.810, validation loss = 0.600, test loss=0.381, test mse = 30208.143, test mae = 28.978\n",
      "epoch=654, loss=0.809, validation loss = 0.600, test loss=0.381, test mse = 30208.117, test mae = 28.974\n",
      "epoch=655, loss=0.808, validation loss = 0.599, test loss=0.381, test mse = 30208.092, test mae = 28.970\n",
      "epoch=656, loss=0.808, validation loss = 0.599, test loss=0.381, test mse = 30208.068, test mae = 28.966\n",
      "epoch=657, loss=0.807, validation loss = 0.598, test loss=0.381, test mse = 30208.047, test mae = 28.962\n",
      "epoch=658, loss=0.807, validation loss = 0.598, test loss=0.381, test mse = 30208.025, test mae = 28.958\n",
      "epoch=659, loss=0.806, validation loss = 0.597, test loss=0.381, test mse = 30208.006, test mae = 28.954\n",
      "epoch=660, loss=0.806, validation loss = 0.597, test loss=0.380, test mse = 30207.982, test mae = 28.950\n",
      "epoch=661, loss=0.805, validation loss = 0.596, test loss=0.380, test mse = 30207.959, test mae = 28.946\n",
      "epoch=662, loss=0.804, validation loss = 0.596, test loss=0.380, test mse = 30207.939, test mae = 28.942\n",
      "epoch=663, loss=0.804, validation loss = 0.595, test loss=0.380, test mse = 30207.920, test mae = 28.938\n",
      "epoch=664, loss=0.803, validation loss = 0.595, test loss=0.380, test mse = 30207.898, test mae = 28.934\n",
      "epoch=665, loss=0.803, validation loss = 0.594, test loss=0.380, test mse = 30207.881, test mae = 28.930\n",
      "epoch=666, loss=0.802, validation loss = 0.594, test loss=0.380, test mse = 30207.859, test mae = 28.926\n",
      "epoch=667, loss=0.801, validation loss = 0.593, test loss=0.380, test mse = 30207.838, test mae = 28.922\n",
      "epoch=668, loss=0.801, validation loss = 0.593, test loss=0.380, test mse = 30207.820, test mae = 28.918\n",
      "epoch=669, loss=0.800, validation loss = 0.592, test loss=0.380, test mse = 30207.803, test mae = 28.914\n",
      "epoch=670, loss=0.800, validation loss = 0.592, test loss=0.380, test mse = 30207.781, test mae = 28.910\n",
      "epoch=671, loss=0.799, validation loss = 0.591, test loss=0.379, test mse = 30207.764, test mae = 28.906\n",
      "epoch=672, loss=0.799, validation loss = 0.591, test loss=0.379, test mse = 30207.744, test mae = 28.902\n",
      "epoch=673, loss=0.798, validation loss = 0.590, test loss=0.379, test mse = 30207.727, test mae = 28.899\n",
      "epoch=674, loss=0.797, validation loss = 0.590, test loss=0.379, test mse = 30207.713, test mae = 28.895\n",
      "epoch=675, loss=0.797, validation loss = 0.589, test loss=0.379, test mse = 30207.693, test mae = 28.891\n",
      "epoch=676, loss=0.796, validation loss = 0.588, test loss=0.379, test mse = 30207.678, test mae = 28.887\n",
      "epoch=677, loss=0.796, validation loss = 0.588, test loss=0.379, test mse = 30207.658, test mae = 28.883\n",
      "epoch=678, loss=0.795, validation loss = 0.587, test loss=0.379, test mse = 30207.646, test mae = 28.880\n",
      "epoch=679, loss=0.794, validation loss = 0.587, test loss=0.379, test mse = 30207.631, test mae = 28.876\n",
      "epoch=680, loss=0.794, validation loss = 0.586, test loss=0.379, test mse = 30207.615, test mae = 28.872\n",
      "epoch=681, loss=0.793, validation loss = 0.586, test loss=0.378, test mse = 30207.602, test mae = 28.869\n",
      "epoch=682, loss=0.793, validation loss = 0.585, test loss=0.378, test mse = 30207.586, test mae = 28.865\n",
      "epoch=683, loss=0.792, validation loss = 0.585, test loss=0.378, test mse = 30207.576, test mae = 28.861\n",
      "epoch=684, loss=0.792, validation loss = 0.584, test loss=0.378, test mse = 30207.562, test mae = 28.858\n",
      "epoch=685, loss=0.791, validation loss = 0.584, test loss=0.378, test mse = 30207.545, test mae = 28.854\n",
      "epoch=686, loss=0.790, validation loss = 0.583, test loss=0.378, test mse = 30207.533, test mae = 28.850\n",
      "epoch=687, loss=0.790, validation loss = 0.583, test loss=0.378, test mse = 30207.521, test mae = 28.847\n",
      "epoch=688, loss=0.789, validation loss = 0.582, test loss=0.378, test mse = 30207.510, test mae = 28.843\n",
      "epoch=689, loss=0.789, validation loss = 0.582, test loss=0.378, test mse = 30207.500, test mae = 28.840\n",
      "epoch=690, loss=0.788, validation loss = 0.581, test loss=0.378, test mse = 30207.486, test mae = 28.836\n",
      "epoch=691, loss=0.788, validation loss = 0.581, test loss=0.378, test mse = 30207.477, test mae = 28.833\n",
      "epoch=692, loss=0.787, validation loss = 0.580, test loss=0.377, test mse = 30207.467, test mae = 28.829\n",
      "epoch=693, loss=0.786, validation loss = 0.580, test loss=0.377, test mse = 30207.459, test mae = 28.826\n",
      "epoch=694, loss=0.786, validation loss = 0.579, test loss=0.377, test mse = 30207.447, test mae = 28.822\n",
      "epoch=695, loss=0.785, validation loss = 0.579, test loss=0.377, test mse = 30207.439, test mae = 28.819\n",
      "epoch=696, loss=0.785, validation loss = 0.578, test loss=0.377, test mse = 30207.428, test mae = 28.815\n",
      "epoch=697, loss=0.784, validation loss = 0.578, test loss=0.377, test mse = 30207.420, test mae = 28.812\n",
      "epoch=698, loss=0.784, validation loss = 0.577, test loss=0.377, test mse = 30207.414, test mae = 28.809\n",
      "epoch=699, loss=0.783, validation loss = 0.577, test loss=0.377, test mse = 30207.404, test mae = 28.805\n",
      "epoch=700, loss=0.782, validation loss = 0.576, test loss=0.377, test mse = 30207.398, test mae = 28.802\n",
      "epoch=701, loss=0.782, validation loss = 0.576, test loss=0.377, test mse = 30207.391, test mae = 28.799\n",
      "epoch=702, loss=0.781, validation loss = 0.575, test loss=0.377, test mse = 30207.383, test mae = 28.795\n",
      "epoch=703, loss=0.781, validation loss = 0.575, test loss=0.376, test mse = 30207.377, test mae = 28.792\n",
      "epoch=704, loss=0.780, validation loss = 0.574, test loss=0.376, test mse = 30207.373, test mae = 28.789\n",
      "epoch=705, loss=0.780, validation loss = 0.574, test loss=0.376, test mse = 30207.365, test mae = 28.786\n",
      "epoch=706, loss=0.779, validation loss = 0.573, test loss=0.376, test mse = 30207.359, test mae = 28.782\n",
      "epoch=707, loss=0.778, validation loss = 0.573, test loss=0.376, test mse = 30207.354, test mae = 28.779\n",
      "epoch=708, loss=0.778, validation loss = 0.572, test loss=0.376, test mse = 30207.350, test mae = 28.776\n",
      "epoch=709, loss=0.777, validation loss = 0.572, test loss=0.376, test mse = 30207.350, test mae = 28.773\n",
      "epoch=710, loss=0.777, validation loss = 0.571, test loss=0.376, test mse = 30207.344, test mae = 28.770\n",
      "epoch=711, loss=0.776, validation loss = 0.571, test loss=0.376, test mse = 30207.338, test mae = 28.767\n",
      "epoch=712, loss=0.776, validation loss = 0.570, test loss=0.376, test mse = 30207.336, test mae = 28.764\n",
      "epoch=713, loss=0.775, validation loss = 0.570, test loss=0.376, test mse = 30207.334, test mae = 28.761\n",
      "epoch=714, loss=0.775, validation loss = 0.569, test loss=0.376, test mse = 30207.330, test mae = 28.758\n",
      "epoch=715, loss=0.774, validation loss = 0.569, test loss=0.375, test mse = 30207.330, test mae = 28.755\n",
      "epoch=716, loss=0.773, validation loss = 0.568, test loss=0.375, test mse = 30207.326, test mae = 28.752\n",
      "epoch=717, loss=0.773, validation loss = 0.568, test loss=0.375, test mse = 30207.328, test mae = 28.749\n",
      "epoch=718, loss=0.772, validation loss = 0.567, test loss=0.375, test mse = 30207.322, test mae = 28.746\n",
      "epoch=719, loss=0.772, validation loss = 0.567, test loss=0.375, test mse = 30207.322, test mae = 28.743\n",
      "epoch=720, loss=0.771, validation loss = 0.566, test loss=0.375, test mse = 30207.322, test mae = 28.740\n",
      "epoch=721, loss=0.771, validation loss = 0.566, test loss=0.375, test mse = 30207.326, test mae = 28.737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=722, loss=0.770, validation loss = 0.565, test loss=0.375, test mse = 30207.322, test mae = 28.734\n",
      "epoch=723, loss=0.769, validation loss = 0.565, test loss=0.375, test mse = 30207.328, test mae = 28.731\n",
      "epoch=724, loss=0.769, validation loss = 0.564, test loss=0.375, test mse = 30207.328, test mae = 28.729\n",
      "epoch=725, loss=0.768, validation loss = 0.564, test loss=0.375, test mse = 30207.328, test mae = 28.726\n",
      "epoch=726, loss=0.768, validation loss = 0.563, test loss=0.375, test mse = 30207.334, test mae = 28.723\n",
      "epoch=727, loss=0.767, validation loss = 0.563, test loss=0.374, test mse = 30207.336, test mae = 28.720\n",
      "epoch=728, loss=0.767, validation loss = 0.562, test loss=0.374, test mse = 30207.338, test mae = 28.718\n",
      "epoch=729, loss=0.766, validation loss = 0.562, test loss=0.374, test mse = 30207.344, test mae = 28.715\n",
      "epoch=730, loss=0.766, validation loss = 0.561, test loss=0.374, test mse = 30207.344, test mae = 28.712\n",
      "epoch=731, loss=0.765, validation loss = 0.561, test loss=0.374, test mse = 30207.352, test mae = 28.710\n",
      "epoch=732, loss=0.764, validation loss = 0.560, test loss=0.374, test mse = 30207.354, test mae = 28.707\n",
      "epoch=733, loss=0.764, validation loss = 0.560, test loss=0.374, test mse = 30207.361, test mae = 28.704\n",
      "epoch=734, loss=0.763, validation loss = 0.559, test loss=0.374, test mse = 30207.365, test mae = 28.702\n",
      "epoch=735, loss=0.763, validation loss = 0.559, test loss=0.374, test mse = 30207.373, test mae = 28.699\n",
      "epoch=736, loss=0.762, validation loss = 0.558, test loss=0.374, test mse = 30207.381, test mae = 28.697\n",
      "epoch=737, loss=0.762, validation loss = 0.558, test loss=0.374, test mse = 30207.385, test mae = 28.694\n",
      "epoch=738, loss=0.761, validation loss = 0.557, test loss=0.374, test mse = 30207.393, test mae = 28.692\n",
      "epoch=739, loss=0.761, validation loss = 0.557, test loss=0.373, test mse = 30207.400, test mae = 28.689\n",
      "epoch=740, loss=0.760, validation loss = 0.556, test loss=0.373, test mse = 30207.406, test mae = 28.687\n",
      "epoch=741, loss=0.759, validation loss = 0.556, test loss=0.373, test mse = 30207.416, test mae = 28.685\n",
      "epoch=742, loss=0.759, validation loss = 0.556, test loss=0.373, test mse = 30207.428, test mae = 28.682\n",
      "epoch=743, loss=0.758, validation loss = 0.555, test loss=0.373, test mse = 30207.438, test mae = 28.680\n",
      "epoch=744, loss=0.758, validation loss = 0.555, test loss=0.373, test mse = 30207.443, test mae = 28.678\n",
      "epoch=745, loss=0.757, validation loss = 0.554, test loss=0.373, test mse = 30207.453, test mae = 28.675\n",
      "epoch=746, loss=0.757, validation loss = 0.554, test loss=0.373, test mse = 30207.467, test mae = 28.673\n",
      "epoch=747, loss=0.756, validation loss = 0.553, test loss=0.373, test mse = 30207.475, test mae = 28.671\n",
      "epoch=748, loss=0.756, validation loss = 0.553, test loss=0.373, test mse = 30207.482, test mae = 28.668\n",
      "epoch=749, loss=0.755, validation loss = 0.552, test loss=0.373, test mse = 30207.498, test mae = 28.666\n",
      "epoch=750, loss=0.754, validation loss = 0.552, test loss=0.373, test mse = 30207.506, test mae = 28.664\n",
      "epoch=751, loss=0.754, validation loss = 0.551, test loss=0.373, test mse = 30207.518, test mae = 28.662\n",
      "epoch=752, loss=0.753, validation loss = 0.551, test loss=0.373, test mse = 30207.529, test mae = 28.660\n",
      "epoch=753, loss=0.753, validation loss = 0.550, test loss=0.372, test mse = 30207.539, test mae = 28.658\n",
      "epoch=754, loss=0.752, validation loss = 0.550, test loss=0.372, test mse = 30207.553, test mae = 28.655\n",
      "epoch=755, loss=0.752, validation loss = 0.549, test loss=0.372, test mse = 30207.564, test mae = 28.653\n",
      "epoch=756, loss=0.751, validation loss = 0.549, test loss=0.372, test mse = 30207.578, test mae = 28.651\n",
      "epoch=757, loss=0.751, validation loss = 0.548, test loss=0.372, test mse = 30207.594, test mae = 28.649\n",
      "epoch=758, loss=0.750, validation loss = 0.548, test loss=0.372, test mse = 30207.607, test mae = 28.647\n",
      "epoch=759, loss=0.749, validation loss = 0.547, test loss=0.372, test mse = 30207.619, test mae = 28.645\n",
      "epoch=760, loss=0.749, validation loss = 0.547, test loss=0.372, test mse = 30207.633, test mae = 28.643\n",
      "epoch=761, loss=0.748, validation loss = 0.546, test loss=0.372, test mse = 30207.646, test mae = 28.641\n",
      "epoch=762, loss=0.748, validation loss = 0.546, test loss=0.372, test mse = 30207.658, test mae = 28.639\n",
      "epoch=763, loss=0.747, validation loss = 0.545, test loss=0.372, test mse = 30207.674, test mae = 28.637\n",
      "epoch=764, loss=0.747, validation loss = 0.545, test loss=0.372, test mse = 30207.688, test mae = 28.635\n",
      "epoch=765, loss=0.746, validation loss = 0.545, test loss=0.372, test mse = 30207.703, test mae = 28.633\n",
      "epoch=766, loss=0.746, validation loss = 0.544, test loss=0.372, test mse = 30207.717, test mae = 28.632\n",
      "epoch=767, loss=0.745, validation loss = 0.544, test loss=0.371, test mse = 30207.734, test mae = 28.630\n",
      "epoch=768, loss=0.745, validation loss = 0.543, test loss=0.371, test mse = 30207.750, test mae = 28.628\n",
      "epoch=769, loss=0.744, validation loss = 0.543, test loss=0.371, test mse = 30207.764, test mae = 28.626\n",
      "epoch=770, loss=0.744, validation loss = 0.542, test loss=0.371, test mse = 30207.781, test mae = 28.624\n",
      "epoch=771, loss=0.743, validation loss = 0.542, test loss=0.371, test mse = 30207.795, test mae = 28.622\n",
      "epoch=772, loss=0.742, validation loss = 0.541, test loss=0.371, test mse = 30207.811, test mae = 28.621\n",
      "epoch=773, loss=0.742, validation loss = 0.541, test loss=0.371, test mse = 30207.828, test mae = 28.619\n",
      "epoch=774, loss=0.741, validation loss = 0.540, test loss=0.371, test mse = 30207.846, test mae = 28.617\n",
      "epoch=775, loss=0.741, validation loss = 0.540, test loss=0.371, test mse = 30207.861, test mae = 28.615\n",
      "epoch=776, loss=0.740, validation loss = 0.539, test loss=0.371, test mse = 30207.881, test mae = 28.614\n",
      "epoch=777, loss=0.740, validation loss = 0.539, test loss=0.371, test mse = 30207.893, test mae = 28.612\n",
      "epoch=778, loss=0.739, validation loss = 0.538, test loss=0.371, test mse = 30207.912, test mae = 28.610\n",
      "epoch=779, loss=0.739, validation loss = 0.538, test loss=0.371, test mse = 30207.930, test mae = 28.609\n",
      "epoch=780, loss=0.738, validation loss = 0.537, test loss=0.371, test mse = 30207.945, test mae = 28.607\n",
      "epoch=781, loss=0.738, validation loss = 0.537, test loss=0.371, test mse = 30207.963, test mae = 28.605\n",
      "epoch=782, loss=0.737, validation loss = 0.537, test loss=0.371, test mse = 30207.979, test mae = 28.604\n",
      "epoch=783, loss=0.736, validation loss = 0.536, test loss=0.370, test mse = 30208.000, test mae = 28.602\n",
      "epoch=784, loss=0.736, validation loss = 0.536, test loss=0.370, test mse = 30208.018, test mae = 28.601\n",
      "epoch=785, loss=0.735, validation loss = 0.535, test loss=0.370, test mse = 30208.037, test mae = 28.599\n",
      "epoch=786, loss=0.735, validation loss = 0.535, test loss=0.370, test mse = 30208.053, test mae = 28.598\n",
      "epoch=787, loss=0.734, validation loss = 0.534, test loss=0.370, test mse = 30208.072, test mae = 28.596\n",
      "epoch=788, loss=0.734, validation loss = 0.534, test loss=0.370, test mse = 30208.092, test mae = 28.595\n",
      "epoch=789, loss=0.733, validation loss = 0.533, test loss=0.370, test mse = 30208.111, test mae = 28.593\n",
      "epoch=790, loss=0.733, validation loss = 0.533, test loss=0.370, test mse = 30208.127, test mae = 28.592\n",
      "epoch=791, loss=0.732, validation loss = 0.532, test loss=0.370, test mse = 30208.146, test mae = 28.590\n",
      "epoch=792, loss=0.732, validation loss = 0.532, test loss=0.370, test mse = 30208.166, test mae = 28.589\n",
      "epoch=793, loss=0.731, validation loss = 0.531, test loss=0.370, test mse = 30208.188, test mae = 28.587\n",
      "epoch=794, loss=0.731, validation loss = 0.531, test loss=0.370, test mse = 30208.205, test mae = 28.586\n",
      "epoch=795, loss=0.730, validation loss = 0.531, test loss=0.370, test mse = 30208.225, test mae = 28.585\n",
      "epoch=796, loss=0.730, validation loss = 0.530, test loss=0.370, test mse = 30208.248, test mae = 28.583\n",
      "epoch=797, loss=0.729, validation loss = 0.530, test loss=0.370, test mse = 30208.266, test mae = 28.582\n",
      "epoch=798, loss=0.729, validation loss = 0.529, test loss=0.370, test mse = 30208.283, test mae = 28.581\n",
      "epoch=799, loss=0.728, validation loss = 0.529, test loss=0.369, test mse = 30208.307, test mae = 28.579\n",
      "epoch=800, loss=0.727, validation loss = 0.528, test loss=0.369, test mse = 30208.326, test mae = 28.578\n",
      "epoch=801, loss=0.727, validation loss = 0.528, test loss=0.369, test mse = 30208.344, test mae = 28.577\n",
      "epoch=802, loss=0.726, validation loss = 0.527, test loss=0.369, test mse = 30208.367, test mae = 28.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=803, loss=0.726, validation loss = 0.527, test loss=0.369, test mse = 30208.385, test mae = 28.574\n",
      "epoch=804, loss=0.725, validation loss = 0.526, test loss=0.369, test mse = 30208.406, test mae = 28.573\n",
      "epoch=805, loss=0.725, validation loss = 0.526, test loss=0.369, test mse = 30208.430, test mae = 28.572\n",
      "epoch=806, loss=0.724, validation loss = 0.526, test loss=0.369, test mse = 30208.447, test mae = 28.571\n",
      "epoch=807, loss=0.724, validation loss = 0.525, test loss=0.369, test mse = 30208.471, test mae = 28.569\n",
      "epoch=808, loss=0.723, validation loss = 0.525, test loss=0.369, test mse = 30208.490, test mae = 28.568\n",
      "epoch=809, loss=0.723, validation loss = 0.524, test loss=0.369, test mse = 30208.510, test mae = 28.567\n",
      "epoch=810, loss=0.722, validation loss = 0.524, test loss=0.369, test mse = 30208.533, test mae = 28.566\n",
      "epoch=811, loss=0.722, validation loss = 0.523, test loss=0.369, test mse = 30208.555, test mae = 28.565\n",
      "epoch=812, loss=0.721, validation loss = 0.523, test loss=0.369, test mse = 30208.576, test mae = 28.564\n",
      "epoch=813, loss=0.721, validation loss = 0.522, test loss=0.369, test mse = 30208.596, test mae = 28.563\n",
      "epoch=814, loss=0.720, validation loss = 0.522, test loss=0.369, test mse = 30208.619, test mae = 28.562\n",
      "epoch=815, loss=0.720, validation loss = 0.521, test loss=0.369, test mse = 30208.641, test mae = 28.561\n",
      "epoch=816, loss=0.719, validation loss = 0.521, test loss=0.369, test mse = 30208.662, test mae = 28.560\n",
      "epoch=817, loss=0.719, validation loss = 0.521, test loss=0.369, test mse = 30208.688, test mae = 28.559\n",
      "epoch=818, loss=0.718, validation loss = 0.520, test loss=0.368, test mse = 30208.709, test mae = 28.558\n",
      "epoch=819, loss=0.717, validation loss = 0.520, test loss=0.368, test mse = 30208.732, test mae = 28.557\n",
      "epoch=820, loss=0.717, validation loss = 0.519, test loss=0.368, test mse = 30208.756, test mae = 28.556\n",
      "epoch=821, loss=0.716, validation loss = 0.519, test loss=0.368, test mse = 30208.775, test mae = 28.555\n",
      "epoch=822, loss=0.716, validation loss = 0.518, test loss=0.368, test mse = 30208.799, test mae = 28.554\n",
      "epoch=823, loss=0.715, validation loss = 0.518, test loss=0.368, test mse = 30208.822, test mae = 28.553\n",
      "epoch=824, loss=0.715, validation loss = 0.517, test loss=0.368, test mse = 30208.846, test mae = 28.552\n",
      "epoch=825, loss=0.714, validation loss = 0.517, test loss=0.368, test mse = 30208.869, test mae = 28.551\n",
      "epoch=826, loss=0.714, validation loss = 0.517, test loss=0.368, test mse = 30208.891, test mae = 28.550\n",
      "epoch=827, loss=0.713, validation loss = 0.516, test loss=0.368, test mse = 30208.916, test mae = 28.549\n",
      "epoch=828, loss=0.713, validation loss = 0.516, test loss=0.368, test mse = 30208.938, test mae = 28.548\n",
      "epoch=829, loss=0.712, validation loss = 0.515, test loss=0.368, test mse = 30208.961, test mae = 28.548\n",
      "epoch=830, loss=0.712, validation loss = 0.515, test loss=0.368, test mse = 30208.984, test mae = 28.547\n",
      "epoch=831, loss=0.711, validation loss = 0.514, test loss=0.368, test mse = 30209.010, test mae = 28.546\n",
      "epoch=832, loss=0.711, validation loss = 0.514, test loss=0.368, test mse = 30209.031, test mae = 28.545\n",
      "epoch=833, loss=0.710, validation loss = 0.513, test loss=0.368, test mse = 30209.057, test mae = 28.544\n",
      "epoch=834, loss=0.710, validation loss = 0.513, test loss=0.368, test mse = 30209.078, test mae = 28.544\n",
      "epoch=835, loss=0.709, validation loss = 0.513, test loss=0.368, test mse = 30209.104, test mae = 28.543\n",
      "epoch=836, loss=0.709, validation loss = 0.512, test loss=0.368, test mse = 30209.127, test mae = 28.542\n",
      "epoch=837, loss=0.708, validation loss = 0.512, test loss=0.368, test mse = 30209.148, test mae = 28.541\n",
      "epoch=838, loss=0.708, validation loss = 0.511, test loss=0.368, test mse = 30209.174, test mae = 28.540\n",
      "epoch=839, loss=0.707, validation loss = 0.511, test loss=0.368, test mse = 30209.197, test mae = 28.540\n",
      "epoch=840, loss=0.707, validation loss = 0.510, test loss=0.367, test mse = 30209.221, test mae = 28.539\n",
      "epoch=841, loss=0.706, validation loss = 0.510, test loss=0.367, test mse = 30209.244, test mae = 28.538\n",
      "epoch=842, loss=0.706, validation loss = 0.510, test loss=0.367, test mse = 30209.266, test mae = 28.538\n",
      "epoch=843, loss=0.705, validation loss = 0.509, test loss=0.367, test mse = 30209.291, test mae = 28.537\n",
      "epoch=844, loss=0.705, validation loss = 0.509, test loss=0.367, test mse = 30209.314, test mae = 28.536\n",
      "epoch=845, loss=0.704, validation loss = 0.508, test loss=0.367, test mse = 30209.336, test mae = 28.536\n",
      "epoch=846, loss=0.704, validation loss = 0.508, test loss=0.367, test mse = 30209.359, test mae = 28.535\n",
      "epoch=847, loss=0.703, validation loss = 0.507, test loss=0.367, test mse = 30209.385, test mae = 28.534\n",
      "epoch=848, loss=0.703, validation loss = 0.507, test loss=0.367, test mse = 30209.406, test mae = 28.534\n",
      "epoch=849, loss=0.702, validation loss = 0.506, test loss=0.367, test mse = 30209.432, test mae = 28.533\n",
      "epoch=850, loss=0.702, validation loss = 0.506, test loss=0.367, test mse = 30209.453, test mae = 28.532\n",
      "epoch=851, loss=0.701, validation loss = 0.506, test loss=0.367, test mse = 30209.477, test mae = 28.532\n",
      "epoch=852, loss=0.701, validation loss = 0.505, test loss=0.367, test mse = 30209.500, test mae = 28.531\n",
      "epoch=853, loss=0.700, validation loss = 0.505, test loss=0.367, test mse = 30209.523, test mae = 28.530\n",
      "epoch=854, loss=0.700, validation loss = 0.504, test loss=0.367, test mse = 30209.545, test mae = 28.530\n",
      "epoch=855, loss=0.699, validation loss = 0.504, test loss=0.367, test mse = 30209.568, test mae = 28.529\n",
      "epoch=856, loss=0.699, validation loss = 0.503, test loss=0.367, test mse = 30209.594, test mae = 28.529\n",
      "epoch=857, loss=0.698, validation loss = 0.503, test loss=0.367, test mse = 30209.615, test mae = 28.528\n",
      "epoch=858, loss=0.698, validation loss = 0.503, test loss=0.367, test mse = 30209.633, test mae = 28.528\n",
      "epoch=859, loss=0.697, validation loss = 0.502, test loss=0.367, test mse = 30209.658, test mae = 28.527\n",
      "epoch=860, loss=0.697, validation loss = 0.502, test loss=0.367, test mse = 30209.682, test mae = 28.526\n",
      "epoch=861, loss=0.696, validation loss = 0.501, test loss=0.367, test mse = 30209.705, test mae = 28.526\n",
      "epoch=862, loss=0.696, validation loss = 0.501, test loss=0.367, test mse = 30209.729, test mae = 28.525\n",
      "epoch=863, loss=0.695, validation loss = 0.500, test loss=0.367, test mse = 30209.750, test mae = 28.525\n",
      "epoch=864, loss=0.695, validation loss = 0.500, test loss=0.367, test mse = 30209.773, test mae = 28.524\n",
      "epoch=865, loss=0.694, validation loss = 0.500, test loss=0.366, test mse = 30209.795, test mae = 28.524\n",
      "epoch=866, loss=0.694, validation loss = 0.499, test loss=0.366, test mse = 30209.818, test mae = 28.523\n",
      "epoch=867, loss=0.693, validation loss = 0.499, test loss=0.366, test mse = 30209.838, test mae = 28.523\n",
      "epoch=868, loss=0.693, validation loss = 0.498, test loss=0.366, test mse = 30209.861, test mae = 28.522\n",
      "epoch=869, loss=0.692, validation loss = 0.498, test loss=0.366, test mse = 30209.885, test mae = 28.521\n",
      "epoch=870, loss=0.692, validation loss = 0.497, test loss=0.366, test mse = 30209.906, test mae = 28.521\n",
      "epoch=871, loss=0.691, validation loss = 0.497, test loss=0.366, test mse = 30209.930, test mae = 28.520\n",
      "epoch=872, loss=0.691, validation loss = 0.497, test loss=0.366, test mse = 30209.951, test mae = 28.520\n",
      "epoch=873, loss=0.690, validation loss = 0.496, test loss=0.366, test mse = 30209.969, test mae = 28.519\n",
      "epoch=874, loss=0.690, validation loss = 0.496, test loss=0.366, test mse = 30209.992, test mae = 28.519\n",
      "epoch=875, loss=0.689, validation loss = 0.495, test loss=0.366, test mse = 30210.016, test mae = 28.518\n",
      "epoch=876, loss=0.689, validation loss = 0.495, test loss=0.366, test mse = 30210.039, test mae = 28.518\n",
      "epoch=877, loss=0.688, validation loss = 0.495, test loss=0.366, test mse = 30210.057, test mae = 28.517\n",
      "epoch=878, loss=0.688, validation loss = 0.494, test loss=0.366, test mse = 30210.080, test mae = 28.517\n",
      "epoch=879, loss=0.687, validation loss = 0.494, test loss=0.366, test mse = 30210.102, test mae = 28.516\n",
      "epoch=880, loss=0.687, validation loss = 0.493, test loss=0.366, test mse = 30210.123, test mae = 28.516\n",
      "epoch=881, loss=0.686, validation loss = 0.493, test loss=0.366, test mse = 30210.143, test mae = 28.515\n",
      "epoch=882, loss=0.686, validation loss = 0.492, test loss=0.366, test mse = 30210.164, test mae = 28.515\n",
      "epoch=883, loss=0.685, validation loss = 0.492, test loss=0.366, test mse = 30210.188, test mae = 28.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=884, loss=0.685, validation loss = 0.492, test loss=0.366, test mse = 30210.205, test mae = 28.514\n",
      "epoch=885, loss=0.684, validation loss = 0.491, test loss=0.366, test mse = 30210.229, test mae = 28.513\n",
      "epoch=886, loss=0.684, validation loss = 0.491, test loss=0.366, test mse = 30210.248, test mae = 28.513\n",
      "epoch=887, loss=0.683, validation loss = 0.490, test loss=0.366, test mse = 30210.268, test mae = 28.512\n",
      "epoch=888, loss=0.683, validation loss = 0.490, test loss=0.366, test mse = 30210.291, test mae = 28.512\n",
      "epoch=889, loss=0.682, validation loss = 0.490, test loss=0.366, test mse = 30210.312, test mae = 28.511\n",
      "epoch=890, loss=0.682, validation loss = 0.489, test loss=0.366, test mse = 30210.334, test mae = 28.510\n",
      "epoch=891, loss=0.681, validation loss = 0.489, test loss=0.366, test mse = 30210.352, test mae = 28.510\n",
      "epoch=892, loss=0.681, validation loss = 0.488, test loss=0.366, test mse = 30210.373, test mae = 28.509\n",
      "epoch=893, loss=0.680, validation loss = 0.488, test loss=0.365, test mse = 30210.391, test mae = 28.509\n",
      "epoch=894, loss=0.680, validation loss = 0.487, test loss=0.365, test mse = 30210.414, test mae = 28.508\n",
      "epoch=895, loss=0.679, validation loss = 0.487, test loss=0.365, test mse = 30210.436, test mae = 28.508\n",
      "epoch=896, loss=0.679, validation loss = 0.487, test loss=0.365, test mse = 30210.453, test mae = 28.507\n",
      "epoch=897, loss=0.678, validation loss = 0.486, test loss=0.365, test mse = 30210.475, test mae = 28.507\n",
      "epoch=898, loss=0.678, validation loss = 0.486, test loss=0.365, test mse = 30210.494, test mae = 28.506\n",
      "epoch=899, loss=0.677, validation loss = 0.485, test loss=0.365, test mse = 30210.516, test mae = 28.506\n",
      "epoch=900, loss=0.677, validation loss = 0.485, test loss=0.365, test mse = 30210.537, test mae = 28.505\n",
      "epoch=901, loss=0.676, validation loss = 0.485, test loss=0.365, test mse = 30210.553, test mae = 28.505\n",
      "epoch=902, loss=0.676, validation loss = 0.484, test loss=0.365, test mse = 30210.576, test mae = 28.504\n",
      "epoch=903, loss=0.675, validation loss = 0.484, test loss=0.365, test mse = 30210.594, test mae = 28.504\n",
      "epoch=904, loss=0.675, validation loss = 0.483, test loss=0.365, test mse = 30210.615, test mae = 28.503\n",
      "epoch=905, loss=0.674, validation loss = 0.483, test loss=0.365, test mse = 30210.635, test mae = 28.503\n",
      "epoch=906, loss=0.674, validation loss = 0.483, test loss=0.365, test mse = 30210.656, test mae = 28.502\n",
      "epoch=907, loss=0.674, validation loss = 0.482, test loss=0.365, test mse = 30210.674, test mae = 28.502\n",
      "epoch=908, loss=0.673, validation loss = 0.482, test loss=0.365, test mse = 30210.695, test mae = 28.501\n",
      "epoch=909, loss=0.673, validation loss = 0.481, test loss=0.365, test mse = 30210.713, test mae = 28.501\n",
      "epoch=910, loss=0.672, validation loss = 0.481, test loss=0.365, test mse = 30210.732, test mae = 28.501\n",
      "epoch=911, loss=0.672, validation loss = 0.481, test loss=0.365, test mse = 30210.750, test mae = 28.500\n",
      "epoch=912, loss=0.671, validation loss = 0.480, test loss=0.365, test mse = 30210.773, test mae = 28.500\n",
      "epoch=913, loss=0.671, validation loss = 0.480, test loss=0.365, test mse = 30210.791, test mae = 28.499\n",
      "epoch=914, loss=0.670, validation loss = 0.479, test loss=0.365, test mse = 30210.811, test mae = 28.499\n",
      "epoch=915, loss=0.670, validation loss = 0.479, test loss=0.365, test mse = 30210.828, test mae = 28.498\n",
      "epoch=916, loss=0.669, validation loss = 0.479, test loss=0.365, test mse = 30210.852, test mae = 28.498\n",
      "epoch=917, loss=0.669, validation loss = 0.478, test loss=0.365, test mse = 30210.869, test mae = 28.497\n",
      "epoch=918, loss=0.668, validation loss = 0.478, test loss=0.365, test mse = 30210.889, test mae = 28.497\n",
      "epoch=919, loss=0.668, validation loss = 0.477, test loss=0.365, test mse = 30210.908, test mae = 28.496\n",
      "epoch=920, loss=0.667, validation loss = 0.477, test loss=0.365, test mse = 30210.928, test mae = 28.496\n",
      "epoch=921, loss=0.667, validation loss = 0.477, test loss=0.365, test mse = 30210.945, test mae = 28.495\n",
      "epoch=922, loss=0.666, validation loss = 0.476, test loss=0.365, test mse = 30210.963, test mae = 28.495\n",
      "epoch=923, loss=0.666, validation loss = 0.476, test loss=0.365, test mse = 30210.984, test mae = 28.494\n",
      "epoch=924, loss=0.665, validation loss = 0.475, test loss=0.365, test mse = 30211.002, test mae = 28.494\n",
      "epoch=925, loss=0.665, validation loss = 0.475, test loss=0.365, test mse = 30211.021, test mae = 28.494\n",
      "epoch=926, loss=0.664, validation loss = 0.475, test loss=0.364, test mse = 30211.041, test mae = 28.493\n",
      "epoch=927, loss=0.664, validation loss = 0.474, test loss=0.364, test mse = 30211.061, test mae = 28.493\n",
      "epoch=928, loss=0.664, validation loss = 0.474, test loss=0.364, test mse = 30211.080, test mae = 28.492\n",
      "epoch=929, loss=0.663, validation loss = 0.473, test loss=0.364, test mse = 30211.100, test mae = 28.492\n",
      "epoch=930, loss=0.663, validation loss = 0.473, test loss=0.364, test mse = 30211.119, test mae = 28.491\n",
      "epoch=931, loss=0.662, validation loss = 0.473, test loss=0.364, test mse = 30211.141, test mae = 28.491\n",
      "epoch=932, loss=0.662, validation loss = 0.472, test loss=0.364, test mse = 30211.158, test mae = 28.490\n",
      "epoch=933, loss=0.661, validation loss = 0.472, test loss=0.364, test mse = 30211.174, test mae = 28.490\n",
      "epoch=934, loss=0.661, validation loss = 0.471, test loss=0.364, test mse = 30211.195, test mae = 28.490\n",
      "epoch=935, loss=0.660, validation loss = 0.471, test loss=0.364, test mse = 30211.213, test mae = 28.489\n",
      "epoch=936, loss=0.660, validation loss = 0.471, test loss=0.364, test mse = 30211.232, test mae = 28.489\n",
      "epoch=937, loss=0.659, validation loss = 0.470, test loss=0.364, test mse = 30211.250, test mae = 28.488\n",
      "epoch=938, loss=0.659, validation loss = 0.470, test loss=0.364, test mse = 30211.268, test mae = 28.488\n",
      "epoch=939, loss=0.658, validation loss = 0.469, test loss=0.364, test mse = 30211.287, test mae = 28.487\n",
      "epoch=940, loss=0.658, validation loss = 0.469, test loss=0.364, test mse = 30211.307, test mae = 28.487\n",
      "epoch=941, loss=0.657, validation loss = 0.469, test loss=0.364, test mse = 30211.326, test mae = 28.487\n",
      "epoch=942, loss=0.657, validation loss = 0.468, test loss=0.364, test mse = 30211.344, test mae = 28.486\n",
      "epoch=943, loss=0.656, validation loss = 0.468, test loss=0.364, test mse = 30211.365, test mae = 28.486\n",
      "epoch=944, loss=0.656, validation loss = 0.468, test loss=0.364, test mse = 30211.381, test mae = 28.485\n",
      "epoch=945, loss=0.656, validation loss = 0.467, test loss=0.364, test mse = 30211.398, test mae = 28.485\n",
      "epoch=946, loss=0.655, validation loss = 0.467, test loss=0.364, test mse = 30211.416, test mae = 28.485\n",
      "epoch=947, loss=0.655, validation loss = 0.466, test loss=0.364, test mse = 30211.436, test mae = 28.484\n",
      "epoch=948, loss=0.654, validation loss = 0.466, test loss=0.364, test mse = 30211.455, test mae = 28.484\n",
      "epoch=949, loss=0.654, validation loss = 0.466, test loss=0.364, test mse = 30211.475, test mae = 28.483\n",
      "epoch=950, loss=0.653, validation loss = 0.465, test loss=0.364, test mse = 30211.490, test mae = 28.483\n",
      "epoch=951, loss=0.653, validation loss = 0.465, test loss=0.364, test mse = 30211.508, test mae = 28.483\n",
      "epoch=952, loss=0.652, validation loss = 0.464, test loss=0.364, test mse = 30211.525, test mae = 28.482\n",
      "epoch=953, loss=0.652, validation loss = 0.464, test loss=0.364, test mse = 30211.545, test mae = 28.482\n",
      "epoch=954, loss=0.651, validation loss = 0.464, test loss=0.364, test mse = 30211.562, test mae = 28.481\n",
      "epoch=955, loss=0.651, validation loss = 0.463, test loss=0.364, test mse = 30211.580, test mae = 28.481\n",
      "epoch=956, loss=0.650, validation loss = 0.463, test loss=0.364, test mse = 30211.600, test mae = 28.481\n",
      "epoch=957, loss=0.650, validation loss = 0.462, test loss=0.364, test mse = 30211.617, test mae = 28.480\n",
      "epoch=958, loss=0.650, validation loss = 0.462, test loss=0.364, test mse = 30211.633, test mae = 28.480\n",
      "epoch=959, loss=0.649, validation loss = 0.462, test loss=0.364, test mse = 30211.650, test mae = 28.479\n",
      "epoch=960, loss=0.649, validation loss = 0.461, test loss=0.364, test mse = 30211.672, test mae = 28.479\n",
      "epoch=961, loss=0.648, validation loss = 0.461, test loss=0.363, test mse = 30211.689, test mae = 28.479\n",
      "epoch=962, loss=0.648, validation loss = 0.461, test loss=0.363, test mse = 30211.705, test mae = 28.478\n",
      "epoch=963, loss=0.647, validation loss = 0.460, test loss=0.363, test mse = 30211.725, test mae = 28.478\n",
      "epoch=964, loss=0.647, validation loss = 0.460, test loss=0.363, test mse = 30211.742, test mae = 28.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=965, loss=0.646, validation loss = 0.459, test loss=0.363, test mse = 30211.760, test mae = 28.477\n",
      "epoch=966, loss=0.646, validation loss = 0.459, test loss=0.363, test mse = 30211.779, test mae = 28.477\n",
      "epoch=967, loss=0.645, validation loss = 0.459, test loss=0.363, test mse = 30211.791, test mae = 28.476\n",
      "epoch=968, loss=0.645, validation loss = 0.458, test loss=0.363, test mse = 30211.812, test mae = 28.476\n",
      "epoch=969, loss=0.645, validation loss = 0.458, test loss=0.363, test mse = 30211.830, test mae = 28.476\n",
      "epoch=970, loss=0.644, validation loss = 0.458, test loss=0.363, test mse = 30211.850, test mae = 28.475\n",
      "epoch=971, loss=0.644, validation loss = 0.457, test loss=0.363, test mse = 30211.865, test mae = 28.475\n",
      "epoch=972, loss=0.643, validation loss = 0.457, test loss=0.363, test mse = 30211.883, test mae = 28.474\n",
      "epoch=973, loss=0.643, validation loss = 0.456, test loss=0.363, test mse = 30211.898, test mae = 28.474\n",
      "epoch=974, loss=0.642, validation loss = 0.456, test loss=0.363, test mse = 30211.914, test mae = 28.474\n",
      "epoch=975, loss=0.642, validation loss = 0.456, test loss=0.363, test mse = 30211.930, test mae = 28.473\n",
      "epoch=976, loss=0.641, validation loss = 0.455, test loss=0.363, test mse = 30211.947, test mae = 28.473\n",
      "epoch=977, loss=0.641, validation loss = 0.455, test loss=0.363, test mse = 30211.967, test mae = 28.473\n",
      "epoch=978, loss=0.640, validation loss = 0.455, test loss=0.363, test mse = 30211.984, test mae = 28.472\n",
      "epoch=979, loss=0.640, validation loss = 0.454, test loss=0.363, test mse = 30212.006, test mae = 28.472\n",
      "epoch=980, loss=0.640, validation loss = 0.454, test loss=0.363, test mse = 30212.018, test mae = 28.471\n",
      "epoch=981, loss=0.639, validation loss = 0.453, test loss=0.363, test mse = 30212.037, test mae = 28.471\n",
      "epoch=982, loss=0.639, validation loss = 0.453, test loss=0.363, test mse = 30212.053, test mae = 28.471\n",
      "epoch=983, loss=0.638, validation loss = 0.453, test loss=0.363, test mse = 30212.070, test mae = 28.470\n",
      "epoch=984, loss=0.638, validation loss = 0.452, test loss=0.363, test mse = 30212.088, test mae = 28.470\n",
      "epoch=985, loss=0.637, validation loss = 0.452, test loss=0.363, test mse = 30212.104, test mae = 28.470\n",
      "epoch=986, loss=0.637, validation loss = 0.452, test loss=0.363, test mse = 30212.119, test mae = 28.469\n",
      "epoch=987, loss=0.636, validation loss = 0.451, test loss=0.363, test mse = 30212.139, test mae = 28.469\n",
      "epoch=988, loss=0.636, validation loss = 0.451, test loss=0.363, test mse = 30212.156, test mae = 28.468\n",
      "epoch=989, loss=0.636, validation loss = 0.450, test loss=0.363, test mse = 30212.170, test mae = 28.468\n",
      "epoch=990, loss=0.635, validation loss = 0.450, test loss=0.363, test mse = 30212.188, test mae = 28.468\n",
      "epoch=991, loss=0.635, validation loss = 0.450, test loss=0.363, test mse = 30212.203, test mae = 28.467\n",
      "epoch=992, loss=0.634, validation loss = 0.449, test loss=0.363, test mse = 30212.219, test mae = 28.467\n",
      "epoch=993, loss=0.634, validation loss = 0.449, test loss=0.363, test mse = 30212.236, test mae = 28.467\n",
      "epoch=994, loss=0.633, validation loss = 0.449, test loss=0.363, test mse = 30212.250, test mae = 28.466\n",
      "epoch=995, loss=0.633, validation loss = 0.448, test loss=0.363, test mse = 30212.268, test mae = 28.466\n",
      "epoch=996, loss=0.632, validation loss = 0.448, test loss=0.363, test mse = 30212.281, test mae = 28.466\n",
      "epoch=997, loss=0.632, validation loss = 0.448, test loss=0.363, test mse = 30212.299, test mae = 28.465\n",
      "epoch=998, loss=0.632, validation loss = 0.447, test loss=0.363, test mse = 30212.314, test mae = 28.465\n",
      "epoch=999, loss=0.631, validation loss = 0.447, test loss=0.362, test mse = 30212.334, test mae = 28.465\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "learning_rate = 0.0000005\n",
    "num_epochs = 1000\n",
    "batch_size = 1000\n",
    "output_size = 2\n",
    "\n",
    "device = th.device('cuda:0')\n",
    "input_size = train_past_cases[0].shape[1] + attrs.shape[1]\n",
    "mlp_sir = Net_SIR(input_size, hidden_size, output_size)\n",
    "print('#features:', input_size)\n",
    "\n",
    "# Move model to GPU\n",
    "mlp_sir = mlp_sir.to(device)\n",
    "# TODO we might want to choose a better loss.\n",
    "# L2 loss will penalize the data points with larger deaths more. Is this what we want?\n",
    "# criterion = criterion.to(device)\n",
    "\n",
    "# Move data to GPU\n",
    "pop = pop.to(device)\n",
    "attrs = attrs.to(device)\n",
    "for i in range(len(train_past_cases)):\n",
    "    train_past_cases[i] = train_past_cases[i].to(device)\n",
    "    train_past_deaths[i] = train_past_deaths[i].to(device)\n",
    "    train_labels_cases[i] = train_labels_cases[i].to(device)\n",
    "    train_labels_deaths[i] = train_labels_deaths[i].to(device)\n",
    "    if len(train_labels_cases[i].shape) == 1:\n",
    "        train_labels_cases[i] = train_labels_cases[i].unsqueeze(1)\n",
    "    if len(train_labels_deaths[i].shape) == 1:\n",
    "        train_labels_deaths[i] = train_labels_deaths[i].unsqueeze(1)\n",
    "        \n",
    "for i in range(len(valid_past_cases)):\n",
    "    valid_past_cases[i] = valid_past_cases[i].to(device)\n",
    "    valid_past_deaths[i] = valid_past_deaths[i].to(device)\n",
    "    valid_labels_cases[i] = valid_labels_cases[i].to(device)\n",
    "    valid_labels_deaths[i] = valid_labels_deaths[i].to(device)\n",
    "    if len(valid_labels_cases[i].shape) == 1:\n",
    "         valid_labels_cases[i] = valid_labels_cases[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths[i].shape) == 1:\n",
    "        valid_labels_deaths[i] = valid_labels_deaths[i].unsqueeze(1)\n",
    "\n",
    "for i in range(len(test_past_cases)):\n",
    "    test_past_cases[i] = test_past_cases[i].to(device)\n",
    "    test_past_deaths[i] = test_past_deaths[i].to(device)\n",
    "    test_labels_cases[i] = test_labels_cases[i].to(device)\n",
    "    test_labels_deaths[i] = test_labels_deaths[i].to(device)\n",
    "    if len(test_labels_cases[i].shape) == 1:\n",
    "        test_labels_cases[i] = test_labels_cases[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths[i].shape) == 1:\n",
    "        test_labels_deaths[i] = test_labels_deaths[i].unsqueeze(1)\n",
    "        \n",
    "# Normalize attrs\n",
    "attrs[th.isnan(attrs)] = 0\n",
    "attr_mean = th.mean(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs - attr_mean\n",
    "attr_std = th.std(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs / attr_std\n",
    "\n",
    "optimizer = th.optim.Adam(mlp_sir.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for idx in range(19, len(train_past_cases)):\n",
    "        labels_cases = train_labels_cases[idx]\n",
    "        labels_deaths = train_labels_deaths[idx]\n",
    "        batch = th.cat([train_past_cases[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = mlp_sir(batch)\n",
    "        I = train_past_cases[idx][:,-1].view(3142,1)\n",
    "        D = train_past_deaths[idx][:,-1].view(3142,1)\n",
    "        I_new, D_new = sir_output(vals, I, D)\n",
    "        loss = my_msle_ID(I_new, D_new, labels_cases, labels_deaths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    with th.no_grad():\n",
    "        eval_errs = []\n",
    "        test_errs = []\n",
    "        test_mses = []\n",
    "        test_maes = []\n",
    "        for idx in range(6):\n",
    "            valid_feats = th.cat([valid_past_cases[idx], attrs], dim=1)\n",
    "            eval_vals = mlp_sir(valid_feats)\n",
    "            eval_I = valid_past_cases[idx][:,-1].view(3142,1)\n",
    "            eval_D = valid_past_deaths[idx][:,-1].view(3142,1)\n",
    "            eval_labels_cases = valid_labels_cases[idx]\n",
    "            eval_labels_deaths = valid_labels_deaths[idx]\n",
    "            eval_I_new, eval_D_new = sir_output(eval_vals, eval_I, eval_D)\n",
    "            err = my_msle_ID(eval_I_new, eval_D_new, eval_labels_cases, eval_labels_deaths)\n",
    "            eval_errs.append(err.cpu().numpy())\n",
    "            \n",
    "            \n",
    "            test_feats = th.cat([test_past_cases[idx], attrs], dim=1)\n",
    "            test_vals = mlp_sir(test_feats)\n",
    "            test_I = test_past_cases[idx][:,-1].view(3142,1)\n",
    "            test_D = test_past_deaths[idx][:,-1].view(3142,1)\n",
    "            test_cases = test_labels_cases[idx]\n",
    "            test_deaths = test_labels_deaths[idx]\n",
    "            test_I_new, test_D_new = sir_output(test_vals, test_I, test_D)\n",
    "            test_err = my_msle_ID(test_I_new, test_D_new, test_cases, test_deaths)\n",
    "            test_mse = th.mean((test_I_new - test_labels_cases[idx])**2)\n",
    "            test_mae = th.mean(th.abs(test_I_new - test_labels_cases[idx]))\n",
    "            test_errs.append(test_err.cpu().numpy())\n",
    "            test_mses.append(test_mse.cpu().numpy())\n",
    "            test_maes.append(test_mae.cpu().numpy())\n",
    "        print('epoch={}, loss={:.3f}, validation loss = {:.3f}, test loss={:.3f}, test mse = {:.3f}, test mae = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs), np.mean(test_errs), np.mean(test_mses), np.mean(test_maes)))\n",
    "            \n",
    "#        if np.mean(eval_errs) <= 0.054:\n",
    "#            R0_NYC = []\n",
    "#            R0_Sacramento = []\n",
    "#            gamma_NYC = []\n",
    "#            beta_NYC = []\n",
    "#            gamma_Sacramento = []\n",
    "#            beta_Sacramento = []\n",
    "#            train_vals = []\n",
    "#            for idx in range(19, len(train_past_cases)):\n",
    "#                labels = train_labels_cases[idx]\n",
    "#                batch = th.cat([train_past_cases[idx], attrs], dim=1)\n",
    "#                th.manual_seed(1)\n",
    "#                vals = mlp_sir(batch)\n",
    "#                gamma_NYC.append(vals[4][0])\n",
    "#                gamma_Sacramento.append(vals[202][0])\n",
    "#                beta_NYC.append(vals[4][1])\n",
    "#                beta_Sacramento.append(vals[202][1])\n",
    "#                R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "#                R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "#                R0_NYC.append(R_NYC_div)\n",
    "#                R0_Sacramento.append(R_Sacramento_div)  \n",
    "#                I = train_past_cases[idx][:,-1].view(3142,1)\n",
    "#                D = train_past_deaths[idx][:,-1].view(3142,1)\n",
    "#                output = sir_output(vals, I, D, labels)\n",
    "#                train_vals.append(output)\n",
    "#            break\n",
    "#        print('epoch={}, loss={:.3f}, validation loss = {:.3f}, test loss={:.3f}, test mse = {:.3f}, test mae = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs), np.mean(test_errs), np.mean(test_mses), np.mean(test_maes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with th.no_grad():\n",
    "    R0_NYC = []\n",
    "    R0_Sacramento = []\n",
    "    gamma_NYC = []\n",
    "    beta_NYC = []\n",
    "    gamma_Sacramento = []\n",
    "    beta_Sacramento = []\n",
    "    train_vals = []\n",
    "    for idx in range(len(train_past_cases_1d)):\n",
    "        labels = train_labels_cases_1d[idx]\n",
    "        batch = th.cat([train_past_cases_1d[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = mlp_sir(batch)\n",
    "        gamma_NYC.append(vals[4][0])\n",
    "        gamma_Sacramento.append(vals[202][0])\n",
    "        beta_NYC.append(vals[4][1])\n",
    "        beta_Sacramento.append(vals[202][1])\n",
    "        R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "        R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "        R0_NYC.append(R_NYC_div)\n",
    "        R0_Sacramento.append(R_Sacramento_div)  \n",
    "        I = train_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "        D = train_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "        I_new, D_new = sir_1d_output(vals, I, D)\n",
    "        train_vals.append(I_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(R0_Sacramento))\n",
    "y1 = R0_Sacramento\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Sacramento R0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_vals = []\n",
    "for i in range(len(train_past_cases_1d)):\n",
    "    pred_vals.append(train_vals[i][202].cpu().numpy())\n",
    "\n",
    "x = range(len(train_past_cases_1d))\n",
    "y1 = train_labels_Sacramento\n",
    "y2 = pred_vals\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Real\")\n",
    "plt.plot(x, y2, ls=\"-\", lw=2, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(len(train_past_cases_1d))\n",
    "y_NYC = R0_NYC\n",
    "plt.plot(x, y_NYC, ls=\"-\", lw=2, label=\"NYC R0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_vals_NYC = []\n",
    "for i in range(len(train_past_cases_1d)):\n",
    "    pred_vals_NYC.append(train_vals[i][4].cpu().numpy())\n",
    "\n",
    "x = range(len(train_past_cases_1d))\n",
    "y1 = train_labels_NYC\n",
    "y2 = pred_vals_NYC\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Real\")\n",
    "plt.plot(x, y2, ls=\"-\", lw=2, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAT - SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, loss=1.290, validation loss = 1.034, test loss=1.158, test mse = 2015927.125, test mae = 83.997\n",
      "epoch=1, loss=1.031, validation loss = 0.541, test loss=0.573, test mse = 30787.713, test mae = 32.163\n",
      "epoch=2, loss=0.940, validation loss = 0.415, test loss=0.501, test mse = 30350.523, test mae = 30.228\n",
      "epoch=3, loss=0.886, validation loss = 0.356, test loss=0.482, test mse = 32233.656, test mae = 29.857\n",
      "epoch=4, loss=0.846, validation loss = 0.320, test loss=0.476, test mse = 31585.117, test mae = 29.550\n",
      "epoch=5, loss=0.813, validation loss = 0.295, test loss=0.475, test mse = 30804.877, test mae = 29.326\n",
      "epoch=6, loss=0.786, validation loss = 0.274, test loss=0.476, test mse = 30735.885, test mae = 29.166\n",
      "epoch=7, loss=0.761, validation loss = 0.260, test loss=0.477, test mse = 30400.367, test mae = 28.986\n",
      "epoch=8, loss=0.739, validation loss = 0.248, test loss=0.478, test mse = 30253.859, test mae = 28.851\n",
      "epoch=9, loss=0.719, validation loss = 0.238, test loss=0.479, test mse = 30226.299, test mae = 28.761\n",
      "epoch=10, loss=0.700, validation loss = 0.230, test loss=0.481, test mse = 30220.150, test mae = 28.696\n",
      "epoch=11, loss=0.684, validation loss = 0.222, test loss=0.482, test mse = 30217.578, test mae = 28.650\n",
      "epoch=12, loss=0.668, validation loss = 0.215, test loss=0.482, test mse = 30216.201, test mae = 28.609\n",
      "epoch=13, loss=0.653, validation loss = 0.210, test loss=0.483, test mse = 30215.727, test mae = 28.575\n",
      "epoch=14, loss=0.639, validation loss = 0.205, test loss=0.484, test mse = 30215.748, test mae = 28.546\n",
      "epoch=15, loss=0.626, validation loss = 0.200, test loss=0.485, test mse = 30216.068, test mae = 28.523\n",
      "epoch=16, loss=0.614, validation loss = 0.197, test loss=0.485, test mse = 30216.564, test mae = 28.505\n",
      "epoch=17, loss=0.603, validation loss = 0.194, test loss=0.486, test mse = 30217.109, test mae = 28.491\n",
      "epoch=18, loss=0.593, validation loss = 0.191, test loss=0.486, test mse = 30217.639, test mae = 28.480\n",
      "epoch=19, loss=0.583, validation loss = 0.189, test loss=0.487, test mse = 30218.119, test mae = 28.471\n",
      "epoch=20, loss=0.574, validation loss = 0.187, test loss=0.487, test mse = 30218.541, test mae = 28.465\n",
      "epoch=21, loss=0.566, validation loss = 0.185, test loss=0.488, test mse = 30218.906, test mae = 28.460\n",
      "epoch=22, loss=0.558, validation loss = 0.183, test loss=0.488, test mse = 30219.211, test mae = 28.456\n",
      "epoch=23, loss=0.551, validation loss = 0.182, test loss=0.489, test mse = 30219.447, test mae = 28.452\n",
      "epoch=24, loss=0.543, validation loss = 0.181, test loss=0.489, test mse = 30219.648, test mae = 28.449\n",
      "epoch=25, loss=0.537, validation loss = 0.180, test loss=0.489, test mse = 30219.811, test mae = 28.447\n",
      "epoch=26, loss=0.530, validation loss = 0.179, test loss=0.490, test mse = 30219.943, test mae = 28.444\n",
      "epoch=27, loss=0.524, validation loss = 0.179, test loss=0.490, test mse = 30220.057, test mae = 28.441\n",
      "epoch=28, loss=0.518, validation loss = 0.178, test loss=0.491, test mse = 30220.146, test mae = 28.439\n",
      "epoch=29, loss=0.513, validation loss = 0.177, test loss=0.491, test mse = 30220.219, test mae = 28.437\n",
      "epoch=30, loss=0.507, validation loss = 0.177, test loss=0.491, test mse = 30220.279, test mae = 28.435\n",
      "epoch=31, loss=0.502, validation loss = 0.177, test loss=0.492, test mse = 30220.334, test mae = 28.433\n",
      "epoch=32, loss=0.497, validation loss = 0.176, test loss=0.492, test mse = 30220.377, test mae = 28.431\n",
      "epoch=33, loss=0.492, validation loss = 0.176, test loss=0.492, test mse = 30220.414, test mae = 28.429\n",
      "epoch=34, loss=0.488, validation loss = 0.176, test loss=0.492, test mse = 30220.445, test mae = 28.428\n",
      "epoch=35, loss=0.483, validation loss = 0.176, test loss=0.493, test mse = 30220.471, test mae = 28.426\n",
      "epoch=36, loss=0.479, validation loss = 0.176, test loss=0.493, test mse = 30220.498, test mae = 28.425\n",
      "epoch=37, loss=0.475, validation loss = 0.175, test loss=0.493, test mse = 30220.516, test mae = 28.424\n",
      "epoch=38, loss=0.471, validation loss = 0.175, test loss=0.494, test mse = 30220.531, test mae = 28.423\n",
      "epoch=39, loss=0.467, validation loss = 0.175, test loss=0.494, test mse = 30220.547, test mae = 28.422\n",
      "epoch=40, loss=0.463, validation loss = 0.175, test loss=0.494, test mse = 30220.561, test mae = 28.421\n",
      "epoch=41, loss=0.459, validation loss = 0.175, test loss=0.494, test mse = 30220.570, test mae = 28.420\n",
      "epoch=42, loss=0.456, validation loss = 0.175, test loss=0.495, test mse = 30220.578, test mae = 28.420\n",
      "epoch=43, loss=0.452, validation loss = 0.175, test loss=0.495, test mse = 30220.588, test mae = 28.419\n",
      "epoch=44, loss=0.449, validation loss = 0.175, test loss=0.495, test mse = 30220.594, test mae = 28.418\n",
      "epoch=45, loss=0.446, validation loss = 0.175, test loss=0.495, test mse = 30220.602, test mae = 28.418\n",
      "epoch=46, loss=0.443, validation loss = 0.175, test loss=0.496, test mse = 30220.604, test mae = 28.417\n",
      "epoch=47, loss=0.439, validation loss = 0.175, test loss=0.496, test mse = 30220.611, test mae = 28.417\n",
      "epoch=48, loss=0.436, validation loss = 0.175, test loss=0.496, test mse = 30220.615, test mae = 28.416\n",
      "epoch=49, loss=0.433, validation loss = 0.175, test loss=0.496, test mse = 30220.617, test mae = 28.416\n",
      "epoch=50, loss=0.431, validation loss = 0.175, test loss=0.496, test mse = 30220.625, test mae = 28.415\n",
      "epoch=51, loss=0.428, validation loss = 0.175, test loss=0.497, test mse = 30220.625, test mae = 28.415\n",
      "epoch=52, loss=0.425, validation loss = 0.175, test loss=0.497, test mse = 30220.631, test mae = 28.414\n",
      "epoch=53, loss=0.423, validation loss = 0.175, test loss=0.497, test mse = 30220.631, test mae = 28.414\n",
      "epoch=54, loss=0.420, validation loss = 0.175, test loss=0.497, test mse = 30220.635, test mae = 28.413\n",
      "epoch=55, loss=0.418, validation loss = 0.174, test loss=0.497, test mse = 30220.635, test mae = 28.413\n",
      "epoch=56, loss=0.415, validation loss = 0.174, test loss=0.497, test mse = 30220.639, test mae = 28.412\n",
      "epoch=57, loss=0.413, validation loss = 0.174, test loss=0.498, test mse = 30220.639, test mae = 28.412\n",
      "epoch=58, loss=0.411, validation loss = 0.174, test loss=0.498, test mse = 30220.639, test mae = 28.412\n",
      "epoch=59, loss=0.409, validation loss = 0.174, test loss=0.498, test mse = 30220.641, test mae = 28.411\n",
      "epoch=60, loss=0.407, validation loss = 0.174, test loss=0.498, test mse = 30220.643, test mae = 28.411\n",
      "epoch=61, loss=0.405, validation loss = 0.174, test loss=0.498, test mse = 30220.643, test mae = 28.411\n",
      "epoch=62, loss=0.403, validation loss = 0.174, test loss=0.498, test mse = 30220.646, test mae = 28.410\n",
      "epoch=63, loss=0.401, validation loss = 0.174, test loss=0.498, test mse = 30220.646, test mae = 28.410\n",
      "epoch=64, loss=0.399, validation loss = 0.174, test loss=0.499, test mse = 30220.646, test mae = 28.410\n",
      "epoch=65, loss=0.398, validation loss = 0.174, test loss=0.499, test mse = 30220.646, test mae = 28.409\n",
      "epoch=66, loss=0.396, validation loss = 0.174, test loss=0.499, test mse = 30220.646, test mae = 28.409\n",
      "epoch=67, loss=0.395, validation loss = 0.174, test loss=0.499, test mse = 30220.650, test mae = 28.409\n",
      "epoch=68, loss=0.393, validation loss = 0.174, test loss=0.499, test mse = 30220.650, test mae = 28.408\n",
      "epoch=69, loss=0.392, validation loss = 0.174, test loss=0.499, test mse = 30220.648, test mae = 28.408\n",
      "epoch=70, loss=0.391, validation loss = 0.174, test loss=0.499, test mse = 30220.650, test mae = 28.408\n",
      "epoch=71, loss=0.389, validation loss = 0.174, test loss=0.499, test mse = 30220.654, test mae = 28.407\n",
      "epoch=72, loss=0.388, validation loss = 0.174, test loss=0.499, test mse = 30220.654, test mae = 28.407\n",
      "epoch=73, loss=0.387, validation loss = 0.174, test loss=0.499, test mse = 30220.654, test mae = 28.407\n",
      "epoch=74, loss=0.386, validation loss = 0.174, test loss=0.500, test mse = 30220.654, test mae = 28.407\n",
      "epoch=75, loss=0.385, validation loss = 0.174, test loss=0.500, test mse = 30220.656, test mae = 28.407\n",
      "epoch=76, loss=0.384, validation loss = 0.174, test loss=0.500, test mse = 30220.656, test mae = 28.406\n",
      "epoch=77, loss=0.383, validation loss = 0.174, test loss=0.500, test mse = 30220.656, test mae = 28.406\n",
      "epoch=78, loss=0.382, validation loss = 0.174, test loss=0.500, test mse = 30220.654, test mae = 28.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=79, loss=0.382, validation loss = 0.174, test loss=0.500, test mse = 30220.656, test mae = 28.406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-7e9a7a0ce944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mtest_cases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mtest_deaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels_deaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mtest_I_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_D_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msir_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_I\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mtest_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_msle_ID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_I_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_D_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_deaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mtest_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_I_new\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_labels_cases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-920307d3643e>\u001b[0m in \u001b[0;36msir_output\u001b[0;34m(params, I, D)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "learning_rate = 0.0000005\n",
    "num_epochs = 1000\n",
    "batch_size = 1000\n",
    "output_size = 2\n",
    "\n",
    "device = th.device('cuda:0')\n",
    "input_size = train_past_cases[0].shape[1] + attrs.shape[1]\n",
    "gat_sir = GAT_SIR(g, input_size, hidden_size, output_size, 1)\n",
    "print('#features:', input_size)\n",
    "\n",
    "# Move model to GPU\n",
    "gat_sir = gat_sir.to(device)\n",
    "# TODO we might want to choose a better loss.\n",
    "# L2 loss will penalize the data points with larger deaths more. Is this what we want?\n",
    "# criterion = criterion.to(device)\n",
    "\n",
    "# Move data to GPU\n",
    "pop = pop.to(device)\n",
    "attrs = attrs.to(device)\n",
    "for i in range(len(train_past_cases)):\n",
    "    train_past_cases[i] = train_past_cases[i].to(device)\n",
    "    train_past_deaths[i] = train_past_deaths[i].to(device)\n",
    "    train_labels_cases[i] = train_labels_cases[i].to(device)\n",
    "    train_labels_deaths[i] = train_labels_deaths[i].to(device)\n",
    "    if len(train_labels_cases[i].shape) == 1:\n",
    "        train_labels_cases[i] = train_labels_cases[i].unsqueeze(1)\n",
    "    if len(train_labels_deaths[i].shape) == 1:\n",
    "        train_labels_deaths[i] = train_labels_deaths[i].unsqueeze(1)\n",
    "        \n",
    "for i in range(len(valid_past_cases)):\n",
    "    valid_past_cases[i] = valid_past_cases[i].to(device)\n",
    "    valid_past_deaths[i] = valid_past_deaths[i].to(device)\n",
    "    valid_labels_cases[i] = valid_labels_cases[i].to(device)\n",
    "    valid_labels_deaths[i] = valid_labels_deaths[i].to(device)\n",
    "    if len(valid_labels_cases[i].shape) == 1:\n",
    "         valid_labels_cases[i] = valid_labels_cases[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths[i].shape) == 1:\n",
    "        valid_labels_deaths[i] = valid_labels_deaths[i].unsqueeze(1)\n",
    "\n",
    "for i in range(len(test_past_cases)):\n",
    "    test_past_cases[i] = test_past_cases[i].to(device)\n",
    "    test_past_deaths[i] = test_past_deaths[i].to(device)\n",
    "    test_labels_cases[i] = test_labels_cases[i].to(device)\n",
    "    test_labels_deaths[i] = test_labels_deaths[i].to(device)\n",
    "    if len(test_labels_cases[i].shape) == 1:\n",
    "        test_labels_cases[i] = test_labels_cases[i].unsqueeze(1)\n",
    "    if len(test_labels_deaths[i].shape) == 1:\n",
    "        test_labels_deaths[i] = test_labels_deaths[i].unsqueeze(1)\n",
    "        \n",
    "# Normalize attrs\n",
    "attrs[th.isnan(attrs)] = 0\n",
    "attr_mean = th.mean(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs - attr_mean\n",
    "attr_std = th.std(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs / attr_std\n",
    "\n",
    "optimizer = th.optim.Adam(gat_sir.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "    for idx in range(19, len(train_past_cases)):\n",
    "        labels_cases = train_labels_cases[idx]\n",
    "        labels_deaths = train_labels_deaths[idx]\n",
    "        batch = th.cat([train_past_cases[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = gat_sir(batch)\n",
    "        I = train_past_cases[idx][:,-1].view(3142,1)\n",
    "        D = train_past_deaths[idx][:,-1].view(3142,1)\n",
    "        I_new, D_new = sir_output(vals, I, D)\n",
    "        loss = my_msle_ID(I_new, D_new, labels_cases, labels_deaths)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    with th.no_grad():\n",
    "        eval_errs = []\n",
    "        test_errs = []\n",
    "        test_mses = []\n",
    "        test_maes = []\n",
    "        for idx in range(6):\n",
    "            valid_feats = th.cat([valid_past_cases[idx], attrs], dim=1)\n",
    "            eval_vals = gat_sir(valid_feats)\n",
    "            eval_I = valid_past_cases[idx][:,-1].view(3142,1)\n",
    "            eval_D = valid_past_deaths[idx][:,-1].view(3142,1)\n",
    "            eval_labels_cases = valid_labels_cases[idx]\n",
    "            eval_labels_deaths = valid_labels_deaths[idx]\n",
    "            eval_I_new, eval_D_new = sir_output(eval_vals, eval_I, eval_D)\n",
    "            err = my_msle_ID(eval_I_new, eval_D_new, eval_labels_cases, eval_labels_deaths)\n",
    "            eval_errs.append(err.cpu().numpy())\n",
    "            \n",
    "            \n",
    "            test_feats = th.cat([test_past_cases[idx], attrs], dim=1)\n",
    "            test_vals = gat_sir(test_feats)\n",
    "            test_I = test_past_cases[idx][:,-1].view(3142,1)\n",
    "            test_D = test_past_deaths[idx][:,-1].view(3142,1)\n",
    "            test_cases = test_labels_cases[idx]\n",
    "            test_deaths = test_labels_deaths[idx]\n",
    "            test_I_new, test_D_new = sir_output(test_vals, test_I, test_D)\n",
    "            test_err = my_msle_ID(test_I_new, test_D_new, test_cases, test_deaths)\n",
    "            test_mse = th.mean((test_I_new - test_labels_cases[idx])**2)\n",
    "            test_mae = th.mean(th.abs(test_I_new - test_labels_cases[idx]))\n",
    "            test_errs.append(test_err.cpu().numpy())\n",
    "            test_mses.append(test_mse.cpu().numpy())\n",
    "            test_maes.append(test_mae.cpu().numpy())\n",
    "        print('epoch={}, loss={:.3f}, validation loss = {:.3f}, test loss={:.3f}, test mse = {:.3f}, test mae = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs), np.mean(test_errs), np.mean(test_mses), np.mean(test_maes)))\n",
    "            \n",
    "#        if np.mean(eval_errs) <= 0.054:\n",
    "#            R0_NYC = []\n",
    "#            R0_Sacramento = []\n",
    "#            gamma_NYC = []\n",
    "#            beta_NYC = []\n",
    "#            gamma_Sacramento = []\n",
    "#            beta_Sacramento = []\n",
    "#            train_vals = []\n",
    "#            for idx in range(19, len(train_past_cases)):\n",
    "#                labels = train_labels_cases[idx]\n",
    "#                batch = th.cat([train_past_cases[idx], attrs], dim=1)\n",
    "#                th.manual_seed(1)\n",
    "#                vals = mlp_sir(batch)\n",
    "#                gamma_NYC.append(vals[4][0])\n",
    "#                gamma_Sacramento.append(vals[202][0])\n",
    "#                beta_NYC.append(vals[4][1])\n",
    "#                beta_Sacramento.append(vals[202][1])\n",
    "#                R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "#                R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "#                R0_NYC.append(R_NYC_div)\n",
    "#                R0_Sacramento.append(R_Sacramento_div)  \n",
    "#                I = train_past_cases[idx][:,-1].view(3142,1)\n",
    "#                D = train_past_deaths[idx][:,-1].view(3142,1)\n",
    "#                output = sir_output(vals, I, D, labels)\n",
    "#                train_vals.append(output)\n",
    "#            break\n",
    "#        print('epoch={}, loss={:.3f}, validation loss = {:.3f}, test loss={:.3f}, test mse = {:.3f}, test mae = {:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs), np.mean(test_errs), np.mean(test_mses), np.mean(test_maes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with th.no_grad():\n",
    "    R0_NYC = []\n",
    "    R0_Sacramento = []\n",
    "    gamma_NYC = []\n",
    "    beta_NYC = []\n",
    "    gamma_Sacramento = []\n",
    "    beta_Sacramento = []\n",
    "    train_vals = []\n",
    "    for idx in range(19, len(train_past_cases_1d)):\n",
    "        labels = train_labels_cases_1d[idx]\n",
    "        batch = th.cat([train_past_cases_1d[idx], attrs], dim=1)\n",
    "        th.manual_seed(1)\n",
    "        vals = gat_sir(batch)\n",
    "        gamma_NYC.append(vals[4][0])\n",
    "        gamma_Sacramento.append(vals[202][0])\n",
    "        beta_NYC.append(vals[4][1])\n",
    "        beta_Sacramento.append(vals[202][1])\n",
    "        R_NYC_div = th.div(vals[4][1],vals[4][0])\n",
    "        R_Sacramento_div = th.div(vals[202][1],vals[202][0])\n",
    "        R0_NYC.append(R_NYC_div)\n",
    "        R0_Sacramento.append(R_Sacramento_div)  \n",
    "        I = train_past_cases_1d[idx][:,-1].view(3142,1)\n",
    "        D = train_past_deaths_1d[idx][:,-1].view(3142,1)\n",
    "        I_new, D_new = sir_1d_output(vals, I, D)\n",
    "        train_vals.append(I_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(R0_Sacramento))\n",
    "y1 = R0_Sacramento\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Sacramento R0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vals = []\n",
    "for i in range(79-19):\n",
    "    pred_vals.append(train_vals[i][202].cpu().numpy())\n",
    "\n",
    "x = range(60)\n",
    "y1 = train_labels_Sacramento\n",
    "y2 = pred_vals\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Real\")\n",
    "plt.plot(x, y2, ls=\"-\", lw=2, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0160, device='cuda:0') tensor(0.0062, device='cuda:0') tensor(2.5541, device='cuda:0')\n",
      "tensor(0.0081, device='cuda:0') tensor(0.0022, device='cuda:0') tensor(3.6677, device='cuda:0')\n",
      "tensor(0.0038, device='cuda:0') tensor(0.0009, device='cuda:0') tensor(4.3246, device='cuda:0')\n",
      "tensor(0.0013, device='cuda:0') tensor(0.0002, device='cuda:0') tensor(8.4636, device='cuda:0')\n",
      "tensor(0.0005, device='cuda:0') tensor(7.1190e-05, device='cuda:0') tensor(7.3065, device='cuda:0')\n",
      "tensor(0.0002, device='cuda:0') tensor(1.8216e-05, device='cuda:0') tensor(9.7661, device='cuda:0')\n",
      "tensor(4.8411e-05, device='cuda:0') tensor(2.2408e-06, device='cuda:0') tensor(21.6038, device='cuda:0')\n",
      "tensor(1.0758e-05, device='cuda:0') tensor(4.2777e-07, device='cuda:0') tensor(25.1499, device='cuda:0')\n",
      "tensor(1.4434e-06, device='cuda:0') tensor(3.7484e-08, device='cuda:0') tensor(38.5078, device='cuda:0')\n",
      "tensor(3.8367e-07, device='cuda:0') tensor(5.4012e-09, device='cuda:0') tensor(71.0348, device='cuda:0')\n",
      "tensor(4.6914e-08, device='cuda:0') tensor(1.8296e-10, device='cuda:0') tensor(256.4198, device='cuda:0')\n",
      "tensor(9.1713e-09, device='cuda:0') tensor(2.5832e-11, device='cuda:0') tensor(355.0359, device='cuda:0')\n",
      "tensor(6.7822e-10, device='cuda:0') tensor(3.9518e-13, device='cuda:0') tensor(1716.2172, device='cuda:0')\n",
      "tensor(5.2675e-11, device='cuda:0') tensor(4.5692e-14, device='cuda:0') tensor(1152.8336, device='cuda:0')\n",
      "tensor(5.2832e-12, device='cuda:0') tensor(7.2952e-16, device='cuda:0') tensor(7242.0601, device='cuda:0')\n",
      "tensor(3.6245e-13, device='cuda:0') tensor(2.4626e-17, device='cuda:0') tensor(14717.9150, device='cuda:0')\n",
      "tensor(9.1744e-14, device='cuda:0') tensor(6.9222e-19, device='cuda:0') tensor(132536.4375, device='cuda:0')\n",
      "tensor(4.0888e-15, device='cuda:0') tensor(1.1653e-20, device='cuda:0') tensor(350890.8125, device='cuda:0')\n",
      "tensor(5.5737e-16, device='cuda:0') tensor(3.7935e-22, device='cuda:0') tensor(1469274.5000, device='cuda:0')\n",
      "tensor(3.2399e-17, device='cuda:0') tensor(5.9723e-24, device='cuda:0') tensor(5424929.5000, device='cuda:0')\n",
      "tensor(1.3785e-18, device='cuda:0') tensor(9.7646e-26, device='cuda:0') tensor(14117651., device='cuda:0')\n",
      "tensor(8.9165e-20, device='cuda:0') tensor(9.6081e-28, device='cuda:0') tensor(92801208., device='cuda:0')\n",
      "tensor(7.3963e-21, device='cuda:0') tensor(1.8425e-29, device='cuda:0') tensor(4.0143e+08, device='cuda:0')\n",
      "tensor(5.9935e-22, device='cuda:0') tensor(4.1325e-31, device='cuda:0') tensor(1.4503e+09, device='cuda:0')\n",
      "tensor(4.1737e-23, device='cuda:0') tensor(1.0904e-32, device='cuda:0') tensor(3.8277e+09, device='cuda:0')\n",
      "tensor(4.1550e-24, device='cuda:0') tensor(1.1811e-34, device='cuda:0') tensor(3.5179e+10, device='cuda:0')\n",
      "tensor(1.6057e-25, device='cuda:0') tensor(2.0291e-36, device='cuda:0') tensor(7.9130e+10, device='cuda:0')\n",
      "tensor(9.5078e-27, device='cuda:0') tensor(6.4673e-38, device='cuda:0') tensor(1.4701e+11, device='cuda:0')\n",
      "tensor(7.8196e-28, device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(6.4257e-29, device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(7.5226e-30, device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(7.3455e-31, device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(6.6377e-32, device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n",
      "tensor(9.0427e-33, device='cuda:0') tensor(0., device='cuda:0') tensor(inf, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i,j,k in zip(beta_Sacramento, gamma_Sacramento, R0_Sacramento):\n",
    "    print(i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(len(R0_NYC))\n",
    "y_NYC = R0_NYC\n",
    "plt.plot(x, y_NYC, ls=\"-\", lw=2, label=\"NYC R0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vals_NYC = []\n",
    "for i in range(79-19):\n",
    "    pred_vals_NYC.append(train_vals[i][4].cpu().numpy())\n",
    "\n",
    "x = range(60)\n",
    "y1 = train_labels_NYC\n",
    "y2 = pred_vals_NYC\n",
    "plt.plot(x, y1, ls=\"-\", lw=2, label=\"Real\")\n",
    "plt.plot(x, y2, ls=\"-\", lw=2, label=\"Predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n",
      "tensor(0., device='cuda:0') tensor(0., device='cuda:0') tensor(nan, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i,j,k in zip(beta_NYC, gamma_NYC, R0_NYC):\n",
    "    print(i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
