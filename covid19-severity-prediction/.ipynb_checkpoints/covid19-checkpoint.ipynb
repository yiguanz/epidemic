{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading county-level data...\n",
      "loaded and merged COVID-19 cases/deaths data successfully\n"
     ]
    }
   ],
   "source": [
    "import load_data\n",
    "df = load_data.load_county_level(data_dir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countyFIPS\n",
      "STATEFP\n",
      "COUNTYFP\n",
      "CountyName\n",
      "StateName\n",
      "State\n",
      "lat\n",
      "lon\n",
      "POP_LATITUDE\n",
      "POP_LONGITUDE\n",
      "CensusRegionName\n",
      "CensusDivisionName\n",
      "Rural-UrbanContinuumCode2013\n",
      "PopulationEstimate2018\n",
      "PopTotalMale2017\n",
      "PopTotalFemale2017\n",
      "FracMale2017\n",
      "PopulationEstimate65+2017\n",
      "PopulationDensityperSqMile2010\n",
      "CensusPopulation2010\n",
      "MedianAge2010\n",
      "#EligibleforMedicare2018\n",
      "MedicareEnrollment,AgedTot2017\n",
      "3-YrDiabetes2015-17\n",
      "DiabetesPercentage\n",
      "HeartDiseaseMortality\n",
      "StrokeMortality\n",
      "Smokers_Percentage\n",
      "RespMortalityRate2014\n",
      "#FTEHospitalTotal2017\n",
      "TotalM.D.'s,TotNon-FedandFed2017\n",
      "#HospParticipatinginNetwork2017\n",
      "#Hospitals\n",
      "#ICU_beds\n",
      "dem_to_rep_ratio\n",
      "PopMale<52010\n",
      "PopFmle<52010\n",
      "PopMale5-92010\n",
      "PopFmle5-92010\n",
      "PopMale10-142010\n",
      "PopFmle10-142010\n",
      "PopMale15-192010\n",
      "PopFmle15-192010\n",
      "PopMale20-242010\n",
      "PopFmle20-242010\n",
      "PopMale25-292010\n",
      "PopFmle25-292010\n",
      "PopMale30-342010\n",
      "PopFmle30-342010\n",
      "PopMale35-442010\n",
      "PopFmle35-442010\n",
      "PopMale45-542010\n",
      "PopFmle45-542010\n",
      "PopMale55-592010\n",
      "PopFmle55-592010\n",
      "PopMale60-642010\n",
      "PopFmle60-642010\n",
      "PopMale65-742010\n",
      "PopFmle65-742010\n",
      "PopMale75-842010\n",
      "PopFmle75-842010\n",
      "PopMale>842010\n",
      "PopFmle>842010\n",
      "3-YrMortalityAge<1Year2015-17\n",
      "3-YrMortalityAge1-4Years2015-17\n",
      "3-YrMortalityAge5-14Years2015-17\n",
      "3-YrMortalityAge15-24Years2015-17\n",
      "3-YrMortalityAge25-34Years2015-17\n",
      "3-YrMortalityAge35-44Years2015-17\n",
      "3-YrMortalityAge45-54Years2015-17\n",
      "3-YrMortalityAge55-64Years2015-17\n",
      "3-YrMortalityAge65-74Years2015-17\n",
      "3-YrMortalityAge75-84Years2015-17\n",
      "3-YrMortalityAge85+Years2015-17\n",
      "mortality2015-17Estimated\n",
      "stay at home\n",
      ">50 gatherings\n",
      ">500 gatherings\n",
      "public schools\n",
      "restaurant dine-in\n",
      "entertainment/gym\n",
      "federal guidelines\n",
      "foreign travel ban\n",
      "SVIPercentile\n",
      "HPSAShortage\n",
      "HPSAServedPop\n",
      "HPSAUnderservedPop\n",
      "#Cases_01-22-2020\n",
      "#Cases_01-23-2020\n",
      "#Cases_01-24-2020\n",
      "#Cases_01-25-2020\n",
      "#Cases_01-26-2020\n",
      "#Cases_01-27-2020\n",
      "#Cases_01-28-2020\n",
      "#Cases_01-29-2020\n",
      "#Cases_01-30-2020\n",
      "#Cases_01-31-2020\n",
      "#Cases_02-01-2020\n",
      "#Cases_02-02-2020\n",
      "#Cases_02-03-2020\n",
      "#Cases_02-04-2020\n",
      "#Cases_02-05-2020\n",
      "#Cases_02-06-2020\n",
      "#Cases_02-07-2020\n",
      "#Cases_02-08-2020\n",
      "#Cases_02-09-2020\n",
      "#Cases_02-10-2020\n",
      "#Cases_02-11-2020\n",
      "#Cases_02-12-2020\n",
      "#Cases_02-13-2020\n",
      "#Cases_02-14-2020\n",
      "#Cases_02-15-2020\n",
      "#Cases_02-16-2020\n",
      "#Cases_02-17-2020\n",
      "#Cases_02-18-2020\n",
      "#Cases_02-19-2020\n",
      "#Cases_02-20-2020\n",
      "#Cases_02-21-2020\n",
      "#Cases_02-22-2020\n",
      "#Cases_02-23-2020\n",
      "#Cases_02-24-2020\n",
      "#Cases_02-25-2020\n",
      "#Cases_02-26-2020\n",
      "#Cases_02-27-2020\n",
      "#Cases_02-28-2020\n",
      "#Cases_02-29-2020\n",
      "#Cases_03-01-2020\n",
      "#Cases_03-02-2020\n",
      "#Cases_03-03-2020\n",
      "#Cases_03-04-2020\n",
      "#Cases_03-05-2020\n",
      "#Cases_03-06-2020\n",
      "#Cases_03-07-2020\n",
      "#Cases_03-08-2020\n",
      "#Cases_03-09-2020\n",
      "#Cases_03-10-2020\n",
      "#Cases_03-11-2020\n",
      "#Cases_03-12-2020\n",
      "#Cases_03-13-2020\n",
      "#Cases_03-14-2020\n",
      "#Cases_03-15-2020\n",
      "#Cases_03-16-2020\n",
      "#Cases_03-17-2020\n",
      "#Cases_03-18-2020\n",
      "#Cases_03-19-2020\n",
      "#Cases_03-20-2020\n",
      "#Cases_03-21-2020\n",
      "#Cases_03-22-2020\n",
      "#Cases_03-23-2020\n",
      "#Cases_03-24-2020\n",
      "#Cases_03-25-2020\n",
      "#Cases_03-26-2020\n",
      "#Cases_03-27-2020\n",
      "#Cases_03-28-2020\n",
      "#Cases_03-29-2020\n",
      "#Cases_03-30-2020\n",
      "#Cases_03-31-2020\n",
      "#Cases_04-01-2020\n",
      "#Cases_04-02-2020\n",
      "#Cases_04-03-2020\n",
      "#Cases_04-04-2020\n",
      "#Cases_04-05-2020\n",
      "#Cases_04-06-2020\n",
      "#Cases_04-07-2020\n",
      "#Cases_04-08-2020\n",
      "#Cases_04-09-2020\n",
      "#Cases_04-10-2020\n",
      "#Cases_04-11-2020\n",
      "#Cases_04-12-2020\n",
      "#Cases_04-13-2020\n",
      "#Cases_04-14-2020\n",
      "#Cases_04-15-2020\n",
      "#Cases_04-16-2020\n",
      "#Cases_04-17-2020\n",
      "#Cases_04-18-2020\n",
      "#Cases_04-19-2020\n",
      "#Cases_04-20-2020\n",
      "#Cases_04-21-2020\n",
      "#Cases_04-22-2020\n",
      "#Cases_04-23-2020\n",
      "#Cases_04-24-2020\n",
      "#Cases_04-25-2020\n",
      "#Cases_04-26-2020\n",
      "#Cases_04-27-2020\n",
      "#Cases_04-28-2020\n",
      "#Cases_04-29-2020\n",
      "#Cases_04-30-2020\n",
      "#Cases_05-01-2020\n",
      "#Cases_05-02-2020\n",
      "#Cases_05-03-2020\n",
      "#Cases_05-04-2020\n",
      "#Cases_05-05-2020\n",
      "#Cases_05-06-2020\n",
      "#Cases_05-07-2020\n",
      "#Cases_05-08-2020\n",
      "#Cases_05-09-2020\n",
      "#Cases_05-10-2020\n",
      "#Cases_05-11-2020\n",
      "#Cases_05-12-2020\n",
      "#Cases_05-13-2020\n",
      "#Cases_05-14-2020\n",
      "#Cases_05-15-2020\n",
      "#Cases_05-16-2020\n",
      "#Cases_05-17-2020\n",
      "#Cases_05-18-2020\n",
      "#Cases_05-19-2020\n",
      "#Cases_05-20-2020\n",
      "#Cases_05-21-2020\n",
      "#Cases_05-22-2020\n",
      "#Cases_05-23-2020\n",
      "#Cases_05-24-2020\n",
      "#Cases_05-25-2020\n",
      "#Cases_05-26-2020\n",
      "#Cases_05-27-2020\n",
      "#Cases_05-28-2020\n",
      "#Cases_05-29-2020\n",
      "#Cases_05-30-2020\n",
      "#Cases_05-31-2020\n",
      "#Deaths_01-22-2020\n",
      "#Deaths_01-23-2020\n",
      "#Deaths_01-24-2020\n",
      "#Deaths_01-25-2020\n",
      "#Deaths_01-26-2020\n",
      "#Deaths_01-27-2020\n",
      "#Deaths_01-28-2020\n",
      "#Deaths_01-29-2020\n",
      "#Deaths_01-30-2020\n",
      "#Deaths_01-31-2020\n",
      "#Deaths_02-01-2020\n",
      "#Deaths_02-02-2020\n",
      "#Deaths_02-03-2020\n",
      "#Deaths_02-04-2020\n",
      "#Deaths_02-05-2020\n",
      "#Deaths_02-06-2020\n",
      "#Deaths_02-07-2020\n",
      "#Deaths_02-08-2020\n",
      "#Deaths_02-09-2020\n",
      "#Deaths_02-10-2020\n",
      "#Deaths_02-11-2020\n",
      "#Deaths_02-12-2020\n",
      "#Deaths_02-13-2020\n",
      "#Deaths_02-14-2020\n",
      "#Deaths_02-15-2020\n",
      "#Deaths_02-16-2020\n",
      "#Deaths_02-17-2020\n",
      "#Deaths_02-18-2020\n",
      "#Deaths_02-19-2020\n",
      "#Deaths_02-20-2020\n",
      "#Deaths_02-21-2020\n",
      "#Deaths_02-22-2020\n",
      "#Deaths_02-23-2020\n",
      "#Deaths_02-24-2020\n",
      "#Deaths_02-25-2020\n",
      "#Deaths_02-26-2020\n",
      "#Deaths_02-27-2020\n",
      "#Deaths_02-28-2020\n",
      "#Deaths_02-29-2020\n",
      "#Deaths_03-01-2020\n",
      "#Deaths_03-02-2020\n",
      "#Deaths_03-03-2020\n",
      "#Deaths_03-04-2020\n",
      "#Deaths_03-05-2020\n",
      "#Deaths_03-06-2020\n",
      "#Deaths_03-07-2020\n",
      "#Deaths_03-08-2020\n",
      "#Deaths_03-09-2020\n",
      "#Deaths_03-10-2020\n",
      "#Deaths_03-11-2020\n",
      "#Deaths_03-12-2020\n",
      "#Deaths_03-13-2020\n",
      "#Deaths_03-14-2020\n",
      "#Deaths_03-15-2020\n",
      "#Deaths_03-16-2020\n",
      "#Deaths_03-17-2020\n",
      "#Deaths_03-18-2020\n",
      "#Deaths_03-19-2020\n",
      "#Deaths_03-20-2020\n",
      "#Deaths_03-21-2020\n",
      "#Deaths_03-22-2020\n",
      "#Deaths_03-23-2020\n",
      "#Deaths_03-24-2020\n",
      "#Deaths_03-25-2020\n",
      "#Deaths_03-26-2020\n",
      "#Deaths_03-27-2020\n",
      "#Deaths_03-28-2020\n",
      "#Deaths_03-29-2020\n",
      "#Deaths_03-30-2020\n",
      "#Deaths_03-31-2020\n",
      "#Deaths_04-01-2020\n",
      "#Deaths_04-02-2020\n",
      "#Deaths_04-03-2020\n",
      "#Deaths_04-04-2020\n",
      "#Deaths_04-05-2020\n",
      "#Deaths_04-06-2020\n",
      "#Deaths_04-07-2020\n",
      "#Deaths_04-08-2020\n",
      "#Deaths_04-09-2020\n",
      "#Deaths_04-10-2020\n",
      "#Deaths_04-11-2020\n",
      "#Deaths_04-12-2020\n",
      "#Deaths_04-13-2020\n",
      "#Deaths_04-14-2020\n",
      "#Deaths_04-15-2020\n",
      "#Deaths_04-16-2020\n",
      "#Deaths_04-17-2020\n",
      "#Deaths_04-18-2020\n",
      "#Deaths_04-19-2020\n",
      "#Deaths_04-20-2020\n",
      "#Deaths_04-21-2020\n",
      "#Deaths_04-22-2020\n",
      "#Deaths_04-23-2020\n",
      "#Deaths_04-24-2020\n",
      "#Deaths_04-25-2020\n",
      "#Deaths_04-26-2020\n",
      "#Deaths_04-27-2020\n",
      "#Deaths_04-28-2020\n",
      "#Deaths_04-29-2020\n",
      "#Deaths_04-30-2020\n",
      "#Deaths_05-01-2020\n",
      "#Deaths_05-02-2020\n",
      "#Deaths_05-03-2020\n",
      "#Deaths_05-04-2020\n",
      "#Deaths_05-05-2020\n",
      "#Deaths_05-06-2020\n",
      "#Deaths_05-07-2020\n",
      "#Deaths_05-08-2020\n",
      "#Deaths_05-09-2020\n",
      "#Deaths_05-10-2020\n",
      "#Deaths_05-11-2020\n",
      "#Deaths_05-12-2020\n",
      "#Deaths_05-13-2020\n",
      "#Deaths_05-14-2020\n",
      "#Deaths_05-15-2020\n",
      "#Deaths_05-16-2020\n",
      "#Deaths_05-17-2020\n",
      "#Deaths_05-18-2020\n",
      "#Deaths_05-19-2020\n",
      "#Deaths_05-20-2020\n",
      "#Deaths_05-21-2020\n",
      "#Deaths_05-22-2020\n",
      "#Deaths_05-23-2020\n",
      "#Deaths_05-24-2020\n",
      "#Deaths_05-25-2020\n",
      "#Deaths_05-26-2020\n",
      "#Deaths_05-27-2020\n",
      "#Deaths_05-28-2020\n",
      "#Deaths_05-29-2020\n",
      "#Deaths_05-30-2020\n",
      "deaths\n",
      "cases\n",
      "tot_deaths\n",
      "tot_cases\n",
      "neighbor_deaths\n",
      "neighbor_cases\n"
     ]
    }
   ],
   "source": [
    "for name in df.keys():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t countyFIPS \t 36047\n",
      "1 \t STATEFP \t 36.0\n",
      "2 \t COUNTYFP \t 47.0\n",
      "3 \t CountyName \t Kings\n",
      "4 \t StateName \t NY\n",
      "5 \t State \t New York\n",
      "6 \t lat \t 40.64057761\n",
      "7 \t lon \t -73.95465424\n",
      "8 \t POP_LATITUDE \t 40.650523\n",
      "9 \t POP_LONGITUDE \t -73.95481099999998\n",
      "10 \t CensusRegionName \t Northeast\n",
      "11 \t CensusDivisionName \t Middle Atlantic\n",
      "12 \t Rural-UrbanContinuumCode2013 \t 1.0\n",
      "13 \t PopulationEstimate2018 \t 2582830.0\n",
      "14 \t PopTotalMale2017 \t 1254966.0\n",
      "15 \t PopTotalFemale2017 \t 1393805.0\n",
      "16 \t FracMale2017 \t 0.4737918075968062\n",
      "17 \t PopulationEstimate65+2017 \t 356714.0\n",
      "18 \t PopulationDensityperSqMile2010 \t 35369.2\n",
      "19 \t CensusPopulation2010 \t 2504700.0\n",
      "20 \t MedianAge2010 \t 34.1\n",
      "21 \t #EligibleforMedicare2018 \t 386673.0\n",
      "22 \t MedicareEnrollment,AgedTot2017 \t 309657.0\n",
      "23 \t 3-YrDiabetes2015-17 \t 635.0\n",
      "24 \t DiabetesPercentage \t 9.7\n",
      "25 \t HeartDiseaseMortality \t 195.8\n",
      "26 \t StrokeMortality \t 19.5\n",
      "27 \t Smokers_Percentage \t 13.840801998\n",
      "28 \t RespMortalityRate2014 \t 23.05\n",
      "29 \t #FTEHospitalTotal2017 \t 35442.0\n",
      "30 \t TotalM.D.'s,TotNon-FedandFed2017 \t 9307.0\n",
      "31 \t #HospParticipatinginNetwork2017 \t 6.0\n",
      "32 \t #Hospitals \t 12.0\n",
      "33 \t #ICU_beds \t 318.0\n",
      "34 \t dem_to_rep_ratio \t 4.5415118686367375\n",
      "35 \t PopMale<52010 \t 90415.0\n",
      "36 \t PopFmle<52010 \t 86783.0\n",
      "37 \t PopMale5-92010 \t 81356.0\n",
      "38 \t PopFmle5-92010 \t 78035.0\n",
      "39 \t PopMale10-142010 \t 79604.0\n",
      "40 \t PopFmle10-142010 \t 76959.0\n",
      "41 \t PopMale15-192010 \t 86716.0\n",
      "42 \t PopFmle15-192010 \t 83968.0\n",
      "43 \t PopMale20-242010 \t 96663.0\n",
      "44 \t PopFmle20-242010 \t 99134.0\n",
      "45 \t PopMale25-292010 \t 106054.0\n",
      "46 \t PopFmle25-292010 \t 116788.0\n",
      "47 \t PopMale30-342010 \t 97154.0\n",
      "48 \t PopFmle30-342010 \t 105704.0\n",
      "49 \t PopMale35-442010 \t 161965.0\n",
      "50 \t PopFmle35-442010 \t 179580.0\n",
      "51 \t PopMale45-542010 \t 149489.0\n",
      "52 \t PopFmle45-542010 \t 174688.0\n",
      "53 \t PopMale55-592010 \t 63789.0\n",
      "54 \t PopFmle55-592010 \t 78116.0\n",
      "55 \t PopMale60-642010 \t 55241.0\n",
      "56 \t PopFmle60-642010 \t 68866.0\n",
      "57 \t PopMale65-742010 \t 64628.0\n",
      "58 \t PopFmle65-742010 \t 88066.0\n",
      "59 \t PopMale75-842010 \t 35780.0\n",
      "60 \t PopFmle75-842010 \t 58209.0\n",
      "61 \t PopMale>842010 \t 12524.0\n",
      "62 \t PopFmle>842010 \t 28426.0\n",
      "63 \t 3-YrMortalityAge<1Year2015-17 \t 154.0\n",
      "64 \t 3-YrMortalityAge1-4Years2015-17 \t 24.0\n",
      "65 \t 3-YrMortalityAge5-14Years2015-17 \t 33.0\n",
      "66 \t 3-YrMortalityAge15-24Years2015-17 \t 151.0\n",
      "67 \t 3-YrMortalityAge25-34Years2015-17 \t 341.0\n",
      "68 \t 3-YrMortalityAge35-44Years2015-17 \t 493.0\n",
      "69 \t 3-YrMortalityAge45-54Years2015-17 \t 1116.0\n",
      "70 \t 3-YrMortalityAge55-64Years2015-17 \t 2139.0\n",
      "71 \t 3-YrMortalityAge65-74Years2015-17 \t 2852.0\n",
      "72 \t 3-YrMortalityAge75-84Years2015-17 \t 3552.0\n",
      "73 \t 3-YrMortalityAge85+Years2015-17 \t 5102.0\n",
      "74 \t mortality2015-17Estimated \t 926.2155379885814\n",
      "75 \t stay at home \t 737506.0\n",
      "76 \t >50 gatherings \t 737500.0\n",
      "77 \t >500 gatherings \t 737497.0\n",
      "78 \t public schools \t 737502.0\n",
      "79 \t restaurant dine-in \t 737500.0\n",
      "80 \t entertainment/gym \t 737500.0\n",
      "81 \t federal guidelines \t 737500.0\n",
      "82 \t foreign travel ban \t 737495.0\n",
      "83 \t SVIPercentile \t 0.8153\n",
      "84 \t HPSAShortage \t nan\n",
      "85 \t HPSAServedPop \t nan\n",
      "86 \t HPSAUnderservedPop \t nan\n",
      "87 \t #Cases_01-22-2020 \t 0\n",
      "88 \t #Cases_01-23-2020 \t 0\n",
      "89 \t #Cases_01-24-2020 \t 0\n",
      "90 \t #Cases_01-25-2020 \t 0\n",
      "91 \t #Cases_01-26-2020 \t 0\n",
      "92 \t #Cases_01-27-2020 \t 0\n",
      "93 \t #Cases_01-28-2020 \t 0\n",
      "94 \t #Cases_01-29-2020 \t 0\n",
      "95 \t #Cases_01-30-2020 \t 0\n",
      "96 \t #Cases_01-31-2020 \t 0\n",
      "97 \t #Cases_02-01-2020 \t 0\n",
      "98 \t #Cases_02-02-2020 \t 0\n",
      "99 \t #Cases_02-03-2020 \t 0\n",
      "100 \t #Cases_02-04-2020 \t 0\n",
      "101 \t #Cases_02-05-2020 \t 0\n",
      "102 \t #Cases_02-06-2020 \t 0\n",
      "103 \t #Cases_02-07-2020 \t 0\n",
      "104 \t #Cases_02-08-2020 \t 0\n",
      "105 \t #Cases_02-09-2020 \t 0\n",
      "106 \t #Cases_02-10-2020 \t 0\n",
      "107 \t #Cases_02-11-2020 \t 0\n",
      "108 \t #Cases_02-12-2020 \t 0\n",
      "109 \t #Cases_02-13-2020 \t 0\n",
      "110 \t #Cases_02-14-2020 \t 0\n",
      "111 \t #Cases_02-15-2020 \t 0\n",
      "112 \t #Cases_02-16-2020 \t 0\n",
      "113 \t #Cases_02-17-2020 \t 0\n",
      "114 \t #Cases_02-18-2020 \t 0\n",
      "115 \t #Cases_02-19-2020 \t 0\n",
      "116 \t #Cases_02-20-2020 \t 0\n",
      "117 \t #Cases_02-21-2020 \t 0\n",
      "118 \t #Cases_02-22-2020 \t 0\n",
      "119 \t #Cases_02-23-2020 \t 0\n",
      "120 \t #Cases_02-24-2020 \t 0\n",
      "121 \t #Cases_02-25-2020 \t 0\n",
      "122 \t #Cases_02-26-2020 \t 0\n",
      "123 \t #Cases_02-27-2020 \t 0\n",
      "124 \t #Cases_02-28-2020 \t 0\n",
      "125 \t #Cases_02-29-2020 \t 0\n",
      "126 \t #Cases_03-01-2020 \t 0\n",
      "127 \t #Cases_03-02-2020 \t 0\n",
      "128 \t #Cases_03-03-2020 \t 0\n",
      "129 \t #Cases_03-04-2020 \t 0\n",
      "130 \t #Cases_03-05-2020 \t 1\n",
      "131 \t #Cases_03-06-2020 \t 1\n",
      "132 \t #Cases_03-07-2020 \t 3\n",
      "133 \t #Cases_03-08-2020 \t 3\n",
      "134 \t #Cases_03-09-2020 \t 4\n",
      "135 \t #Cases_03-10-2020 \t 10\n",
      "136 \t #Cases_03-11-2020 \t 14\n",
      "137 \t #Cases_03-12-2020 \t 24\n",
      "138 \t #Cases_03-13-2020 \t 24\n",
      "139 \t #Cases_03-14-2020 \t 34\n",
      "140 \t #Cases_03-15-2020 \t 53\n",
      "141 \t #Cases_03-16-2020 \t 62\n",
      "142 \t #Cases_03-17-2020 \t 157\n",
      "143 \t #Cases_03-18-2020 \t 505\n",
      "144 \t #Cases_03-19-2020 \t 1195\n",
      "145 \t #Cases_03-20-2020 \t 1518\n",
      "146 \t #Cases_03-21-2020 \t 2484\n",
      "147 \t #Cases_03-22-2020 \t 2857\n",
      "148 \t #Cases_03-23-2020 \t 3494\n",
      "149 \t #Cases_03-24-2020 \t 4237\n",
      "150 \t #Cases_03-25-2020 \t 5232\n",
      "151 \t #Cases_03-26-2020 \t 6095\n",
      "152 \t #Cases_03-27-2020 \t 6750\n",
      "153 \t #Cases_03-28-2020 \t 8129\n",
      "154 \t #Cases_03-29-2020 \t 8887\n",
      "155 \t #Cases_03-30-2020 \t 10171\n",
      "156 \t #Cases_03-31-2020 \t 11160\n",
      "157 \t #Cases_04-01-2020 \t 12274\n",
      "158 \t #Cases_04-02-2020 \t 13290\n",
      "159 \t #Cases_04-03-2020 \t 15700\n",
      "160 \t #Cases_04-04-2020 \t 17504\n",
      "161 \t #Cases_04-05-2020 \t 18558\n",
      "162 \t #Cases_04-06-2020 \t 19702\n",
      "163 \t #Cases_04-07-2020 \t 20879\n",
      "164 \t #Cases_04-08-2020 \t 22082\n",
      "165 \t #Cases_04-09-2020 \t 23394\n",
      "166 \t #Cases_04-10-2020 \t 24715\n",
      "167 \t #Cases_04-11-2020 \t 26243\n",
      "168 \t #Cases_04-12-2020 \t 27471\n",
      "169 \t #Cases_04-13-2020 \t 28404\n",
      "170 \t #Cases_04-14-2020 \t 29306\n",
      "171 \t #Cases_04-15-2020 \t 31969\n",
      "172 \t #Cases_04-16-2020 \t 33521\n",
      "173 \t #Cases_04-17-2020 \t 34705\n",
      "174 \t #Cases_04-18-2020 \t 35763\n",
      "175 \t #Cases_04-19-2020 \t 36482\n",
      "176 \t #Cases_04-20-2020 \t 37030\n",
      "177 \t #Cases_04-21-2020 \t 37694\n",
      "178 \t #Cases_04-22-2020 \t 38481\n",
      "179 \t #Cases_04-23-2020 \t 39354\n",
      "180 \t #Cases_04-24-2020 \t 40648\n",
      "181 \t #Cases_04-25-2020 \t 41660\n",
      "182 \t #Cases_04-26-2020 \t 42487\n",
      "183 \t #Cases_04-27-2020 \t 43014\n",
      "184 \t #Cases_04-28-2020 \t 43587\n",
      "185 \t #Cases_04-29-2020 \t 44236\n",
      "186 \t #Cases_04-30-2020 \t 44872\n",
      "187 \t #Cases_05-01-2020 \t 45519\n",
      "188 \t #Cases_05-02-2020 \t 46275\n",
      "189 \t #Cases_05-03-2020 \t 46839\n",
      "190 \t #Cases_05-04-2020 \t 47183\n",
      "191 \t #Cases_05-05-2020 \t 47579\n",
      "192 \t #Cases_05-06-2020 \t 47974\n",
      "193 \t #Cases_05-07-2020 \t 48550\n",
      "194 \t #Cases_05-08-2020 \t 48998\n",
      "195 \t #Cases_05-09-2020 \t 49461\n",
      "196 \t #Cases_05-10-2020 \t 49817\n",
      "197 \t #Cases_05-11-2020 \t 50072\n",
      "198 \t #Cases_05-12-2020 \t 50331\n",
      "199 \t #Cases_05-13-2020 \t 50667\n",
      "200 \t #Cases_05-14-2020 \t 51095\n",
      "201 \t #Cases_05-15-2020 \t 51581\n",
      "202 \t #Cases_05-16-2020 \t 51991\n",
      "203 \t #Cases_05-17-2020 \t 52298\n",
      "204 \t #Cases_05-18-2020 \t 52485\n",
      "205 \t #Cases_05-19-2020 \t 52681\n",
      "206 \t #Cases_05-20-2020 \t 52889\n",
      "207 \t #Cases_05-21-2020 \t 53385\n",
      "208 \t #Cases_05-22-2020 \t 53639\n",
      "209 \t #Cases_05-23-2020 \t 53902\n",
      "210 \t #Cases_05-24-2020 \t 54175\n",
      "211 \t #Cases_05-25-2020 \t 54360\n",
      "212 \t #Cases_05-26-2020 \t 54560\n",
      "213 \t #Cases_05-27-2020 \t 54779\n",
      "214 \t #Cases_05-28-2020 \t 55147\n",
      "215 \t #Cases_05-29-2020 \t 55446\n",
      "216 \t #Cases_05-30-2020 \t 55727\n",
      "217 \t #Cases_05-31-2020 \t 55900\n",
      "218 \t #Deaths_01-22-2020 \t 0\n",
      "219 \t #Deaths_01-23-2020 \t 0\n",
      "220 \t #Deaths_01-24-2020 \t 0\n",
      "221 \t #Deaths_01-25-2020 \t 0\n",
      "222 \t #Deaths_01-26-2020 \t 0\n",
      "223 \t #Deaths_01-27-2020 \t 0\n",
      "224 \t #Deaths_01-28-2020 \t 0\n",
      "225 \t #Deaths_01-29-2020 \t 0\n",
      "226 \t #Deaths_01-30-2020 \t 0\n",
      "227 \t #Deaths_01-31-2020 \t 0\n",
      "228 \t #Deaths_02-01-2020 \t 0\n",
      "229 \t #Deaths_02-02-2020 \t 0\n",
      "230 \t #Deaths_02-03-2020 \t 0\n",
      "231 \t #Deaths_02-04-2020 \t 0\n",
      "232 \t #Deaths_02-05-2020 \t 0\n",
      "233 \t #Deaths_02-06-2020 \t 0\n",
      "234 \t #Deaths_02-07-2020 \t 0\n",
      "235 \t #Deaths_02-08-2020 \t 0\n",
      "236 \t #Deaths_02-09-2020 \t 0\n",
      "237 \t #Deaths_02-10-2020 \t 0\n",
      "238 \t #Deaths_02-11-2020 \t 0\n",
      "239 \t #Deaths_02-12-2020 \t 0\n",
      "240 \t #Deaths_02-13-2020 \t 0\n",
      "241 \t #Deaths_02-14-2020 \t 0\n",
      "242 \t #Deaths_02-15-2020 \t 0\n",
      "243 \t #Deaths_02-16-2020 \t 0\n",
      "244 \t #Deaths_02-17-2020 \t 0\n",
      "245 \t #Deaths_02-18-2020 \t 0\n",
      "246 \t #Deaths_02-19-2020 \t 0\n",
      "247 \t #Deaths_02-20-2020 \t 0\n",
      "248 \t #Deaths_02-21-2020 \t 0\n",
      "249 \t #Deaths_02-22-2020 \t 0\n",
      "250 \t #Deaths_02-23-2020 \t 0\n",
      "251 \t #Deaths_02-24-2020 \t 0\n",
      "252 \t #Deaths_02-25-2020 \t 0\n",
      "253 \t #Deaths_02-26-2020 \t 0\n",
      "254 \t #Deaths_02-27-2020 \t 0\n",
      "255 \t #Deaths_02-28-2020 \t 0\n",
      "256 \t #Deaths_02-29-2020 \t 0\n",
      "257 \t #Deaths_03-01-2020 \t 0\n",
      "258 \t #Deaths_03-02-2020 \t 0\n",
      "259 \t #Deaths_03-03-2020 \t 0\n",
      "260 \t #Deaths_03-04-2020 \t 0\n",
      "261 \t #Deaths_03-05-2020 \t 0\n",
      "262 \t #Deaths_03-06-2020 \t 0\n",
      "263 \t #Deaths_03-07-2020 \t 0\n",
      "264 \t #Deaths_03-08-2020 \t 0\n",
      "265 \t #Deaths_03-09-2020 \t 0\n",
      "266 \t #Deaths_03-10-2020 \t 0\n",
      "267 \t #Deaths_03-11-2020 \t 0\n",
      "268 \t #Deaths_03-12-2020 \t 0\n",
      "269 \t #Deaths_03-13-2020 \t 0\n",
      "270 \t #Deaths_03-14-2020 \t 1\n",
      "271 \t #Deaths_03-15-2020 \t 1\n",
      "272 \t #Deaths_03-16-2020 \t 1\n",
      "273 \t #Deaths_03-17-2020 \t 1\n",
      "274 \t #Deaths_03-18-2020 \t 1\n",
      "275 \t #Deaths_03-19-2020 \t 1\n",
      "276 \t #Deaths_03-20-2020 \t 1\n",
      "277 \t #Deaths_03-21-2020 \t 1\n",
      "278 \t #Deaths_03-22-2020 \t 14\n",
      "279 \t #Deaths_03-23-2020 \t 27\n",
      "280 \t #Deaths_03-24-2020 \t 45\n",
      "281 \t #Deaths_03-25-2020 \t 64\n",
      "282 \t #Deaths_03-26-2020 \t 81\n",
      "283 \t #Deaths_03-27-2020 \t 102\n",
      "284 \t #Deaths_03-28-2020 \t 167\n",
      "285 \t #Deaths_03-29-2020 \t 185\n",
      "286 \t #Deaths_03-30-2020 \t 215\n",
      "287 \t #Deaths_03-31-2020 \t 261\n",
      "288 \t #Deaths_04-01-2020 \t 328\n",
      "289 \t #Deaths_04-02-2020 \t 385\n",
      "290 \t #Deaths_04-03-2020 \t 485\n",
      "291 \t #Deaths_04-04-2020 \t 610\n",
      "292 \t #Deaths_04-05-2020 \t 896\n",
      "293 \t #Deaths_04-06-2020 \t 1022\n",
      "294 \t #Deaths_04-07-2020 \t 1153\n",
      "295 \t #Deaths_04-08-2020 \t 1313\n",
      "296 \t #Deaths_04-09-2020 \t 1473\n",
      "297 \t #Deaths_04-10-2020 \t 1640\n",
      "298 \t #Deaths_04-11-2020 \t 1843\n",
      "299 \t #Deaths_04-12-2020 \t 2028\n",
      "300 \t #Deaths_04-13-2020 \t 2132\n",
      "301 \t #Deaths_04-14-2020 \t 2839\n",
      "302 \t #Deaths_04-15-2020 \t 3007\n",
      "303 \t #Deaths_04-16-2020 \t 3164\n",
      "304 \t #Deaths_04-17-2020 \t 3317\n",
      "305 \t #Deaths_04-18-2020 \t 3451\n",
      "306 \t #Deaths_04-19-2020 \t 3749\n",
      "307 \t #Deaths_04-20-2020 \t 3900\n",
      "308 \t #Deaths_04-21-2020 \t 4071\n",
      "309 \t #Deaths_04-22-2020 \t 4247\n",
      "310 \t #Deaths_04-23-2020 \t 4413\n",
      "311 \t #Deaths_04-24-2020 \t 4568\n",
      "312 \t #Deaths_04-25-2020 \t 4738\n",
      "313 \t #Deaths_04-26-2020 \t 4878\n",
      "314 \t #Deaths_04-27-2020 \t 4970\n",
      "315 \t #Deaths_04-28-2020 \t 5064\n",
      "316 \t #Deaths_04-29-2020 \t 5155\n",
      "317 \t #Deaths_04-30-2020 \t 5228\n",
      "318 \t #Deaths_05-01-2020 \t 5320\n",
      "319 \t #Deaths_05-02-2020 \t 5410\n",
      "320 \t #Deaths_05-03-2020 \t 5508\n",
      "321 \t #Deaths_05-04-2020 \t 5569\n",
      "322 \t #Deaths_05-05-2020 \t 5638\n",
      "323 \t #Deaths_05-06-2020 \t 5677\n",
      "324 \t #Deaths_05-07-2020 \t 5783\n",
      "325 \t #Deaths_05-08-2020 \t 5853\n",
      "326 \t #Deaths_05-09-2020 \t 5924\n",
      "327 \t #Deaths_05-10-2020 \t 5976\n",
      "328 \t #Deaths_05-11-2020 \t 6017\n",
      "329 \t #Deaths_05-12-2020 \t 6077\n",
      "330 \t #Deaths_05-13-2020 \t 6127\n",
      "331 \t #Deaths_05-14-2020 \t 6194\n",
      "332 \t #Deaths_05-15-2020 \t 6246\n",
      "333 \t #Deaths_05-16-2020 \t 6278\n",
      "334 \t #Deaths_05-17-2020 \t 6304\n",
      "335 \t #Deaths_05-18-2020 \t 6330\n",
      "336 \t #Deaths_05-19-2020 \t 6353\n",
      "337 \t #Deaths_05-20-2020 \t 6401\n",
      "338 \t #Deaths_05-21-2020 \t 6435\n",
      "339 \t #Deaths_05-22-2020 \t 6459\n",
      "340 \t #Deaths_05-23-2020 \t 6479\n",
      "341 \t #Deaths_05-24-2020 \t 6504\n",
      "342 \t #Deaths_05-25-2020 \t 6517\n",
      "343 \t #Deaths_05-26-2020 \t 6533\n",
      "344 \t #Deaths_05-27-2020 \t 6544\n",
      "345 \t #Deaths_05-28-2020 \t 6561\n",
      "346 \t #Deaths_05-29-2020 \t 6582\n",
      "347 \t #Deaths_05-30-2020 \t 6582\n",
      "348 \t deaths \t [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    1    1    1    1\n",
      "    1    1    1    1   14   27   45   64   81  102  167  185  215  261\n",
      "  328  385  485  610  896 1022 1153 1313 1473 1640 1843 2028 2132 2839\n",
      " 3007 3164 3317 3451 3749 3900 4071 4247 4413 4568 4738 4878 4970 5064\n",
      " 5155 5228 5320 5410 5508 5569 5638 5677 5783 5853 5924 5976 6017 6077\n",
      " 6127 6194 6246 6278 6304 6330 6353 6401 6435 6459 6479 6504 6517 6533\n",
      " 6544 6561 6582 6582]\n",
      "349 \t cases \t [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     1     1     3     3     4\n",
      "    10    14    24    24    34    53    62   157   505  1195  1518  2484\n",
      "  2857  3494  4237  5232  6095  6750  8129  8887 10171 11160 12274 13290\n",
      " 15700 17504 18558 19702 20879 22082 23394 24715 26243 27471 28404 29306\n",
      " 31969 33521 34705 35763 36482 37030 37694 38481 39354 40648 41660 42487\n",
      " 43014 43587 44236 44872 45519 46275 46839 47183 47579 47974 48550 48998\n",
      " 49461 49817 50072 50331 50667 51095 51581 51991 52298 52485 52681 52889\n",
      " 53385 53639 53902 54175 54360 54560 54779 55147 55446 55727 55900]\n",
      "350 \t tot_deaths \t 6582\n",
      "351 \t tot_cases \t 55900\n",
      "352 \t neighbor_deaths \t [0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00\n",
      " 0.0000e+00 0.0000e+00 0.0000e+00 0.0000e+00 1.0000e+00 5.0000e+00\n",
      " 1.0000e+00 1.0000e+00 1.0000e+00 2.0000e+00 2.0000e+00 2.0000e+00\n",
      " 5.0000e+01 9.8000e+01 1.4700e+02 2.2300e+02 2.8900e+02 3.5300e+02\n",
      " 5.2600e+02 5.9400e+02 7.0400e+02 8.4500e+02 1.0420e+03 1.1840e+03\n",
      " 1.4450e+03 1.7550e+03 2.3360e+03 2.6700e+03 3.0940e+03 3.6120e+03\n",
      " 3.9250e+03 4.5820e+03 4.9780e+03 5.5490e+03 5.6660e+03 7.5060e+03\n",
      " 7.9520e+03 8.4210e+03 8.8230e+03 9.1510e+03 9.9080e+03 1.0308e+04\n",
      " 1.0807e+04 1.1246e+04 1.1617e+04 1.2110e+04 1.2558e+04 1.2866e+04\n",
      " 1.3092e+04 1.3366e+04 1.3651e+04 1.3911e+04 1.4157e+04 1.4383e+04\n",
      " 1.4639e+04 1.4788e+04 1.4968e+04 1.5258e+04 1.5515e+04 1.5687e+04\n",
      " 1.5872e+04 1.6006e+04 1.6122e+04 1.6245e+04 1.6386e+04 1.6532e+04\n",
      " 1.6656e+04 1.6737e+04 1.6833e+04 1.6908e+04 1.6982e+04 1.7100e+04\n",
      " 1.7193e+04 1.7274e+04 1.7335e+04 1.7387e+04 1.7424e+04 1.7459e+04\n",
      " 1.7502e+04 1.7554e+04 1.7613e+04 1.7618e+04]\n",
      "353 \t neighbor_cases \t [0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      " 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00\n",
      " 1.00000e+00 4.00000e+00 5.00000e+00 1.20000e+01 1.30000e+01 1.90000e+01\n",
      " 3.40000e+01 4.10000e+01 8.60000e+01 9.30000e+01 1.75000e+02 2.30000e+02\n",
      " 3.29000e+02 7.42000e+02 1.73900e+03 3.50900e+03 4.54600e+03 7.13500e+03\n",
      " 8.36300e+03 1.06940e+04 1.26750e+04 1.66940e+04 1.92740e+04 2.14760e+04\n",
      " 2.57490e+04 2.81640e+04 3.24410e+04 3.55280e+04 3.89750e+04 4.25990e+04\n",
      " 4.95640e+04 5.44820e+04 5.81070e+04 6.22490e+04 6.64770e+04 7.06140e+04\n",
      " 7.51150e+04 7.96350e+04 8.46820e+04 8.92360e+04 9.24370e+04 9.54410e+04\n",
      " 1.02160e+05 1.06379e+05 1.09953e+05 1.13200e+05 1.16099e+05 1.18584e+05\n",
      " 1.21017e+05 1.23663e+05 1.26841e+05 1.30783e+05 1.34297e+05 1.36996e+05\n",
      " 1.38858e+05 1.40653e+05 1.42837e+05 1.45150e+05 1.47053e+05 1.49305e+05\n",
      " 1.51184e+05 1.52309e+05 1.53497e+05 1.54709e+05 1.56389e+05 1.57770e+05\n",
      " 1.59160e+05 1.60180e+05 1.60997e+05 1.61657e+05 1.62608e+05 1.63699e+05\n",
      " 1.65075e+05 1.66114e+05 1.67018e+05 1.67646e+05 1.68172e+05 1.68880e+05\n",
      " 1.69886e+05 1.70615e+05 1.71255e+05 1.71963e+05 1.72535e+05 1.73033e+05\n",
      " 1.73597e+05 1.74524e+05 1.75312e+05 1.75978e+05 1.76469e+05]\n"
     ]
    }
   ],
   "source": [
    "keys = df.keys()\n",
    "for i, val in enumerate(df.iloc[0]):\n",
    "    print(i, '\\t', keys[i], '\\t', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contiguous graph\n",
    "\n",
    "Counties are connected if they are next to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "county_names = df['CountyName']\n",
    "state_code = np.array([int(code) for code in df['STATEFP']])\n",
    "county_code = np.array([int(code) for code in df['COUNTYFP']])\n",
    "county_code = state_code * 1000 + county_code\n",
    "county_code_dict = {code:idx for idx, code in enumerate(county_code)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
      "county code 33 does not exist\n",
      "county code 20 does not exist\n",
      "county code 21 does not exist\n",
      "county code 72 does not exist\n",
      "county code 15 does not exist\n",
      "county code 36 does not exist\n",
      "county code 116 does not exist\n",
      "county code 14 does not exist\n",
      "county code 17 does not exist\n",
      "county code 13 does not exist\n",
      "county code 15 does not exist\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d0b308d467e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneigh_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mneigh_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mneigh_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounty_code_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0msrc_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "from scipy import sparse as spsp\n",
    "import dgl\n",
    "\n",
    "src_nodes = []\n",
    "dst_nodes = []\n",
    "for i in range(65, 79):\n",
    "    contiguous = df[keys[i]]\n",
    "    for src, neigh_code in enumerate(contiguous):\n",
    "        if neigh_code != '':\n",
    "            neigh_code = int(neigh_code)\n",
    "            if neigh_code in county_code_dict:\n",
    "                src_nodes.append(src)\n",
    "                dst_nodes.append(county_code_dict[neigh_code])\n",
    "            else:\n",
    "                print('county code {} does not exist'.format(neigh_code))\n",
    "src_nodes = np.array(src_nodes)\n",
    "dst_nodes = np.array(dst_nodes)\n",
    "spm = spsp.coo_matrix((np.ones(len(src_nodes)), (src_nodes, dst_nodes)))\n",
    "print(spm.shape)\n",
    "g = dgl.DGLGraph(spm, readonly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commute graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "commute_df = pd.read_csv('data/commute.csv', encoding = \"ISO-8859-1\", header=None,\n",
    "                         names=['state_code', 'county_code', 'state', 'county',\n",
    "                                'work_state_code', 'work_county_code', 'work_state', 'work_county',\n",
    "                                'num', 'error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|V|=3113, |E|=64070\n",
      "(array([   1, 1081, 1124,  330,  138,  124,  114,   91,  108,    2]), array([    0,     1,     5,    10,    15,    20,    30,    50,   100,\n",
      "        1000, 10000]))\n",
      "(array([   0,  885, 1284,  397,  147,   99,   95,   86,  119,    1]), array([    0,     1,     5,    10,    15,    20,    30,    50,   100,\n",
      "        1000, 10000]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "commutes = np.array(commute_df['num'])\n",
    "src_code = np.array(commute_df['state_code']) * 1000 + np.array(commute_df['county_code'])\n",
    "dst_code = np.array(commute_df['work_state_code']) * 1000 + np.array(commute_df['work_county_code'])\n",
    "src_code1 = src_code[np.logical_and(commutes > 100, np.logical_not(np.isnan(dst_code)))]\n",
    "dst_code1 = dst_code[np.logical_and(commutes > 100, np.logical_not(np.isnan(dst_code)))]\n",
    "src = []\n",
    "dst = []\n",
    "for s, d in zip(src_code1, dst_code1):\n",
    "    if s in county_code_dict and d in county_code_dict:\n",
    "        src.append(county_code_dict[s])\n",
    "        dst.append(county_code_dict[d])\n",
    "src = np.array(src)\n",
    "dst = np.array(dst)\n",
    "spm = spsp.coo_matrix((np.ones(len(src)), (src, dst)))\n",
    "commute_g = dgl.DGLGraph(spm, readonly=True)\n",
    "print('|V|={}, |E|={}'.format(commute_g.number_of_nodes(), commute_g.number_of_edges()))\n",
    "print(np.histogram(commute_g.in_degrees().numpy(), bins=[0, 1, 5, 10, 15, 20, 30, 50, 100, 1000, 10000]))\n",
    "print(np.histogram(commute_g.out_degrees().numpy(), bins=[0, 1, 5, 10, 15, 20, 30, 50, 100, 1000, 10000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load attributes of counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrs: torch.Size([3113, 7092])\n",
      "cases: (3113, 77)\n",
      "deaths: (3113, 77)\n",
      "tensor([ 1.4670e+03,  1.4860e+03,  1.5060e+03,  ...,  2.2200e+01,\n",
      "         1.2428e+01, -5.5396e-01])\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     1     1     2\n",
      "     4     4    17    26    55    78   118   248   533  1042  1406  2254\n",
      "  2715  3621  4364  6420  7362  8214  9831 10737 12756 13869 15217 16819\n",
      " 18823 20114 21436 23133 24840]\n",
      "[27752 29303 31291     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0    21    40    60    92   124   149   216   253   305\n",
      "   376   447   499   590   685]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "attr_cols = []\n",
    "\n",
    "# Set the variable to True if we want to specify features ourselves.\n",
    "use_specified_fields = False\n",
    "\n",
    "if use_specified_fields:\n",
    "    f = open(\"fields.txt\", \"r\")\n",
    "    fields = f.readlines()\n",
    "    for field in fields:\n",
    "        field = field.rstrip()\n",
    "        arr = np.array(df[field])\n",
    "        if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
    "            attr_cols.append(np.array(arr, dtype=np.float32))\n",
    "else:\n",
    "    for i in range(79, 7181):\n",
    "        arr = np.array(df[keys[i]])\n",
    "        if arr.dtype == np.float32 or arr.dtype == np.float64:\n",
    "            attr_cols.append(np.array(arr, dtype=np.float32))\n",
    "\n",
    "attrs = th.tensor(np.stack(attr_cols, 1), dtype=th.float32)\n",
    "cases = []\n",
    "for i in range(7187, 7264):\n",
    "    cases.append(np.array(df[keys[i]]))\n",
    "cases = np.stack(cases, 1)\n",
    "deaths = []\n",
    "for i in range(7265, 7342):\n",
    "    deaths.append(np.array(df[keys[i]]))\n",
    "deaths = np.stack(deaths, 1)\n",
    "print('attrs:', attrs.shape)\n",
    "print('cases:', cases.shape)\n",
    "print('deaths:', deaths.shape)\n",
    "print(attrs[0])\n",
    "print(cases[0])\n",
    "print(deaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split: Give 10 days as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "num_days = cases.shape[1]\n",
    "train_test_split = num_days - 5\n",
    "in_len = 20\n",
    "out_len = 1\n",
    "\n",
    "train_attr_idxs = []\n",
    "train_past_cases = []\n",
    "train_labels = []\n",
    "for start in range(train_test_split - in_len - out_len + 1):\n",
    "    end = start + in_len + out_len - 1\n",
    "    train_attr_idxs.append(np.arange(len(cases)))\n",
    "    train_past_cases.append(cases[:,start:end])\n",
    "    train_labels.append(deaths[:,end])\n",
    "num_seqs = len(train_past_cases)\n",
    "\n",
    "test_attr_idxs = []\n",
    "test_past_cases = []\n",
    "test_labels = []\n",
    "for start in range(train_test_split - in_len - out_len + 1,\n",
    "                    num_days - in_len - out_len):\n",
    "    end = start + in_len + out_len - 1\n",
    "    test_attr_idxs.append(np.arange(len(cases)))\n",
    "    test_past_cases.append(cases[:,start:end])\n",
    "    test_labels.append(deaths[:,end])\n",
    "\n",
    "train_attr_idxs = np.concatenate(train_attr_idxs, axis=0)\n",
    "train_past_cases = th.tensor(np.concatenate(train_past_cases, axis=0), dtype=th.float32)\n",
    "train_labels = th.tensor(np.concatenate(train_labels, axis=0), dtype=th.float32)\n",
    "test_attr_idxs = np.concatenate(test_attr_idxs, axis=0)\n",
    "test_past_cases = th.tensor(np.concatenate(test_past_cases, axis=0), dtype=th.float32)\n",
    "test_labels = th.tensor(np.concatenate(test_labels, axis=0), dtype=th.float32)\n",
    "print(train_attr_idxs.shape)\n",
    "print(test_attr_idxs.shape)\n",
    "print('train:', train_past_cases.shape)\n",
    "print('test:', test_past_cases.shape)\n",
    "print('test feats:', test_feats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.nn_model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            #nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.nn_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "learning_rate = 0.000001\n",
    "num_epochs = 500\n",
    "batch_size = 1000\n",
    "\n",
    "print('mean of training labels: {:.3f}, mean of testing labels: {:.3f}'.format(th.mean(train_labels),\n",
    "                                                                               th.mean(test_labels)))\n",
    "\n",
    "device = th.device('cuda:0')\n",
    "net = Net(train_past_cases.shape[1] + attrs.shape[1], hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "print('#features:', train_past_cases.shape[1] + attrs.shape[1])\n",
    "\n",
    "# Move model to GPU\n",
    "net = net.to(device)\n",
    "# TODO we might want to choose a better loss.\n",
    "# L2 loss will penalize the data points with larger deaths more. Is this what we want?\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Move data to GPU\n",
    "attrs = attrs.to(device)\n",
    "attrs[th.isnan(attrs)] = 0\n",
    "train_past_cases = train_past_cases.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "if len(train_labels.shape) == 1:\n",
    "    train_labels = train_labels.unsqueeze(1)\n",
    "test_past_cases = test_past_cases.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "if len(test_labels.shape) == 1:\n",
    "    test_labels = test_labels.unsqueeze(1)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# Normalize attrs\n",
    "attr_mean = th.mean(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs - attr_mean\n",
    "attr_std = th.std(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs / attr_std\n",
    "\n",
    "optimizer = th.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    sample_idxs = th.randperm(len(train_past_cases))\n",
    "    batch_idxs = th.split(sample_idxs, batch_size)\n",
    "    losses = []\n",
    "    for idx in batch_idxs:\n",
    "        attr_idx = train_attr_idxs[idx]\n",
    "        labels = train_labels[idx]\n",
    "        batch = th.cat([train_past_cases[idx], attrs[attr_idx]], dim=1)\n",
    "        #batch = train_past_cases[idx]\n",
    "        vals = net(batch)\n",
    "        loss = criterion(vals, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    with th.no_grad():\n",
    "        attr_idx = test_attr_idxs\n",
    "        test_feats = th.cat([test_past_cases, attrs[attr_idx]], dim=1)\n",
    "        #test_feats = test_past_cases\n",
    "        eval_vals = net(test_feats)\n",
    "        eval_rmse = th.mean(th.abs(eval_vals - test_labels))\n",
    "        #print(eval_vals, test_labels)\n",
    "    print('epoch={}, loss={:.3f}, test rmse={:.3f}'.format(epoch, np.mean(losses), eval_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "num_days = cases.shape[1]\n",
    "train_test_split = num_days - 5\n",
    "in_len = 20\n",
    "out_len = 1\n",
    "\n",
    "train_past_cases = []\n",
    "train_labels = []\n",
    "for start in range(train_test_split - in_len - out_len + 1):\n",
    "    end = start + in_len + out_len - 1\n",
    "    train_past_cases.append(th.tensor(cases[:,start:end], dtype=th.float32))\n",
    "    train_labels.append(th.tensor(deaths[:,end], dtype=th.float32))\n",
    "num_seqs = len(train_past_cases)\n",
    "\n",
    "test_past_cases = []\n",
    "test_labels = []\n",
    "for start in range(train_test_split - in_len - out_len + 1,\n",
    "                    num_days - in_len - out_len):\n",
    "    end = start + in_len + out_len - 1\n",
    "    test_past_cases.append(th.tensor(cases[:,start:end], dtype=th.float32))\n",
    "    test_labels.append(th.tensor(deaths[:,end], dtype=th.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import pytorch as dglnn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, g, input_size, hidden_size, gcn_nlayers, num_heads=5):\n",
    "        super(GAT, self).__init__()\n",
    "        self.g = g\n",
    "        self.gcn_layers = nn.ModuleList()\n",
    "        self.gcn_layers.append(dglnn.conv.GATConv(input_size, hidden_size, num_heads=num_heads,\n",
    "                                                  residual=True, activation=F.relu))\n",
    "        for i in range(gcn_nlayers):\n",
    "            self.gcn_layers.append(dglnn.conv.GATConv(num_heads * hidden_size, hidden_size, num_heads=num_heads,\n",
    "                                                      residual=True, activation=F.relu))\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(num_heads * hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        for layer in self.gcn_layers:\n",
    "            h = layer(self.g, h).flatten(1)\n",
    "        return self.linear_layers(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphSage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSage(nn.Module):\n",
    "    def __init__(self, g, input_size, hidden_size, gcn_nlayers):\n",
    "        super(GraphSage, self).__init__()\n",
    "        self.g = g\n",
    "        self.gcn_layers = nn.ModuleList()\n",
    "        self.gcn_layers.append(dglnn.conv.SAGEConv(input_size, hidden_size, aggregator_type='mean', activation=F.relu))\n",
    "        for i in range(gcn_nlayers):\n",
    "            self.gcn_layers.append(dglnn.conv.SAGEConv(hidden_size, hidden_size, aggregator_type='mean', activation=F.relu))\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        for layer in self.gcn_layers:\n",
    "            h = layer(self.g, h)\n",
    "        return self.linear_layers(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#features: 7112\n",
      "epoch=0, loss=4.034, test rmse=1.400\n",
      "epoch=1, loss=3.604, test rmse=1.303\n",
      "epoch=2, loss=3.220, test rmse=1.228\n",
      "epoch=3, loss=2.763, test rmse=1.173\n",
      "epoch=4, loss=2.481, test rmse=1.146\n",
      "epoch=5, loss=2.134, test rmse=1.135\n",
      "epoch=6, loss=2.000, test rmse=1.112\n",
      "epoch=7, loss=1.870, test rmse=1.080\n",
      "epoch=8, loss=1.799, test rmse=1.052\n",
      "epoch=9, loss=1.773, test rmse=1.033\n",
      "epoch=10, loss=1.792, test rmse=1.022\n",
      "epoch=11, loss=1.808, test rmse=1.017\n",
      "epoch=12, loss=1.827, test rmse=1.012\n",
      "epoch=13, loss=1.841, test rmse=0.995\n",
      "epoch=14, loss=1.832, test rmse=0.980\n",
      "epoch=15, loss=1.784, test rmse=0.965\n",
      "epoch=16, loss=1.726, test rmse=0.948\n",
      "epoch=17, loss=1.623, test rmse=0.941\n",
      "epoch=18, loss=1.526, test rmse=0.930\n",
      "epoch=19, loss=1.475, test rmse=0.908\n",
      "epoch=20, loss=1.385, test rmse=0.888\n",
      "epoch=21, loss=1.347, test rmse=0.872\n",
      "epoch=22, loss=1.340, test rmse=0.866\n",
      "epoch=23, loss=1.333, test rmse=0.868\n",
      "epoch=24, loss=1.313, test rmse=0.880\n",
      "epoch=25, loss=1.311, test rmse=0.884\n",
      "epoch=26, loss=1.295, test rmse=0.878\n",
      "epoch=27, loss=1.287, test rmse=0.872\n",
      "epoch=28, loss=1.270, test rmse=0.865\n",
      "epoch=29, loss=1.244, test rmse=0.859\n",
      "epoch=30, loss=1.213, test rmse=0.856\n",
      "epoch=31, loss=1.180, test rmse=0.852\n",
      "epoch=32, loss=1.152, test rmse=0.841\n",
      "epoch=33, loss=1.122, test rmse=0.824\n",
      "epoch=34, loss=1.095, test rmse=0.809\n",
      "epoch=35, loss=1.069, test rmse=0.802\n",
      "epoch=36, loss=1.058, test rmse=0.807\n",
      "epoch=37, loss=1.050, test rmse=0.812\n",
      "epoch=38, loss=1.041, test rmse=0.815\n",
      "epoch=39, loss=1.033, test rmse=0.815\n",
      "epoch=40, loss=1.029, test rmse=0.810\n",
      "epoch=41, loss=1.018, test rmse=0.806\n",
      "epoch=42, loss=1.004, test rmse=0.804\n",
      "epoch=43, loss=0.990, test rmse=0.804\n",
      "epoch=44, loss=0.972, test rmse=0.808\n",
      "epoch=45, loss=0.958, test rmse=0.812\n",
      "epoch=46, loss=0.938, test rmse=0.809\n",
      "epoch=47, loss=0.926, test rmse=0.800\n",
      "epoch=48, loss=0.918, test rmse=0.798\n",
      "epoch=49, loss=0.910, test rmse=0.801\n",
      "epoch=50, loss=0.903, test rmse=0.805\n",
      "epoch=51, loss=0.899, test rmse=0.815\n",
      "epoch=52, loss=0.889, test rmse=0.822\n",
      "epoch=53, loss=0.878, test rmse=0.818\n",
      "epoch=54, loss=0.868, test rmse=0.808\n",
      "epoch=55, loss=0.852, test rmse=0.805\n",
      "epoch=56, loss=0.839, test rmse=0.807\n",
      "epoch=57, loss=0.829, test rmse=0.813\n",
      "epoch=58, loss=0.825, test rmse=0.827\n",
      "epoch=59, loss=0.822, test rmse=0.834\n",
      "epoch=60, loss=0.818, test rmse=0.827\n",
      "epoch=61, loss=0.814, test rmse=0.825\n",
      "epoch=62, loss=0.807, test rmse=0.827\n",
      "epoch=63, loss=0.798, test rmse=0.829\n",
      "epoch=64, loss=0.783, test rmse=0.840\n",
      "epoch=65, loss=0.775, test rmse=0.853\n",
      "epoch=66, loss=0.770, test rmse=0.852\n",
      "epoch=67, loss=0.762, test rmse=0.841\n",
      "epoch=68, loss=0.760, test rmse=0.835\n",
      "epoch=69, loss=0.755, test rmse=0.833\n",
      "epoch=70, loss=0.748, test rmse=0.832\n",
      "epoch=71, loss=0.739, test rmse=0.848\n",
      "epoch=72, loss=0.729, test rmse=0.869\n",
      "epoch=73, loss=0.716, test rmse=0.873\n",
      "epoch=74, loss=0.702, test rmse=0.858\n",
      "epoch=75, loss=0.700, test rmse=0.861\n",
      "epoch=76, loss=0.691, test rmse=0.845\n",
      "epoch=77, loss=0.690, test rmse=0.832\n",
      "epoch=78, loss=0.688, test rmse=0.835\n",
      "epoch=79, loss=0.684, test rmse=0.850\n",
      "epoch=80, loss=0.676, test rmse=0.845\n",
      "epoch=81, loss=0.663, test rmse=0.823\n",
      "epoch=82, loss=0.655, test rmse=0.810\n",
      "epoch=83, loss=0.644, test rmse=0.808\n",
      "epoch=84, loss=0.644, test rmse=0.803\n",
      "epoch=85, loss=0.636, test rmse=0.802\n",
      "epoch=86, loss=0.630, test rmse=0.824\n",
      "epoch=87, loss=0.625, test rmse=0.841\n",
      "epoch=88, loss=0.615, test rmse=0.845\n",
      "epoch=89, loss=0.598, test rmse=0.837\n",
      "epoch=90, loss=0.583, test rmse=0.837\n",
      "epoch=91, loss=0.572, test rmse=0.850\n",
      "epoch=92, loss=0.555, test rmse=0.852\n",
      "epoch=93, loss=0.551, test rmse=0.873\n",
      "epoch=94, loss=0.573, test rmse=0.876\n",
      "epoch=95, loss=0.542, test rmse=0.875\n",
      "epoch=96, loss=0.535, test rmse=0.875\n",
      "epoch=97, loss=0.534, test rmse=0.873\n",
      "epoch=98, loss=0.519, test rmse=0.850\n",
      "epoch=99, loss=0.510, test rmse=0.834\n",
      "epoch=100, loss=0.494, test rmse=0.850\n",
      "epoch=101, loss=0.498, test rmse=0.863\n",
      "epoch=102, loss=0.498, test rmse=0.858\n",
      "epoch=103, loss=0.489, test rmse=0.871\n",
      "epoch=104, loss=0.481, test rmse=0.883\n",
      "epoch=105, loss=0.473, test rmse=0.892\n",
      "epoch=106, loss=0.470, test rmse=0.879\n",
      "epoch=107, loss=0.466, test rmse=0.845\n",
      "epoch=108, loss=0.452, test rmse=0.839\n",
      "epoch=109, loss=0.449, test rmse=0.872\n",
      "epoch=110, loss=0.445, test rmse=0.911\n",
      "epoch=111, loss=0.447, test rmse=0.916\n",
      "epoch=112, loss=0.440, test rmse=0.899\n",
      "epoch=113, loss=0.433, test rmse=0.911\n",
      "epoch=114, loss=0.428, test rmse=0.932\n",
      "epoch=115, loss=0.415, test rmse=0.933\n",
      "epoch=116, loss=0.411, test rmse=0.905\n",
      "epoch=117, loss=0.402, test rmse=0.859\n",
      "epoch=118, loss=0.400, test rmse=0.833\n",
      "epoch=119, loss=0.407, test rmse=0.857\n",
      "epoch=120, loss=0.413, test rmse=0.870\n",
      "epoch=121, loss=0.401, test rmse=0.858\n",
      "epoch=122, loss=0.389, test rmse=0.849\n",
      "epoch=123, loss=0.377, test rmse=0.880\n",
      "epoch=124, loss=0.374, test rmse=0.931\n",
      "epoch=125, loss=0.374, test rmse=0.955\n",
      "epoch=126, loss=0.373, test rmse=0.961\n",
      "epoch=127, loss=0.368, test rmse=0.945\n",
      "epoch=128, loss=0.367, test rmse=0.911\n",
      "epoch=129, loss=0.364, test rmse=0.922\n",
      "epoch=130, loss=0.360, test rmse=0.921\n",
      "epoch=131, loss=0.362, test rmse=0.911\n",
      "epoch=132, loss=0.355, test rmse=0.894\n",
      "epoch=133, loss=0.350, test rmse=0.860\n",
      "epoch=134, loss=0.347, test rmse=0.868\n",
      "epoch=135, loss=0.348, test rmse=0.881\n",
      "epoch=136, loss=0.352, test rmse=0.884\n",
      "epoch=137, loss=0.353, test rmse=0.869\n",
      "epoch=138, loss=0.351, test rmse=0.846\n",
      "epoch=139, loss=0.348, test rmse=0.828\n",
      "epoch=140, loss=0.342, test rmse=0.843\n",
      "epoch=141, loss=0.341, test rmse=0.849\n",
      "epoch=142, loss=0.338, test rmse=0.847\n",
      "epoch=143, loss=0.336, test rmse=0.845\n",
      "epoch=144, loss=0.335, test rmse=0.858\n",
      "epoch=145, loss=0.332, test rmse=0.874\n",
      "epoch=146, loss=0.327, test rmse=0.890\n",
      "epoch=147, loss=0.320, test rmse=0.896\n",
      "epoch=148, loss=0.330, test rmse=0.893\n",
      "epoch=149, loss=0.336, test rmse=0.894\n",
      "epoch=150, loss=0.338, test rmse=0.890\n",
      "epoch=151, loss=0.327, test rmse=0.885\n",
      "epoch=152, loss=0.315, test rmse=0.882\n",
      "epoch=153, loss=0.314, test rmse=0.880\n",
      "epoch=154, loss=0.320, test rmse=0.873\n",
      "epoch=155, loss=0.324, test rmse=0.856\n",
      "epoch=156, loss=0.321, test rmse=0.848\n",
      "epoch=157, loss=0.317, test rmse=0.855\n",
      "epoch=158, loss=0.317, test rmse=0.857\n",
      "epoch=159, loss=0.318, test rmse=0.853\n",
      "epoch=160, loss=0.316, test rmse=0.876\n",
      "epoch=161, loss=0.312, test rmse=0.913\n",
      "epoch=162, loss=0.308, test rmse=0.919\n",
      "epoch=163, loss=0.300, test rmse=0.917\n",
      "epoch=164, loss=0.295, test rmse=0.892\n",
      "epoch=165, loss=0.297, test rmse=0.880\n",
      "epoch=166, loss=0.303, test rmse=0.897\n",
      "epoch=167, loss=0.308, test rmse=0.904\n",
      "epoch=168, loss=0.306, test rmse=0.893\n",
      "epoch=169, loss=0.298, test rmse=0.880\n",
      "epoch=170, loss=0.290, test rmse=0.901\n",
      "epoch=171, loss=0.288, test rmse=0.918\n",
      "epoch=172, loss=0.287, test rmse=0.911\n",
      "epoch=173, loss=0.290, test rmse=0.901\n",
      "epoch=174, loss=0.292, test rmse=0.876\n",
      "epoch=175, loss=0.292, test rmse=0.857\n",
      "epoch=176, loss=0.287, test rmse=0.848\n",
      "epoch=177, loss=0.284, test rmse=0.845\n",
      "epoch=178, loss=0.286, test rmse=0.846\n",
      "epoch=179, loss=0.289, test rmse=0.856\n",
      "epoch=180, loss=0.286, test rmse=0.862\n",
      "epoch=181, loss=0.276, test rmse=0.857\n",
      "epoch=182, loss=0.268, test rmse=0.875\n",
      "epoch=183, loss=0.273, test rmse=0.888\n",
      "epoch=184, loss=0.281, test rmse=0.900\n",
      "epoch=185, loss=0.280, test rmse=0.915\n",
      "epoch=186, loss=0.275, test rmse=0.922\n",
      "epoch=187, loss=0.268, test rmse=0.914\n",
      "epoch=188, loss=0.269, test rmse=0.879\n",
      "epoch=189, loss=0.270, test rmse=0.866\n",
      "epoch=190, loss=0.272, test rmse=0.873\n",
      "epoch=191, loss=0.272, test rmse=0.876\n",
      "epoch=192, loss=0.267, test rmse=0.864\n",
      "epoch=193, loss=0.260, test rmse=0.874\n",
      "epoch=194, loss=0.264, test rmse=0.930\n",
      "epoch=195, loss=0.273, test rmse=0.961\n",
      "epoch=196, loss=0.275, test rmse=0.948\n",
      "epoch=197, loss=0.262, test rmse=0.911\n",
      "epoch=198, loss=0.253, test rmse=0.873\n",
      "epoch=199, loss=0.258, test rmse=0.899\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 100\n",
    "learning_rate = 0.0000005\n",
    "num_epochs = 200\n",
    "batch_size = 1000\n",
    "\n",
    "device = th.device('cuda:0')\n",
    "net = GAT(g, train_past_cases[0].shape[1] + attrs.shape[1], hidden_size, 1)\n",
    "criterion = nn.MSELoss()\n",
    "print('#features:', train_past_cases[0].shape[1] + attrs.shape[1])\n",
    "\n",
    "# Move model to GPU\n",
    "net = net.to(device)\n",
    "# TODO we might want to choose a better loss.\n",
    "# L2 loss will penalize the data points with larger deaths more. Is this what we want?\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Move data to GPU\n",
    "attrs = attrs.to(device)\n",
    "attrs[th.isnan(attrs)] = 0\n",
    "for i in range(len(train_past_cases)):\n",
    "    train_past_cases[i] = train_past_cases[i].to(device)\n",
    "    train_labels[i] = train_labels[i].to(device)\n",
    "    if len(train_labels[i].shape) == 1:\n",
    "        train_labels[i] = train_labels[i].unsqueeze(1)\n",
    "for i in range(len(test_past_cases)):\n",
    "    test_past_cases[i] = test_past_cases[i].to(device)\n",
    "    test_labels[i] = test_labels[i].to(device)\n",
    "    if len(test_labels[i].shape) == 1:\n",
    "        test_labels[i] = test_labels[i].unsqueeze(1)\n",
    "\n",
    "# Normalize attrs\n",
    "attr_mean = th.mean(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs - attr_mean\n",
    "attr_std = th.std(attrs, dim=1, keepdim=True)\n",
    "attrs = attrs / attr_std\n",
    "\n",
    "optimizer = th.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    sample_idxs = th.randperm(len(train_past_cases))\n",
    "    losses = []\n",
    "    for idx in sample_idxs:\n",
    "        labels = train_labels[idx]\n",
    "        batch = th.cat([train_past_cases[idx], attrs], dim=1)\n",
    "        #batch = train_past_cases[idx]\n",
    "        vals = net(batch)\n",
    "        loss = criterion(vals, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    with th.no_grad():\n",
    "        eval_errs = []\n",
    "        for cases, labels in zip(test_past_cases, test_labels):\n",
    "            test_feats = th.cat([cases, attrs], dim=1)\n",
    "            #test_feats = test_past_cases\n",
    "            eval_vals = net(test_feats)\n",
    "            err = th.mean(th.abs(eval_vals - labels))\n",
    "            eval_errs.append(err.cpu().numpy())\n",
    "            #print(eval_vals, test_labels)\n",
    "    print('epoch={}, loss={:.3f}, test rmse={:.3f}'.format(epoch, np.mean(losses), np.mean(eval_errs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
