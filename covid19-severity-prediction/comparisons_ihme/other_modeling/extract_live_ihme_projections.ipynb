{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Notes\n",
    "\n",
    "Run this once a day to extract live data from https://ihmecovid19storage.blob.core.windows.net/latest/ihme-covid19.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile, urllib.request, shutil\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from os import listdir, path\n",
    "\n",
    "# Constants\n",
    "MAX_PROJECTION = 10\n",
    "URL = 'https://ihmecovid19storage.blob.core.windows.net/latest/ihme-covid19.zip'\n",
    "RAW_DIREC = 'ihme/raw/'\n",
    "PROCESSED_DIREC = 'ihme/'\n",
    "TWO_WEEKS, THREE_WEEKS = 14, 21\n",
    "LOCATION = 'location_name' # keeps changing randomly from location to location_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(path_to_zip_file, directory):\n",
    "    with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory)\n",
    "\n",
    "# Initialize file name\n",
    "now = \"\".join(str(datetime.now())).replace(\" \", \"_\")\n",
    "file_name = RAW_DIREC + now + '.zip'\n",
    "\n",
    "# Download zip file\n",
    "with urllib.request.urlopen(URL) as response, open(file_name, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "        \n",
    "# Unzip and delete zip file\n",
    "unzip(file_name, RAW_DIREC)\n",
    "os.remove(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csvs( path_to_dir, suffix=\".csv\" ):\n",
    "    filenames = listdir(path_to_dir)\n",
    "    return [ filename for filename in filenames if filename.endswith(suffix)]\n",
    "\n",
    "def find_date(frame):\n",
    "    # Find latest date for historical data\n",
    "    dates = np.unique(frame[DATE])\n",
    "    for date in dates[::-1]:\n",
    "        delta = datetime.strptime(latest_date, '%Y-%m-%d') - datetime.strptime(date, '%Y-%m-%d')\n",
    "        if abs(delta.days) <= 7:\n",
    "            sub = frame.loc[frame[DATE] == date]\n",
    "            sub = sub.loc[sub[LOCATION] == 'United States of America'].reset_index()\n",
    "            current_date = True\n",
    "            for i in range(sub.shape[0]):\n",
    "                \n",
    "                if sub['deaths_mean'].iloc[i] != sub['deaths_upper'].iloc[i]:\n",
    "                    current_date = False\n",
    "            \n",
    "            if current_date:\n",
    "                return date\n",
    "\n",
    "# Get all downloaded directory names\n",
    "directories = next(os.walk(RAW_DIREC))[1]\n",
    "if '.ipynb_checkpoints' in directories:\n",
    "    directories.remove('.ipynb_checkpoints')\n",
    "    \n",
    "# Find latest date\n",
    "for i, directory in enumerate(directories):\n",
    "    date = directory[:10].replace(\"_\", '-')\n",
    "    if i == 0:\n",
    "        latest_date = date\n",
    "        latest_direc = directory\n",
    "    else:\n",
    "        delta = datetime.strptime(date, '%Y-%m-%d') - datetime.strptime(latest_date, '%Y-%m-%d')\n",
    "        if delta.days >= 0:\n",
    "            latest_date = date\n",
    "            latest_direc = directory\n",
    "            \n",
    "# Read main data file\n",
    "csvs = find_csvs(RAW_DIREC + latest_direc + '/')\n",
    "deaths = pd.read_csv(RAW_DIREC + latest_direc + '/' + csvs[0])\n",
    "\n",
    "for col in list(deaths.columns):\n",
    "    if 'location' in col:\n",
    "        LOCATION = col\n",
    "    elif 'date' in col:\n",
    "        DATE = col\n",
    "        \n",
    "LATEST_DATE = find_date(copy.deepcopy(deaths))\n",
    "\n",
    "# Columns for compiled data\n",
    "columns = [LOCATION, DATE, 'totdea_mean', 'totdea_lower', 'totdea_upper', 'deaths_mean', 'deaths_lower', 'deaths_upper']\n",
    "        \n",
    "# Get unique locations\n",
    "locations = np.unique(deaths[LOCATION])\n",
    "\n",
    "for i, location in enumerate(locations):\n",
    "\n",
    "    # Subset on lcoation\n",
    "    sub_deaths = deaths.loc[deaths[LOCATION] == location]\n",
    "    sub_deaths = sub_deaths.loc[sub_deaths[DATE] >= LATEST_DATE]\n",
    "\n",
    "    sub_deaths = sub_deaths[columns].copy().reset_index()\n",
    "    sub_deaths = sub_deaths.sort_values(by=DATE)\n",
    "\n",
    "    # Calculate projections\n",
    "    projections = pd.DataFrame([sub_deaths.iloc[0].values], columns=sub_deaths.columns)\n",
    "\n",
    "    for j in range(1,MAX_PROJECTION+1):\n",
    "        projections[str(j) + '_day_cumul_mean'] = sub_deaths.iloc[j]['totdea_mean']\n",
    "        projections[str(j) + '_day_cumul_lower'] = sub_deaths.iloc[j]['totdea_lower']\n",
    "        projections[str(j) + '_day_cumul_upper'] = sub_deaths.iloc[j]['totdea_upper']\n",
    "\n",
    "        projections[str(j) + '_day_mean'] = sub_deaths.iloc[j]['deaths_mean']\n",
    "        projections[str(j) + '_day_lower'] = sub_deaths.iloc[j]['deaths_lower']\n",
    "        projections[str(j) + '_day_upper'] = sub_deaths.iloc[j]['deaths_upper']\n",
    "        \n",
    "    for j in [TWO_WEEKS,THREE_WEEKS]:\n",
    "        projections[str(j) + '_day_cumul_mean'] = sub_deaths.iloc[j]['totdea_mean']\n",
    "        projections[str(j) + '_day_cumul_lower'] = sub_deaths.iloc[j]['totdea_lower']\n",
    "        projections[str(j) + '_day_cumul_upper'] = sub_deaths.iloc[j]['totdea_upper']\n",
    "\n",
    "        projections[str(j) + '_day_mean'] = sub_deaths.iloc[j]['deaths_mean']\n",
    "        projections[str(j) + '_day_lower'] = sub_deaths.iloc[j]['deaths_lower']\n",
    "        projections[str(j) + '_day_upper'] = sub_deaths.iloc[j]['deaths_upper']\n",
    "\n",
    "    if i == 0:\n",
    "        compiled_projections = projections.copy()\n",
    "    else:\n",
    "        compiled_projections = compiled_projections.append(projections.copy(), ignore_index=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "compiled_projections = compiled_projections.drop(columns=['index', 'totdea_upper', 'totdea_lower',\n",
    "                                                         'deaths_upper', 'deaths_lower'])\n",
    "\n",
    "# Rename column\n",
    "compiled_projections = compiled_projections.rename(columns={\"totdea_mean\": \"cumul_deaths\",\n",
    "                                                            \"deaths_mean\": 'deaths'})\n",
    "\n",
    "# Change type to int\n",
    "compiled_projections = compiled_projections.astype({'deaths': 'int32', 'cumul_deaths': 'int32'})\n",
    "\n",
    "# Save to file\n",
    "compiled_projections.to_csv(PROCESSED_DIREC + LATEST_DATE + \".csv\", index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
